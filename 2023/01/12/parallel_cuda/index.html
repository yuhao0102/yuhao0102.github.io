<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="zn-ch">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="积累," />










<meta name="description" content="1. GPU 简介GPU（Graphics Processing Unit）是一种图形渲染设备，是显卡（Video Card&#x2F;Graphics Card）的计算核心。GPU 最初仅用作纹理映射和多边形着色等需要较多存储空间的图形处理任务，不过，现代 GPU 已经不再局限于 3D 图形处理。GPU 已经成为了通用的多核处理器，它在 浮点运算、并行计算 等方面提供数十倍乃至于上百倍于 CPU 的性能。">
<meta property="og:type" content="article">
<meta property="og:title" content="parallel CUDA 介绍">
<meta property="og:url" content="http://yoursite.com/2023/01/12/parallel_cuda/index.html">
<meta property="og:site_name" content="Hao Yu&#39;s blog">
<meta property="og:description" content="1. GPU 简介GPU（Graphics Processing Unit）是一种图形渲染设备，是显卡（Video Card&#x2F;Graphics Card）的计算核心。GPU 最初仅用作纹理映射和多边形着色等需要较多存储空间的图形处理任务，不过，现代 GPU 已经不再局限于 3D 图形处理。GPU 已经成为了通用的多核处理器，它在 浮点运算、并行计算 等方面提供数十倍乃至于上百倍于 CPU 的性能。">
<meta property="og:locale" content="zn_CH">
<meta property="og:image" content="http://yoursite.com/img/gpu_cpu.gif">
<meta property="og:image" content="http://yoursite.com/img/gpu_cuda_prog.gif">
<meta property="og:image" content="http://yoursite.com/img/gpu_device_memory.gif">
<meta property="og:image" content="http://yoursite.com/img/gpu_cuda_indexing.gif">
<meta property="og:image" content="http://yoursite.com/img/gpu_dimgrid_dimblock.png">
<meta property="og:image" content="http://yoursite.com/img/gpu_img_size.gif">
<meta property="og:image" content="http://yoursite.com/img/gpu_img_blur.gif">
<meta property="og:image" content="http://yoursite.com/img/gpu_img_blur_edge.gif">
<meta property="og:image" content="http://yoursite.com/img/gpu_block_no_sync.png">
<meta property="og:image" content="http://yoursite.com/img/gpu_automatic_scalability.png">
<meta property="og:image" content="http://yoursite.com/img/gpu_matrix_mul.gif">
<meta property="og:image" content="http://yoursite.com/img/gpu_matrix_example.gif">
<meta property="og:image" content="http://yoursite.com/img/gpu_matrix_example_block.png">
<meta property="og:image" content="http://yoursite.com/img/gpu_cuda_memory_types.gif">
<meta property="og:image" content="http://yoursite.com/img/gpu_matrix_block00.png">
<meta property="og:image" content="http://yoursite.com/img/gpu_cuda_6_unified_memory.gif">
<meta property="article:published_time" content="2023-01-12T10:01:00.000Z">
<meta property="article:modified_time" content="2023-01-12T10:01:23.000Z">
<meta property="article:author" content="Hao Yu">
<meta property="article:tag" content="积累">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/img/gpu_cpu.gif">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2023/01/12/parallel_cuda/"/>





  <title>parallel CUDA 介绍 | Hao Yu's blog</title>
  








<meta name="generator" content="Hexo 6.3.0"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zn-ch">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hao Yu's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">The program monkey was eaten by the siege lion.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/%20" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2023/01/12/parallel_cuda/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hao Yu's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">parallel CUDA 介绍</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2023-01-12T18:01:00+08:00">
                2023-01-12
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="1-GPU-简介"><a href="#1-GPU-简介" class="headerlink" title="1. GPU 简介"></a>1. GPU 简介</h2><p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Graphics_processing_unit">GPU</a>（Graphics Processing Unit）是一种图形渲染设备，是显卡（Video Card/Graphics Card）的计算核心。GPU 最初仅用作纹理映射和多边形着色等需要较多存储空间的图形处理任务，不过，现代 GPU 已经不再局限于 3D 图形处理。GPU 已经成为了通用的多核处理器，它在 <strong>浮点运算、并行计算</strong> 等方面提供数十倍乃至于上百倍于 CPU 的性能。</p>
<p>GPU 和 CPU 有设计理念的不同，GPU 中包含大量的 ALU（Arithmetic Logic Unit），如图 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org0000000">1</a> 所示。</p>
<p><img src="/img/gpu_cpu.gif" alt="gpu_cpu.gif"></p>
<p>Figure 1: GPU 和 CPU 有设计理念的不同，GPU 中包含大量的计算单元</p>
<h2 id="2-CUDA-C-编程"><a href="#2-CUDA-C-编程" class="headerlink" title="2. CUDA C 编程"></a>2. CUDA C 编程</h2><p><a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Nvidia">Nvidia</a> 提出了 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/CUDA">CUDA</a>（Compute Unified Device Architecture）编程模型，它在 C（注：也支持 Fortran）语言的基础上进行了很小的扩展，使得应用程序既可以包含在 CPU 中执行的代码，又可以包含在 GPU 中执行的代码，充分利用了 CPU 和 GPU 各自的优点。</p>
<p>CUDA 程序的执行过程如图 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org0000005">2</a> 所示，这个图演示了先执行 CPU 代码，再执行 GPU 代码，然后又执行 CPU 代码，又再执行 GPU 代码的情况。</p>
<p><img src="/img/gpu_cuda_prog.gif" alt="gpu_cuda_prog.gif"></p>
<p>Figure 2: Execution of a CUDA program</p>
<p>CUDA 程序中， <strong>一个函数用 <code>__global__</code> 修饰，表明这个函数在 GPU 中运行，且被称为“kernel”。</strong></p>
<h3 id="2-1-Hello-World"><a href="#2-1-Hello-World" class="headerlink" title="2.1. Hello World"></a>2.1. Hello World</h3><p>下面是 CUDA 版本的 Hello World 程序：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#include&lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">// Your first kernel (= GPU function)</span><br><span class="line">__global__ void helloFromGPU (void)      // __global__ 是 CUDA 的扩展，表明这个函数在 GPU 中运行</span><br><span class="line">&#123;</span><br><span class="line">    printf(&quot;Hello World from GPU! Thread %d\n&quot;, threadIdx.x);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main(void)</span><br><span class="line">&#123;</span><br><span class="line">    helloFromGPU &lt;&lt;&lt;1, 4&gt;&gt;&gt;();           // &lt;&lt;&lt; &gt;&gt;&gt; 是 CUDA 的扩展，用于指定GPU线程规模</span><br><span class="line"></span><br><span class="line">    cudaDeviceReset();</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用 <a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compilation-with-nvcc">nvcc</a> 进行编译：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ nvcc hello.cu –o hello</span><br></pre></td></tr></table></figure>
<p>测试运行得到的可执行程序：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ ./hello</span><br><span class="line">Hello World from GPU! Thread 0</span><br><span class="line">Hello World from GPU! Thread 1</span><br><span class="line">Hello World from GPU! Thread 2</span><br><span class="line">Hello World from GPU! Thread 3</span><br></pre></td></tr></table></figure>
<h3 id="2-2-实例：数组相加"><a href="#2-2-实例：数组相加" class="headerlink" title="2.2. 实例：数组相加"></a>2.2. 实例：数组相加</h3><p>下面通过“两个浮点数数组相加”的例子来介绍一下 CUDA 编程。</p>
<h4 id="2-2-1-CPU-版本"><a href="#2-2-1-CPU-版本" class="headerlink" title="2.2.1. CPU 版本"></a>2.2.1. CPU 版本</h4><p>先看一下“两个浮点数数组相加”的 CPU 版本：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;iostream&gt;</span><br><span class="line">#include &lt;math.h&gt;</span><br><span class="line"></span><br><span class="line">// function to add the elements of two arrays</span><br><span class="line">void add(int n, float *x, float *y)</span><br><span class="line">&#123;</span><br><span class="line">    for (int i = 0; i &lt; n; i++)</span><br><span class="line">        y[i] = x[i] + y[i];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main(void)</span><br><span class="line">&#123;</span><br><span class="line">    int N = 1&lt;&lt;20; // 1M elements</span><br><span class="line"></span><br><span class="line">    float *x = new float[N];</span><br><span class="line">    float *y = new float[N];</span><br><span class="line"></span><br><span class="line">    // initialize x and y arrays on the host</span><br><span class="line">    for (int i = 0; i &lt; N; i++) &#123;</span><br><span class="line">        x[i] = 1.0f;</span><br><span class="line">        y[i] = 2.0f;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // Run on the CPU</span><br><span class="line">    add(N, x, y);</span><br><span class="line"></span><br><span class="line">    // Check for errors (all values should be 3.0f)</span><br><span class="line">    float maxError = 0.0f;</span><br><span class="line">    for (int i = 0; i &lt; N; i++)</span><br><span class="line">        maxError = fmax(maxError, fabs(y[i]-3.0f));</span><br><span class="line">    std::cout &lt;&lt; &quot;Max error: &quot; &lt;&lt; maxError &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    // Free memory</span><br><span class="line">    delete [] x;</span><br><span class="line">    delete [] y;</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>编译并运行：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ g++ add.cpp -o add</span><br><span class="line">$ ./add</span><br><span class="line">Max error: 0</span><br></pre></td></tr></table></figure>
<h4 id="2-2-2-改造为-GPU-版本"><a href="#2-2-2-改造为-GPU-版本" class="headerlink" title="2.2.2. 改造为 GPU 版本"></a>2.2.2. 改造为 GPU 版本</h4><p>下面我们来看看如何把前面的程序改造为 GPU 版本。</p>
<p><strong>GPU 只能访问 GPU 中的内存，称为 Device Memory；而 CPU 能访问的内存称为 Host Memory。</strong></p>
<p><img src="/img/gpu_device_memory.gif" alt="gpu_device_memory.gif"></p>
<p>Figure 3: Host Memory and Device Memory</p>
<p><strong>对于前面例子，我们要把输入数据（x, y 两个数组）所占的内存从 Host Memory 复制到 Device Memory 中，然后执行 GPU 计算，计算完成后，把计算后的结果从 Device Memory 复制加 Host Memory 中。</strong> 这是 GPU 编程的通用编程模式。</p>
<p>下面是改造后的 GPU 版本：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">// 这个例子仅启动了 1 个 GPU 线程，没有利用 GPU 优势</span><br><span class="line">#include &lt;iostream&gt;</span><br><span class="line">#include &lt;math.h&gt;</span><br><span class="line"></span><br><span class="line">// Kernel function to add the elements of two arrays</span><br><span class="line">__global__                                              // __global__ 表示其将在 GPU 上运行</span><br><span class="line">void add(int n, float *x, float *y)</span><br><span class="line">&#123;</span><br><span class="line">    for (int i = 0; i &lt; n; i++)</span><br><span class="line">        y[i] = x[i] + y[i];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int main(void)</span><br><span class="line">&#123;</span><br><span class="line">    int N = 1&lt;&lt;20; // 1M elements</span><br><span class="line"></span><br><span class="line">    float *x = new float[N];</span><br><span class="line">    float *y = new float[N];</span><br><span class="line"></span><br><span class="line">    // initialize x and y arrays on the host</span><br><span class="line">    for (int i = 0; i &lt; N; i++) &#123;</span><br><span class="line">        x[i] = 1.0f;</span><br><span class="line">        y[i] = 2.0f;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    //</span><br><span class="line">    float *dev_x, *dev_y;</span><br><span class="line">    int size = N * sizeof(float);</span><br><span class="line">    cudaError_t err</span><br><span class="line">    err = cudaMalloc((void **)&amp;dev_x, size);            // 在 GPU 上分配内存</span><br><span class="line">    if (err != cudaSuccess) &#123;</span><br><span class="line">        printf(&quot;%s in %s at line %d\n&quot;, cudaGetErrorString(err),__FILE__,__LINE__);</span><br><span class="line">        exit(EXIT_FAILURE);</span><br><span class="line">    &#125;</span><br><span class="line">    err = cudaMalloc((void **)&amp;dev_y, size);</span><br><span class="line">    if (err != cudaSuccess) &#123;</span><br><span class="line">        printf(&quot;%s in %s at line %d\n&quot;, cudaGetErrorString(err),__FILE__,__LINE__);</span><br><span class="line">        exit(EXIT_FAILURE);</span><br><span class="line">    &#125;</span><br><span class="line">    cudaMemcpy(dev_x, x, size, cudaMemcpyHostToDevice); // 把输入数据从 Host 内存到 Device 内存</span><br><span class="line">    cudaMemcpy(dev_y, y, size, cudaMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    add&lt;&lt;&lt;1, 1&gt;&gt;&gt;(N, x, y);                             // 在 GPU 上执行计算</span><br><span class="line"></span><br><span class="line">    cudaMemcpy(y, dev_y, size, cudaMemcpyDeviceToHost); // 把结果从 Device 内存复制回 Host 内存</span><br><span class="line"></span><br><span class="line">    cudaFree(dev_x);                                    // 释放 Device 内存</span><br><span class="line">    cudaFree(dev_y);</span><br><span class="line"></span><br><span class="line">    // Check for errors (all values should be 3.0f)</span><br><span class="line">    float maxError = 0.0f;</span><br><span class="line">    for (int i = 0; i &lt; N; i++)</span><br><span class="line">        maxError = fmax(maxError, fabs(y[i]-3.0f));</span><br><span class="line">    std::cout &lt;&lt; &quot;Max error: &quot; &lt;&lt; maxError &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    // Free Host memory</span><br><span class="line">    delete [] x;</span><br><span class="line">    delete [] y;</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>经过这个改造后，函数 <code>add</code> 在 GPU 上运行，但仅启动了一个 GPU 线程，这并没有利用 GPU 的优势。为了利用 GPU 优势，我们需要对函数 <code>add</code> 本身进行改造。后面将对此进行介绍。</p>
<h4 id="2-2-3-线程结构-lt-lt-lt-numBlocks-threadsPerBlock-gt-gt-gt"><a href="#2-2-3-线程结构-lt-lt-lt-numBlocks-threadsPerBlock-gt-gt-gt" class="headerlink" title="2.2.3. 线程结构 &lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;"></a>2.2.3. 线程结构 <code>&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;</code></h4><p>在启用 GPU 线程时，需要使用语法 <code>&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;</code> 指定线程结构。</p>
<p>比如： <code>kernel1&lt;&lt;&lt;1, 4&gt;&gt;&gt;();</code> 表示 1 个 block，每个 block 中有 4 个线程。<br>在 kernel 函数中，可以通过 <code>threadIdx.x</code> 知道自己是第几个线程。这例子中 kernel1 中打印 <code>threadIdx.x</code> 时会分别得到 0,1,2,3，参考节 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org0000007">2.1</a> 中的例子。</p>
<p>又如： <code>kernel1&lt;&lt;&lt;2, 4&gt;&gt;&gt;();</code> 表示 2 个 block，每个 block 中有 4 个线程。<br>在 kernel 函数中， <strong>可以通过 <code>blockIdx.x</code> 知道自己是第几个 block，这个例子中会分别为 0,1；可以通过 <code>threadIdx.x</code> 知道自己是第几个线程。</strong> 这例子中 kernel1 中打印 <code>threadIdx.x</code> 时会分别得到 0,1,2,3。也就是说 8 个线程中打印 <code>blockIdx.x</code> 和 <code>threadIdx.x</code> 时会得到：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">blockIdx.x   threadIdx.x</span><br><span class="line">0            0</span><br><span class="line">0            1</span><br><span class="line">0            2</span><br><span class="line">0            3</span><br><span class="line">1            0</span><br><span class="line">1            1</span><br><span class="line">1            2</span><br><span class="line">1            3</span><br></pre></td></tr></table></figure>
<p>在 kernel 函数，通过 <code>blockDim.x</code> 可以知道 <code>threadIdx.x</code> 的维度（最大 <code>x</code> 下标加 1）。也就是说 8 个线程中打印 blockIdx.x, threadIdx.x, blockDim.x 时会得到：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">blockIdx.x   threadIdx.x   blockDim.x</span><br><span class="line">0            0             4</span><br><span class="line">0            1             4</span><br><span class="line">0            2             4</span><br><span class="line">0            3             4</span><br><span class="line">1            0             4</span><br><span class="line">1            1             4</span><br><span class="line">1            2             4</span><br><span class="line">1            3             4</span><br></pre></td></tr></table></figure>
<p>这样，以方式 <code>kernel1&lt;&lt;&lt;2, 4&gt;&gt;&gt;();</code> 启动 kernel1 时，在 kernel1 函数中使用 <code>blockIdx.x * blockDim.x + threadIdx.x</code> 就可以得到 0,1,2,3,4,5,6,7。</p>
<p>这里介绍的线程结构比较简单，关于更多细节，可参考节：<a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org0000019">3.1</a></p>
<h4 id="2-2-4-GPU-版本-2（monolithic-kernel）"><a href="#2-2-4-GPU-版本-2（monolithic-kernel）" class="headerlink" title="2.2.4. GPU 版本 2（monolithic kernel）"></a>2.2.4. GPU 版本 2（monolithic kernel）</h4><p>为了充分利用 GPU 优势，我们让每个 GPU 线程仅处理数组中的一个元素。kernel 函数改造为如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">__global__</span><br><span class="line">void add(int n, float *x, float *y)                 // kernel中仅处理一个元素，每个 kernel处理不同元素</span><br><span class="line">&#123;</span><br><span class="line">    int i = blockIdx.x * blockDim.x + threadIdx.x;  // 获取元素下标，其含义参考上一节内容</span><br><span class="line">    if (i &lt; n)</span><br><span class="line">        y[i] = x[i] + y[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这种类型的 kernel 被称为“monolithic kernel”。</p>
<p>每个线程仅处理 1 个元素，数组有 <code>N=1&lt;&lt;20</code> （即 1M）元素，故我们需要启动 1M 线程，每个线程处理不同元素，下面这都是可行的：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">add&lt;&lt;&lt;ceil(N/512.0), 512&gt;&gt;&gt;(N, x, y); // ceil(N/512.0) = 2048 个 block，每个 block 中有 512 个线程；2048 * 512 = 1M</span><br><span class="line">add&lt;&lt;&lt;ceil(N/256.0), 256&gt;&gt;&gt;(N, x, y); // ceil(N/256.0) = 4096 个 block，每个 block 中有 256 个线程；4096 * 256 = 1M</span><br></pre></td></tr></table></figure>
<p>我们可以直接配置 1 个 block，让 block 的线程数为 <code>N</code> 吗？像下面这样：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add&lt;&lt;&lt;1, N&gt;&gt;&gt;(N, x, y);               // 这是不行的，N 超过了每个 block 中的最大线程数的限制</span><br></pre></td></tr></table></figure>
<p>这是不行的。因为每个 block 中的最大线程数是有限制的：</p>
<ol>
<li><strong>当 Compute capability &lt; 2.0 时，每个 block 中的最大线程数为 512；</strong></li>
<li><strong>当 Compute capability &gt;= 2.0 时，每个 block 中的最大线程数为 1024。</strong></li>
</ol>
<h4 id="2-2-5-GPU-版本-3（grid-stride-loop）"><a href="#2-2-5-GPU-版本-3（grid-stride-loop）" class="headerlink" title="2.2.5. GPU 版本 3（grid-stride loop）"></a>2.2.5. GPU 版本 3（grid-stride loop）</h4><p>在上一节介绍的 monolithic kernel 是不灵活的。启动 GPU 线程时，必须指定恰当的 <code>&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;</code> 参数，否则可能出现数组元素没有被处理的情况（这种情况在指定的 numBlocks 太小时可能出现）；此外，当元素规模变得更大时，可能会超过 numBlocks 的最大限制。</p>
<p>这种介绍另外一种更加灵活的 Kernel 函数编写方式——grid-stride loop：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">__global__</span><br><span class="line">void add(int n, float *x, float *y)                      // grid-stride loop</span><br><span class="line">&#123;</span><br><span class="line">    int index = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    int stride = blockDim.x * gridDim.x;</span><br><span class="line">    for (int i = index; i &lt; n; i += stride)</span><br><span class="line">        y[i] = x[i] + y[i];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>grid-stride loop 形式的 kernel 很灵活，其正确性和调用时如何指定线程无关。比如，下面这些调用形式都可以得到正确的结果：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">add&lt;&lt;&lt;1, 256&gt;&gt;&gt;(N, x, y);</span><br><span class="line">add&lt;&lt;&lt;2, 256&gt;&gt;&gt;(N, x, y);</span><br><span class="line">add&lt;&lt;&lt;4096, 256&gt;&gt;&gt;(N, x, y);</span><br><span class="line">add&lt;&lt;&lt;1, 1&gt;&gt;&gt;(N, x, y);</span><br><span class="line">......</span><br></pre></td></tr></table></figure>
<p>下面分别介绍这几种情况。</p>
<p>当使用 <code>add&lt;&lt;&lt;1, 256&gt;&gt;&gt;(N, x, y);</code> 时，共 256 个线程，每个线程处理 4096 个元素，每个线程中各变量如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">blockIdx.x  blockDim.x  threadIdx.x  gridDim.x  index    stride</span><br><span class="line">0           256         0            1          0        256 * 1</span><br><span class="line">0           256         1            1          1        256 * 1</span><br><span class="line">......</span><br><span class="line">0           256         254          1          254      256 * 1</span><br><span class="line">0           256         255          1          255      256 * 1</span><br></pre></td></tr></table></figure>
<p>例如，index 为 0 的线程将对数组下标为 0, 256, 2<em>256, …, 4095</em>256 的元素（共 4096 个）进行处理。</p>
<p>当使用 <code>add&lt;&lt;&lt;2, 256&gt;&gt;&gt;(N, x, y);</code> 共 512 个线程，每个线程处理 2048 个元素，每个线程中各变量如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">blockIdx.x  blockDim.x  threadIdx.x  gridDim.x  index    stride</span><br><span class="line">0           256         0            2          0        256 * 2</span><br><span class="line">0           256         1            2          1        256 * 2</span><br><span class="line">......</span><br><span class="line">0           256         254          2          254      256 * 2</span><br><span class="line">0           256         255          2          255      256 * 2</span><br><span class="line">1           256         0            2          256      256 * 2</span><br><span class="line">1           256         1            2          257      256 * 2</span><br><span class="line">......</span><br><span class="line">1           256         254          2          510      256 * 2</span><br><span class="line">1           256         255          2          511      256 * 2</span><br></pre></td></tr></table></figure>
<p>例如，index 为 0 的线程将对数组下标为 0, 512, 2<em>512, …, 2047</em>512 的元素（共 2048 个）进行处理。</p>
<p>当使用 <code>add&lt;&lt;&lt;4096, 256&gt;&gt;&gt;(N, x, y);</code> 时，共 1M 线程（index 为 515 的线程如图 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org0000024">4</a> 所示，图片摘自 <a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/even-easier-introduction-cuda/">https://developer.nvidia.com/blog/even-easier-introduction-cuda/</a> ），每个线程处理 1 个元素，每个线程中各变量如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">blockIdx.x  blockDim.x  threadIdx.x  gridDim.x  index    stride</span><br><span class="line">0           256         0            4096       0        256 * 4096</span><br><span class="line">0           256         1            4096       1        256 * 4096</span><br><span class="line">......</span><br><span class="line">0           256         254          4096       254      256 * 4096</span><br><span class="line">0           256         255          4096       255      256 * 4096</span><br><span class="line">1           256         0            4096       256      256 * 4096</span><br><span class="line">1           256         1            4096       257      256 * 4096</span><br><span class="line">......</span><br><span class="line">4095        256         254          4096       1048574  256 * 4096</span><br><span class="line">4095        256         255          4096       1048575  256 * 4096</span><br></pre></td></tr></table></figure>
<p><img src="/img/gpu_cuda_indexing.gif" alt="gpu_cuda_indexing.gif"></p>
<p>Figure 4: <code>add&lt;&lt;&lt;4096, 256&gt;&gt;&gt;(N, x, y);</code> 中 index 为 515 的线程</p>
<p>当使用 <code>add&lt;&lt;&lt;1, 1&gt;&gt;&gt;(N, x, y);</code> 时，共 1 个线程，每个线程处理 1M 元素，每个线程中各变量如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">blockIdx.x  blockDim.x  threadIdx.x  gridDim.x  index    stride</span><br><span class="line">0           1           0            1          0        1 * 1</span><br></pre></td></tr></table></figure>
<p>在 <a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/cuda-pro-tip-write-flexible-kernels-grid-stride-loops/">CUDA Pro Tip: Write Flexible Kernels with Grid-Stride Loops</a> 一文中，总结了 grid-stride loop 的几个优点：</p>
<ol>
<li>Scalability and thread reuse. By using a loop, you can support any problem size even if it exceeds the largest grid size your CUDA device supports. Moreover, you can limit the number of blocks you use to tune performance.</li>
<li>Debugging. By using a loop instead of a monolithic kernel, you can easily switch to serial processing by launching one block with one thread. <code>add&lt;&lt;&lt;1, 1&gt;&gt;&gt;(N, x, y);</code> This makes it easier to emulate a serial host implementation to validate results.</li>
<li>Portability and readability. The grid-stride loop code is more like the original sequential loop code than the monolithic kernel code, making it clearer for other users.</li>
</ol>
<h3 id="2-3-Function-Execution-Space-Specifiers"><a href="#2-3-Function-Execution-Space-Specifiers" class="headerlink" title="2.3. Function Execution Space Specifiers"></a>2.3. Function Execution Space Specifiers</h3><p>函数除了用 <code>__global__</code> 修饰外，还可以指定 <code>__device__, __host__</code> ，它们的含义和区别如表 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org000002e">1</a> 所示。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">name</th>
<th style="text-align:left">Executed on the:</th>
<th style="text-align:left">Only callable from the:</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><code>__global__</code></td>
<td style="text-align:left">device</td>
<td style="text-align:left">host</td>
</tr>
<tr>
<td style="text-align:left"><code>__device__</code></td>
<td style="text-align:left">device</td>
<td style="text-align:left">device</td>
</tr>
<tr>
<td style="text-align:left"><code>__host__</code></td>
<td style="text-align:left">host</td>
<td style="text-align:left">host</td>
</tr>
</tbody>
</table>
</div>
<p>所谓 host 就是指 CPU，而 device 就是 GPU。</p>
<p><code>__global__</code> 不能和 <code>__device__</code> 同时使用，也不能和 <code>__host__</code> 同时使用；而 <code>__device__</code> 和 <code>__host__</code> 可以同时使用。</p>
<p>参考：<a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#function-declaration-specifiers">https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#function-declaration-specifiers</a></p>
<h4 id="2-3-1-forceinline-and-noinline"><a href="#2-3-1-forceinline-and-noinline" class="headerlink" title="2.3.1. __forceinline__ and __noinline__"></a>2.3.1. <code>__forceinline__</code> and <code>__noinline__</code></h4><p>当一个函数用 <code>__device__</code> 修饰时，编译器自己会决定是否对该函数进行内联编译。</p>
<p>我们也可以指定 <code>__forceinline__</code> 或者 <code>__noinline__</code> 来强制使用（或者不使用）内联编译。</p>
<h2 id="3-可伸缩的并行执行"><a href="#3-可伸缩的并行执行" class="headerlink" title="3. 可伸缩的并行执行"></a>3. 可伸缩的并行执行</h2><h3 id="3-1-CUDA-线程组织"><a href="#3-1-CUDA-线程组织" class="headerlink" title="3.1. CUDA 线程组织"></a>3.1. CUDA 线程组织</h3><p>一个 Grid 内的所有线程会执行相同的 kernel 函数。</p>
<p>在语法 <code>&lt;&lt;&lt;m, n&gt;&gt;&gt;</code> 中，参数 m 和 n 除了可以是 <code>int</code> 类型外，还可以是 <code>dim3</code> 类型（三维数组）：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dim3 dimGrid(2, 1, 1);</span><br><span class="line">dim3 dimBlock(4, 1, 1);</span><br><span class="line">kernel1&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(...);          // 这相同于 kernel1&lt;&lt;&lt;2, 4&gt;&gt;&gt;(...)</span><br></pre></td></tr></table></figure>
<p>下面我们看一个复杂一些的例子，dimGrid 为 2 x 2 x 1，dimBlock 为 4 x 2 x 2：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dim3 dimGrid(2, 2, 1);</span><br><span class="line">dim3 dimBlock(4, 2, 2);</span><br><span class="line">Kernel1&lt;&lt;&lt;dimGrid, dimBlock&gt;&gt;&gt;(...);</span><br></pre></td></tr></table></figure>
<p>这个例子中，block 共 4 个，表现为二维形式；而 thread 共 8 个，表现为三维形式，如图 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org0000039">5</a> 所示。</p>
<p><img src="/img/gpu_dimgrid_dimblock.png" alt="gpu_dimgrid_dimblock.png"></p>
<p>Figure 5: A multidimensional example of CUDA grid organization.</p>
<p>内置变量 <code>gridDim.x, gridDim.y, gridDim.z</code> 分别保存着 grid 的三个维度的信息，上面例子中，由于 dimGrid 为 2 x 2 x 1，所以有：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">gridDim.x = 2</span><br><span class="line">gridDim.y = 2</span><br><span class="line">gridDim.z = 1</span><br></pre></td></tr></table></figure>
<p>内置变量 <code>blockDim.x, blockDim.y, blockDim.z</code> 分别保存着 block 的三个维度的信息，上面例子中，由于 dimBlock 为 4 x 2 x 2，所以有：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">blockDim.x = 4</span><br><span class="line">blockDim.y = 2</span><br><span class="line">blockDim.z = 2</span><br></pre></td></tr></table></figure>
<p><code>blockIdx.x, blockIdx.y, blockIdx.z</code> 保存着 grid 中当前 block 的下标， <code>threadIdx.x, threadIdx.y, threadIdx.z</code> 保存着 block 中当前 thread 的下标。如果以图 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org0000039">5</a> 中面向读者的右下角那个 thread 为当前 thread，则有：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">blockIdx.x = 1</span><br><span class="line">blockIdx.y = 1</span><br><span class="line">blockIdx.z = 0</span><br><span class="line">threadIdx.x = 0</span><br><span class="line">threadIdx.y = 1</span><br><span class="line">threadIdx.z = 3</span><br></pre></td></tr></table></figure>
<h4 id="3-1-1-各种维度情况下线程的编号"><a href="#3-1-1-各种维度情况下线程的编号" class="headerlink" title="3.1.1. 各种维度情况下线程的编号"></a>3.1.1. 各种维度情况下线程的编号</h4><p>不管采用什么维度的 grid 和 block，我们都可以得到当前 thread 的扁平的全局一维下标：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">// 1D grid of 1D blocks</span><br><span class="line">__device__</span><br><span class="line">int getGlobalIdx_1D_1D()&#123;</span><br><span class="line">    return blockIdx.x *blockDim.x + threadIdx.x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 1D grid of 2D blocks</span><br><span class="line">__device__</span><br><span class="line">int getGlobalIdx_1D_2D()&#123;</span><br><span class="line">    return blockIdx.x * blockDim.x * blockDim.y</span><br><span class="line">        + threadIdx.y * blockDim.x + threadIdx.x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 1D grid of 3D blocks</span><br><span class="line">__device__</span><br><span class="line">int getGlobalIdx_1D_3D()&#123;</span><br><span class="line">    return blockIdx.x * blockDim.x * blockDim.y * blockDim.z</span><br><span class="line">        + threadIdx.z * blockDim.y * blockDim.x</span><br><span class="line">        + threadIdx.y * blockDim.x + threadIdx.x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 2D grid of 1D blocks</span><br><span class="line">__device__ int getGlobalIdx_2D_1D()&#123;</span><br><span class="line">    int blockId = blockIdx.y * gridDim.x + blockIdx.x;</span><br><span class="line">    int threadId = blockId * blockDim.x + threadIdx.x;</span><br><span class="line">    return threadId;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 2D grid of 2D blocks</span><br><span class="line">__device__</span><br><span class="line">int getGlobalIdx_2D_2D()&#123;</span><br><span class="line">    int blockId = blockIdx.x + blockIdx.y * gridDim.x;</span><br><span class="line">    int threadId = blockId * (blockDim.x * blockDim.y)</span><br><span class="line">        + (threadIdx.y * blockDim.x) + threadIdx.x;</span><br><span class="line">    return threadId;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 2D grid of 3D blocks</span><br><span class="line">__device__</span><br><span class="line">int getGlobalIdx_2D_3D()&#123;</span><br><span class="line">    int blockId = blockIdx.x + blockIdx.y * gridDim.x;</span><br><span class="line">    int threadId = blockId * (blockDim.x * blockDim.y * blockDim.z)</span><br><span class="line">        + (threadIdx.z * (blockDim.x * blockDim.y))</span><br><span class="line">        + (threadIdx.y * blockDim.x) + threadIdx.x;</span><br><span class="line">    return threadId;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 3D grid of 1D blocks</span><br><span class="line">__device__</span><br><span class="line">int getGlobalIdx_3D_1D()&#123;</span><br><span class="line">    int blockId = blockIdx.x + blockIdx.y * gridDim.x</span><br><span class="line">        + gridDim.x * gridDim.y * blockIdx.z;</span><br><span class="line">    int threadId = blockId * blockDim.x + threadIdx.x;</span><br><span class="line">    return threadId;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 3D grid of 2D blocks</span><br><span class="line">__device__</span><br><span class="line">int getGlobalIdx_3D_2D()&#123;</span><br><span class="line">    int blockId = blockIdx.x + blockIdx.y * gridDim.x</span><br><span class="line">        + gridDim.x * gridDim.y * blockIdx.z;</span><br><span class="line">    int threadId = blockId * (blockDim.x * blockDim.y)</span><br><span class="line">        + (threadIdx.y * blockDim.x) + threadIdx.x;</span><br><span class="line">    return threadId;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// 3D grid of 3D blocks</span><br><span class="line">__device__</span><br><span class="line">int getGlobalIdx_3D_3D()&#123;</span><br><span class="line">    int blockId = blockIdx.x + blockIdx.y * gridDim.x</span><br><span class="line">        + gridDim.x * gridDim.y * blockIdx.z;</span><br><span class="line">    int threadId = blockId * (blockDim.x * blockDim.y * blockDim.z)</span><br><span class="line">        + (threadIdx.z * (blockDim.x * blockDim.y))</span><br><span class="line">        + (threadIdx.y * blockDim.x) + threadIdx.x;</span><br><span class="line">    return threadId;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>参考：<a target="_blank" rel="noopener" href="https://cs.calvin.edu/courses/cs/374/CUDA/CUDA-Thread-Indexing-Cheatsheet.pdf">https://cs.calvin.edu/courses/cs/374/CUDA/CUDA-Thread-Indexing-Cheatsheet.pdf</a></p>
<h4 id="3-1-2-抽象概念（Grid-Block-Thread）和硬件的映射关系"><a href="#3-1-2-抽象概念（Grid-Block-Thread）和硬件的映射关系" class="headerlink" title="3.1.2. 抽象概念（Grid/Block/Thread）和硬件的映射关系"></a>3.1.2. 抽象概念（Grid/Block/Thread）和硬件的映射关系</h4><p>下面是抽象概念（Grid/Block/Thread）和硬件的映射关系：</p>
<ul>
<li>Grids map to GPUs</li>
<li>Blocks map to the MultiProcessors (MP)</li>
<li>Threads map to Stream Processors (SP)</li>
<li>Warps are groups of (32) threads that execute simultaneously</li>
</ul>
<h3 id="3-2-映射线程到多维数据（RGB-转灰度图片实例）"><a href="#3-2-映射线程到多维数据（RGB-转灰度图片实例）" class="headerlink" title="3.2. 映射线程到多维数据（RGB 转灰度图片实例）"></a>3.2. 映射线程到多维数据（RGB 转灰度图片实例）</h3><p><strong>grid 可以是 1D，2D，3D，block 也可以是 1D，2D，3D，那我们应该如何选择线程的组织形式呢？这往往由待处理数组的结构的决定。</strong> 比如，处理图片时，由于图片是像素点的二维数组，这时采用 2D grid 和 2D block 是个不错的选择。假设，现在要处理图片的像素规模为 x×y=76×62 。我们决定采用 16 x 16 的 2D block，这时 x 方向上至少需要 5 block，而 y 方向上至少需要 4 block，如图 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org0000049">6</a> 所示。</p>
<p><img src="/img/gpu_img_size.gif" alt="gpu_img_size.gif"></p>
<p>Figure 6: Using a 2D thread grid to process a 76 × 62 picture P.</p>
<p>从图 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org0000049">6</a> 中可以看到，在 x 方向上有 4 个多余的线程，在 y 方向上有 2 个多余的线程。在 kernel 函数中通过边界检查让多余线程不执行操作即可。</p>
<p>假设 GPU 任务为 RGB 彩色图片转灰色图片，则可以这样启动 kernel：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">int m = 76;</span><br><span class="line">int n = 62;</span><br><span class="line">dim3 dimGrid(ceil(m/16.0), ceil(n/16.0), 1);      // 5 x 4 x 1</span><br><span class="line">dim3 dimBlock(16, 16, 1);                         // 16 x 16 x 1</span><br><span class="line">colorToGreyscaleConversion&lt;&lt;&lt;dimGrid,dimBlock&gt;&gt;&gt;(d_Pin, d_Pout, m, n);</span><br></pre></td></tr></table></figure>
<p>关键的 kernel，即 colorToGreyscaleConversion 的实现如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">// we have 3 channels corresponding to RGB</span><br><span class="line">// The input image is encoded as unsigned characters [0, 255]</span><br><span class="line">__global__</span><br><span class="line">void colorToGreyscaleConversion(unsigned char * Pout, unsigned</span><br><span class="line">                                char * Pin, int width, int height) &#123;,</span><br><span class="line">    int Col = threadIdx.x + blockIdx.x * blockDim.x;        // threadIdx.x: [0, 15] ，blockIdx.x: [0, 4]，blockDim.x 总是为 16</span><br><span class="line">    int Row = threadIdx.y + blockIdx.y * blockDim.y;        // threadIdx.y: [0, 15] ，blockIdx.y: [0, 3]，blockDim.y 总是为 16</span><br><span class="line">    if (Col &lt; width &amp;&amp; Row &lt; height) &#123;                      // 多余的线程不会通过这个边界检查</span><br><span class="line">        // get 1D coordinate for the grayscale image</span><br><span class="line">        int greyOffset = Row*width + Col;</span><br><span class="line">        // one can think of the RGB image having</span><br><span class="line">        // CHANNEL times columns than the grayscale image</span><br><span class="line">        int rgbOffset = greyOffset*CHANNELS;                // RGB 有 3 个通道，CHANNELS 为 3</span><br><span class="line">        unsigned char r = Pin[rgbOffset ]; // red value for pixel</span><br><span class="line">        unsigned char g = Pin[rgbOffset + 2]; // green value for pixel</span><br><span class="line">        unsigned char b = Pin[rgbOffset + 3]; // blue value for pixel</span><br><span class="line">        // perform the rescaling and store it</span><br><span class="line">        // We multiply by floating point constants</span><br><span class="line">        Pout[grayOffset] = 0.21f*r + 0.71f*g + 0.07f*b;     // RGB 转灰色的公式</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="3-3-图片模糊处理实例"><a href="#3-3-图片模糊处理实例" class="headerlink" title="3.3. 图片模糊处理实例"></a>3.3. 图片模糊处理实例</h3><p>下面看一个更复杂的图片处理例子——图片模糊处理。</p>
<p>图片模糊处理的一种方式就是“把当前像素相邻的几个像素的平均值”作为当前像素的值，如图 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org0000050">7</a> 所示，它取的是 3 x 3 小窗口里的像素的平均值（当然这个小窗口也可以更大，如 5 x 5 或 7 x 7 等）。</p>
<p><img src="/img/gpu_img_blur.gif" alt="gpu_img_blur.gif"></p>
<p>Figure 7: Each output pixel is the average of a patch of pixels in the input image.</p>
<p>下面是图片模糊处理 blurKernel 的实现：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">__global__</span><br><span class="line">void blurKernel(unsigned char * in, unsigned char * out, int w, int h) &#123;</span><br><span class="line">    int Col = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    int Row = threadIdx.y + blockIdx.y * blockDim.y;</span><br><span class="line">    if (Col &lt; w &amp;&amp; Row &lt; h) &#123;</span><br><span class="line">        int pixVal = 0;</span><br><span class="line">        int pixels = 0;</span><br><span class="line"></span><br><span class="line">        // Get the average of the surrounding BLUR_SIZE x BLUE_SIZE box</span><br><span class="line">        for (int blurRow = -BLUR_SIZE; blurRow &lt; BLUR_SIZE + 1; ++blurRow) &#123;</span><br><span class="line">            for (int blurCol = -BLUE_SIZE; blurCol &lt; BLUR_SIZE + 1; ++blurCol) &#123;</span><br><span class="line">                int curRow = Row + blurRow;</span><br><span class="line">                int curCol = Col + blurCol;</span><br><span class="line"></span><br><span class="line">                // Verify we have a valid image pixel</span><br><span class="line">                if (curRow &gt; -1 &amp;&amp; curRow &lt; h &amp;&amp; curCol &gt; -1 &amp;&amp; curCol &lt; w) &#123;</span><br><span class="line">                    pixVal += in[curRow * w + curCol];</span><br><span class="line">                    pixels++; // Key track of number of pixels in the avg</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        // Write our new pixel value out</span><br><span class="line">        out[Row * w + Col] = (unsigned char)(pixVal / pixels);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面代码中，如果计算 3 x 3 小窗口里的像素的平均值（9 个像素点的平均值），则 BLUE_SIZE = 1；如果计算 5 x 5 小窗口里的像素的平均值（25 个像素点的平均值），则 BLUE_SIZE = 2。</p>
<p>需要说明的是，对于角上和边上的像素，其平均值并没有计算 9 个像素点，如图 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org0000052">8</a> 所示。</p>
<p><img src="/img/gpu_img_blur_edge.gif" alt="gpu_img_blur_edge.gif"></p>
<p>Figure 8: 角上仅考虑了 4 个像素点的平均，边上仅考虑了 6 个像素点的平均</p>
<h3 id="3-4-Barrier-Synchronization（限于-block-内）"><a href="#3-4-Barrier-Synchronization（限于-block-内）" class="headerlink" title="3.4. Barrier Synchronization（限于 block 内）"></a>3.4. Barrier Synchronization（限于 block 内）</h3><p><strong>CUDA 中，可以使用函数 <code>__syncthreads()</code> ，让同一个 block 中的线程进行同步。也就是说，当一个线程调用 <code>__syncthreads()</code> 后，它会等待同一个 block 中的所有其它线程都到达 <code>__syncthreads()</code> 所在位置后，才往下执行。</strong></p>
<p>不过，需要注意的是。一个 <code>__syncthreads()</code> 必须被同一个 block 中所有线程都执行，或者都不执行。假设在 <code>if-then-else</code> 语句的 if 和 else 分支中各有一个 <code>__syncthreads()</code> 语句，而同一个 block 中的有些线程执行进入了 if 分支，而另外一些线程进入了 else 分支，那么这个程序会一直等待。</p>
<p>这种同步机制限定在同一个 block 内，也就是说 <strong>block 之间没有任何的依赖和约束，它们可以以任意顺序执行，</strong> 这提供了 Transparent Scalability，如图 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org0000057">9</a> 所示。</p>
<p><img src="/img/gpu_block_no_sync.png" alt="gpu_block_no_sync.png"></p>
<p>Figure 9: Lack of synchronization constraints between blocks enables transparent scalability for CUDA programs.</p>
<h3 id="3-5-Thread-Scheduling"><a href="#3-5-Thread-Scheduling" class="headerlink" title="3.5. Thread Scheduling"></a>3.5. Thread Scheduling</h3><p>Thread 调度属于硬件的实现细节，了解这些实现细节有助于我们进行性能调优。</p>
<p>CUDA 程序一般会创建一些线程块（Block）， <strong>Block 会被调度到空闲的 Streaming Multiprocessors（SM）上去。当 Block 执行完毕后，Block 会退出 SM，释放出 SM 的资源，以供其他待 Block 调度进去。</strong></p>
<p>因此，无论是只有 2 个 SM 的 GPU，还是有 4 个 SM 的 GPU，这些线程块都会被调度执行，只不过 4 个 SM 的 GPU 一般会执行得更快。因此，同样的程序，可以在具有不同 SM 数量上的 GPU 运行，这称为 Automatic Scalability。如图 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org000005c">10</a> 所示。</p>
<p><img src="/img/gpu_automatic_scalability.png" alt="gpu_automatic_scalability.png"></p>
<p>Figure 10: Automatic Scalability</p>
<p>更细节一点， <strong>一个 block 分配给 SM 执行时，还会进一步拆分为 Warp，它是以 32 个 thread 组成的小分组（warpSize 是一个硬件的参数，它往往为 32）。Warp 是 SM 内的线程调度的最小单元。</strong> 假设，一个 block 中共有 256 个线程，则我们可以计算出这个 block 包含 256/32 = 8 个 Warp。</p>
<p>一个 Warp 在执行时，遵循 Single instruction, multiple threads（<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_threads">SIMT</a>）模式。也就是 32 个 thread 会共享“instruction fetching”过程，并不是每个 thread 分别去“instruction fetching”，而是“instruction fetching”后，给 32 个线程都执行。这种方式可以大大减少频繁的“instruction fetching”过程。</p>
<h2 id="4-Memory-and-Data-Locality"><a href="#4-Memory-and-Data-Locality" class="headerlink" title="4. Memory and Data Locality"></a>4. Memory and Data Locality</h2><h3 id="4-1-Memory-Bound-Programs"><a href="#4-1-Memory-Bound-Programs" class="headerlink" title="4.1. Memory-Bound Programs"></a>4.1. Memory-Bound Programs</h3><p>考虑节 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org000004e">3.3</a> 中介绍的图片模糊 kernel 的最核心代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">// Get the average of the surrounding BLUR_SIZE x BLUE_SIZE box</span><br><span class="line">for (int blurRow = -BLUR_SIZE; blurRow &lt; BLUR_SIZE + 1; ++blurRow) &#123;</span><br><span class="line">    for (int blurCol = -BLUE_SIZE; blurCol &lt; BLUR_SIZE + 1; ++blurCol) &#123;</span><br><span class="line">        int curRow = Row + blurRow;</span><br><span class="line">        int curCol = Col + blurCol;</span><br><span class="line"></span><br><span class="line">        // Verify we have a valid image pixel</span><br><span class="line">        if (curRow &gt; -1 &amp;&amp; curRow &lt; h &amp;&amp; curCol &gt; -1 &amp;&amp; curCol &lt; w) &#123;</span><br><span class="line">            pixVal += in[curRow * w + curCol];</span><br><span class="line">            pixels++; // Key track of number of pixels in the avg</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在内层 for 循环的每次迭代中，有 1 次 Global Memory 的访问（即对 <code>in[]</code> 数组的访问），有 1 次浮点数的加法运算（即 <code>pixVal += in[curRow * w + curCol]</code> ）。</p>
<p>我们把“浮点运算次数”和“取内存次数”的比值定义为 compute-to-globalmemory-access ratio (CGMA)，对于上面例子有：<br>浮点运算次数访问次数CGMA=浮点运算次数Global Memory 访问次数=11=1.0</p>
<p>假设 Global memory 的访问速度是 1000 GB/s（即 1 TB/s），考虑单精度浮点数占用 4 个字节，那么每秒可以加载 1000/4=250 giga 浮点数，也就是说 kernel 每秒处理浮点数不会超过 250 GFLOPS。</p>
<p>设某 GPU 的浮点计算性能为 12 TFLOPS，那么运行上面 kernel 时，仅达到浮点计算能力峰值的 2%，没有充分地利用 GPU。像这种，执行速度的 <strong>“瓶颈位于内存访问过程”的程序被称为“memory-bound program”。</strong></p>
<p>后文将介绍如何减少内存的访问次数，以提高程序执行速度。</p>
<h3 id="4-2-矩阵乘法"><a href="#4-2-矩阵乘法" class="headerlink" title="4.2. 矩阵乘法"></a>4.2. 矩阵乘法</h3><p>下面介绍矩阵 M 和 N 相乘得到结果矩阵 P。</p>
<p>假设每个线程仅计算结果矩阵 P 的一个元素，可以使用下面的 kernel 函数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">__global__</span><br><span class="line">void MatrixMulKernel(float* M, float* N, float* P, int Width) &#123;</span><br><span class="line">    // Calculate the row index of the P element and M</span><br><span class="line">    int Row = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line">    // Calculate the column index of P and N</span><br><span class="line">    int Col = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    if ((Row &lt; Width) &amp;&amp; (Col &lt; Width)) &#123;</span><br><span class="line">        float Pvalue = 0;</span><br><span class="line">        // each thread computes one element of the block sub-matrix</span><br><span class="line">        for (int k = 0; k &lt; Width; ++k) &#123;</span><br><span class="line">            Pvalue += M[Row*Width+k] * N[k*Width+Col];</span><br><span class="line">        &#125;</span><br><span class="line">        P[Row*Width+Col] = Pvalue;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个 kernel 和节 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org0000047">3.2</a> 介绍的彩色图片转灰度图片的 colorToGreyscaleConversion 基本类似。kernel 中 Row 和 Col 的如图 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org0000067">11</a> 所示。</p>
<p><img src="/img/gpu_matrix_mul.gif" alt="gpu_matrix_mul.gif"></p>
<p>Figure 11: Row 和 Col 的计算</p>
<p>和彩色图片转灰度图片类似，我们也是采用 2D block。假设矩阵为 4 x 4 的，采用 2 x 2 的 block，那么 kernel 执行如 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org0000069">12</a> 图所示。</p>
<p><img src="/img/gpu_matrix_example.gif" alt="gpu_matrix_example.gif"></p>
<p>Figure 12: MatrixMulKernel 执行示意图</p>
<p>如果仅考虑 block(0,0) 中线程的执行，则如图 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org000006b">13</a> 所示。</p>
<p><img src="/img/gpu_matrix_example_block.png" alt="gpu_matrix_example_block.png"></p>
<p>Figure 13: block(0,0) 中线程的执行</p>
<p>在下面最关键代码中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for (int k = 0; k &lt; Width; ++k) &#123;</span><br><span class="line">    Pvalue += M[Row*Width+k] * N[k*Width+Col];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>有两次 Global memory 的访问，一次浮点乘法和一次浮点加法。所以上一节介绍的 CGMA 值会为 1，这是一个“memory-bound program”，我们需要想办法减少内存的访问次数。</p>
<h3 id="4-3-CUDA-内存类型"><a href="#4-3-CUDA-内存类型" class="headerlink" title="4.3. CUDA 内存类型"></a>4.3. CUDA 内存类型</h3><p>CUDA 设备中有不同的内存类型，可以帮助我们提高 CGMA，以提高程序性能。</p>
<p>CUDA 的内存类型如图 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org0000070">14</a> 所示。</p>
<p><img src="/img/gpu_cuda_memory_types.gif" alt="gpu_cuda_memory_types.gif"></p>
<p>Figure 14: Overview of the CUDA device memory model</p>
<p>通过表 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org0000072">2</a> 所示语法可以声明程序变量位于哪种内存中。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">Variable declaration</th>
<th style="text-align:left">Memory</th>
<th style="text-align:left">Scope</th>
<th style="text-align:left">Lifetime</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Automatic variables other than arrays</td>
<td style="text-align:left">Register</td>
<td style="text-align:left">Thread</td>
<td style="text-align:left">Kernel</td>
</tr>
<tr>
<td style="text-align:left">Automatic array variables</td>
<td style="text-align:left">Local</td>
<td style="text-align:left">Thread</td>
<td style="text-align:left">Kernel</td>
</tr>
<tr>
<td style="text-align:left"><code>__device__ __shared__ int SharedVar;</code></td>
<td style="text-align:left">Shared</td>
<td style="text-align:left">Block</td>
<td style="text-align:left">Kernel</td>
</tr>
<tr>
<td style="text-align:left"><code>__device__ int GlobalVar;</code></td>
<td style="text-align:left">Global</td>
<td style="text-align:left">Grid</td>
<td style="text-align:left">Application</td>
</tr>
<tr>
<td style="text-align:left"><code>__device__ __constant__ int ConstVar;</code></td>
<td style="text-align:left">Constant</td>
<td style="text-align:left">Grid</td>
<td style="text-align:left">Application</td>
</tr>
</tbody>
</table>
</div>
<h3 id="4-4-矩阵相乘优化（Tile-优化）"><a href="#4-4-矩阵相乘优化（Tile-优化）" class="headerlink" title="4.4. 矩阵相乘优化（Tile 优化）"></a>4.4. 矩阵相乘优化（Tile 优化）</h3><p>如何减少矩阵相乘时对 Global memory 的访问呢？我们先看看图 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org000006b">13</a> 的情况。</p>
<p>block(0,0) 中的 4 个线程读取 Global memory 的情况如图 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org0000077">15</a> 所示。可以发现：Global memory 中的数据被读取了多次。</p>
<p><img src="/img/gpu_matrix_block00.png" alt="gpu_matrix_block00.png"></p>
<p>Figure 15: block(0,0) 线程读取内存的情况</p>
<p><strong>如果同一个 block 中的线程仅从 Global memory 中读取输入矩阵一次，放入到 Shared memory 中，则可以减少对 Global memory 的访问，以提高程序性能。</strong></p>
<p>这种优化被为 Tile 优化。下面是一个采用 Tile 优化的矩阵相乘的 kernel 函数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">__global__</span><br><span class="line">void MatrixMulKernel(float* d_M, float* d_N, float* d_P,</span><br><span class="line">                     int Width) &#123;</span><br><span class="line">    __shared__ float Mds[TILE_WIDTH][TILE_WIDTH];  // 后面会把 d_M 数据（Global memory）先保存到Shared memory 中</span><br><span class="line">    __shared__ float Nds[TILE_WIDTH][TILE_WIDTH];  // 后面会把 d_M 数据（Global memory）先保存到Shared memory 中</span><br><span class="line"></span><br><span class="line">    int bx = blockIdx.x; int by = blockIdx.y;</span><br><span class="line">    int tx = threadIdx.x; int ty = threadIdx.y;</span><br><span class="line">    // Identify the row and column of the d_P element to work on</span><br><span class="line">    int Row = by * TILE_WIDTH + ty;</span><br><span class="line">    int Col = bx * TILE_WIDTH + tx;</span><br><span class="line">    float Pvalue = 0;</span><br><span class="line">    // Loop over the d_M and d_N tiles required to compute d_P element</span><br><span class="line">    for (int ph = 0; ph &lt; Width/TILE_WIDTH; ++ph) &#123;</span><br><span class="line">        // Collaborative loading of d_M and d_N tiles into shared memory</span><br><span class="line">        Mds[ty][tx] = d_M[Row*Width + ph*TILE_WIDTH + tx];</span><br><span class="line">        Nds[ty][tx] = d_N[(ph*TILE_WIDTH + ty)*Width + Col];</span><br><span class="line">        __syncthreads();     // 确保当每个线程需要的数据被不同线程加载到 Shared memory 中后，同 block 中的线程才往下执行</span><br><span class="line">        for (int k = 0; k &lt; TILE_WIDTH; ++k) &#123;</span><br><span class="line">            Pvalue += Mds[ty][k] * Nds[k][tx];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();     // 确保当所有线程都执行完上面的计算后，同 block 中的线程才往下执行</span><br><span class="line">    &#125;</span><br><span class="line">    d_P[Row*Width + Col] = Pvalue;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="5-Unified-Memory"><a href="#5-Unified-Memory" class="headerlink" title="5. Unified Memory"></a>5. Unified Memory</h2><p>CUDA 6 中引入了 Unified Memory，不用显式地使用 <code>cudaMemcpy</code> 在 Host 和 Device 之间复制内存了，简化了编程步骤，如图 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org000007f">16</a> 所示。</p>
<p><img src="/img/gpu_cuda_6_unified_memory.gif" alt="gpu_cuda_6_unified_memory.gif"></p>
<p>Figure 16: CUDA 6 Unified Memory</p>
<p>摘自：<a target="_blank" rel="noopener" href="https://developer.nvidia.com/blog/unified-memory-in-cuda-6/">Unified Memory in CUDA 6</a></p>
<h2 id="6-并行计算模式"><a href="#6-并行计算模式" class="headerlink" title="6. 并行计算模式"></a>6. 并行计算模式</h2><p>在《Programming Massively Parallel Processors, 3rd, 2017》一书介绍了一些并行计算模式，如：Convolution、Prefix Sum、Histogram、Sparse Matrix Computation、Merge Sort、Graph Search。</p>
<p>这里不介绍它们，有兴趣的读者可以参考原著。</p>
<h2 id="7-Compute-Capability"><a href="#7-Compute-Capability" class="headerlink" title="7. Compute Capability"></a>7. Compute Capability</h2><p>CUDA 的计算能力 Compute Capability 可以认为是硬件的版本。表 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org0000087">3</a> 列出了不同 Compute Capability 下的一些产品型号。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:right">Compute Capability</th>
<th style="text-align:left">Micro-architecture</th>
<th style="text-align:left">GeForce（消费级）</th>
<th style="text-align:left">Quadro（专业级）</th>
<th style="text-align:left">Tesla（数据中心）</th>
<th style="text-align:left">Jetson（嵌入式）</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">1.0</td>
<td style="text-align:left">Tesla</td>
<td style="text-align:left">GeForce 8800 GTX</td>
<td style="text-align:left">Quadro FX 5600</td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:right">2.0</td>
<td style="text-align:left">Fermi</td>
<td style="text-align:left">GeForce GTX 590</td>
<td style="text-align:left">Quadro Plex 7000</td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:right">3.0</td>
<td style="text-align:left">Kepler</td>
<td style="text-align:left">GeForce GTX 770</td>
<td style="text-align:left">Quadro K5000</td>
<td style="text-align:left">Tesla K10</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:right">3.2</td>
<td style="text-align:left">Kepler</td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:right">3.5</td>
<td style="text-align:left">Kepler</td>
<td style="text-align:left">GeForce GTX TITAN Z</td>
<td style="text-align:left">Quadro K6000</td>
<td style="text-align:left">Tesla K40, Tesla K20</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:right">3.7</td>
<td style="text-align:left">Kepler</td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
<td style="text-align:left">Tesla K80</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:right">5.0</td>
<td style="text-align:left">Maxwell</td>
<td style="text-align:left">GeForce GTX 750</td>
<td style="text-align:left">Quadro K1200</td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:right">5.2</td>
<td style="text-align:left">Maxwell</td>
<td style="text-align:left">GeForce GTX TITAN X</td>
<td style="text-align:left">Quadro M5000</td>
<td style="text-align:left">Tesla M60, Tesla M40</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:right">5.3</td>
<td style="text-align:left">Maxwell</td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
<td style="text-align:left">Jetson TX1, Tegra X1</td>
</tr>
<tr>
<td style="text-align:right">6.0</td>
<td style="text-align:left">Pascal</td>
<td style="text-align:left"></td>
<td style="text-align:left">Quadro GP100</td>
<td style="text-align:left">Tesla P100</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:right">6.1</td>
<td style="text-align:left">Pascal</td>
<td style="text-align:left">GeForce GTX 1080</td>
<td style="text-align:left">Quadro P6000</td>
<td style="text-align:left">Tesla P40, Tesla P4</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:right">6.2</td>
<td style="text-align:left">Pascal</td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
<td style="text-align:left">Jetson TX2</td>
</tr>
<tr>
<td style="text-align:right">7.0</td>
<td style="text-align:left">Volta</td>
<td style="text-align:left">NVIDIA TITAN V</td>
<td style="text-align:left">Quadro GV100</td>
<td style="text-align:left">Tesla V100</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:right">7.2</td>
<td style="text-align:left">Volta</td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
<td style="text-align:left">Jetson AGX Xavier</td>
</tr>
<tr>
<td style="text-align:right">7.5</td>
<td style="text-align:left">Turing</td>
<td style="text-align:left">Geforce RTX 2080</td>
<td style="text-align:left">Quadro RTX 8000</td>
<td style="text-align:left">Tesla T4</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:right">8.0</td>
<td style="text-align:left">Ampere</td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
<td style="text-align:left"></td>
</tr>
</tbody>
</table>
</div>
<p>不同 Compute Capability 的区别可以参考：<a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities">https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#compute-capabilities</a></p>
<h2 id="8-开发工具"><a href="#8-开发工具" class="headerlink" title="8. 开发工具"></a>8. 开发工具</h2><h3 id="8-1-nvcc"><a href="#8-1-nvcc" class="headerlink" title="8.1. nvcc"></a>8.1. nvcc</h3><p><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html">nvcc</a> 是 CUDA 编程器，在节 <a target="_blank" rel="noopener" href="http://aandds.com/blog/parallel-computing.html#org0000007">2.1</a> 中介绍了它的基本用法。</p>
<h3 id="8-2-nvprof"><a href="#8-2-nvprof" class="headerlink" title="8.2. nvprof"></a>8.2. nvprof</h3><p><a target="_blank" rel="noopener" href="https://docs.nvidia.com/cuda/profiler-users-guide/index.html#nvprof-overview">nvprof</a> 是对 CUDA 程序进行性能瓶颈分析的工具。</p>
<p>下面是使用 <code>nvprof</code> 对矩阵相乘 CUDA 程序进行分析的例子：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">$ nvprof matrixMul</span><br><span class="line">[Matrix Multiply Using CUDA] - Starting...</span><br><span class="line">==27694== NVPROF is profiling process 27694, command: matrixMul</span><br><span class="line">GPU Device 0: &quot;GeForce GT 640M LE&quot; with compute capability 3.0</span><br><span class="line"></span><br><span class="line">MatrixA(320,320), MatrixB(640,320)</span><br><span class="line">Computing result using CUDA Kernel...</span><br><span class="line">done</span><br><span class="line">Performance= 35.35 GFlop/s, Time= 3.708 msec, Size= 131072000 Ops, WorkgroupSize= 1024 threads/block</span><br><span class="line">Checking computed result for correctness: OK</span><br><span class="line"></span><br><span class="line">Note: For peak performance, please refer to the matrixMulCUBLAS example.</span><br><span class="line">==27694== Profiling application: matrixMul</span><br><span class="line">==27694== Profiling result:</span><br><span class="line">Time(%)      Time     Calls       Avg       Min       Max  Name</span><br><span class="line"> 99.94%  1.11524s       301  3.7051ms  3.6928ms  3.7174ms  void matrixMulCUDA&lt;int=32&gt;(float*, float*, float*, int, int)</span><br><span class="line">  0.04%  406.30us         2  203.15us  136.13us  270.18us  [CUDA memcpy HtoD]</span><br><span class="line">  0.02%  248.29us         1  248.29us  248.29us  248.29us  [CUDA memcpy DtoH]</span><br><span class="line"></span><br><span class="line">==27964== API calls:</span><br><span class="line">Time(%)      Time     Calls       Avg       Min       Max  Name</span><br><span class="line"> 49.81%  285.17ms         3  95.055ms  153.32us  284.86ms  cudaMalloc</span><br><span class="line"> 25.95%  148.57ms         1  148.57ms  148.57ms  148.57ms  cudaEventSynchronize</span><br><span class="line"> 22.23%  127.28ms         1  127.28ms  127.28ms  127.28ms  cudaDeviceReset</span><br><span class="line">  1.33%  7.6314ms       301  25.353us  23.551us  143.98us  cudaLaunch</span><br><span class="line">  0.25%  1.4343ms         3  478.09us  155.84us  984.38us  cudaMemcpy</span><br><span class="line">  0.11%  601.45us         1  601.45us  601.45us  601.45us  cudaDeviceSynchronize</span><br><span class="line">  0.10%  564.48us      1505     375ns     313ns  3.6790us  cudaSetupArgument</span><br><span class="line">  0.09%  490.44us        76  6.4530us     307ns  221.93us  cuDeviceGetAttribute</span><br><span class="line">  0.07%  406.61us         3  135.54us  115.07us  169.99us  cudaFree</span><br><span class="line">  0.02%  143.00us       301     475ns     431ns  2.4370us  cudaConfigureCall</span><br><span class="line">  0.01%  42.321us         1  42.321us  42.321us  42.321us  cuDeviceTotalMem</span><br><span class="line">  0.01%  33.655us         1  33.655us  33.655us  33.655us  cudaGetDeviceProperties</span><br><span class="line">  0.01%  31.900us         1  31.900us  31.900us  31.900us  cuDeviceGetName</span><br><span class="line">  0.00%  21.874us         2  10.937us  8.5850us  13.289us  cudaEventRecord</span><br><span class="line">  0.00%  16.513us         2  8.2560us  2.6240us  13.889us  cudaEventCreate</span><br><span class="line">  0.00%  13.091us         1  13.091us  13.091us  13.091us  cudaEventElapsedTime</span><br><span class="line">  0.00%  8.1410us         1  8.1410us  8.1410us  8.1410us  cudaGetDevice</span><br><span class="line">  0.00%  2.6290us         2  1.3140us     509ns  2.1200us  cuDeviceGetCount</span><br><span class="line">  0.00%  1.9970us         2     998ns     520ns  1.4770us  cuDeviceGet</span><br></pre></td></tr></table></figure>
<h3 id="8-3-nvidia-smi"><a href="#8-3-nvidia-smi" class="headerlink" title="8.3. nvidia-smi"></a>8.3. nvidia-smi</h3><p><a target="_blank" rel="noopener" href="https://developer.download.nvidia.cn/compute/DCGM/docs/nvidia-smi-367.38.pdf">nvidia-smi</a> (NVIDIA System Management Interface) 是管理 NVIDIA GPU 设备的命令行工具。可以监控 GPU 使用情况以及更改 GPU 状态。</p>
<p>下面是 nvidia-smi 的运行例子，输出中 GPU-Util 为 100% 表示 GPU 正在满负载工作。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ nvidia-smi</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|===============================+======================+======================|</span><br><span class="line">|   0  Tesla P4            On   | 00000000:00:08.0 Off |                    0 |</span><br><span class="line">| N/A   59C    P0    47W /  75W |   1399MiB /  7611MiB |    100%      Default |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line"></span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                       GPU Memory |</span><br><span class="line">|  GPU       PID   Type   Process name                             Usage      |</span><br><span class="line">|=============================================================================|</span><br><span class="line">|    0     22589      C   ./test                                      1389MiB |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>
<h2 id="9-参考"><a href="#9-参考" class="headerlink" title="9. 参考"></a>9. 参考</h2><p>本文主要考虑</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/%E7%A7%AF%E7%B4%AF/" rel="tag"># 积累</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2023/01/04/HIP%E7%BC%96%E7%A8%8B/" rel="next" title="HIP编程">
                <i class="fa fa-chevron-left"></i> HIP编程
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2023/04/10/cpp%E9%AB%98%E6%80%A7%E8%83%BD%E7%BC%96%E7%A8%8B%E5%AE%9E%E6%88%98/" rel="prev" title="C++ 高性能编程实战">
                C++ 高性能编程实战 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name"></p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%20%7C%7C%20archive">
              
                  <span class="site-state-item-count">130</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-GPU-%E7%AE%80%E4%BB%8B"><span class="nav-number">1.</span> <span class="nav-text">1. GPU 简介</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-CUDA-C-%E7%BC%96%E7%A8%8B"><span class="nav-number">2.</span> <span class="nav-text">2. CUDA C 编程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-Hello-World"><span class="nav-number">2.1.</span> <span class="nav-text">2.1. Hello World</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-%E5%AE%9E%E4%BE%8B%EF%BC%9A%E6%95%B0%E7%BB%84%E7%9B%B8%E5%8A%A0"><span class="nav-number">2.2.</span> <span class="nav-text">2.2. 实例：数组相加</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-1-CPU-%E7%89%88%E6%9C%AC"><span class="nav-number">2.2.1.</span> <span class="nav-text">2.2.1. CPU 版本</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-2-%E6%94%B9%E9%80%A0%E4%B8%BA-GPU-%E7%89%88%E6%9C%AC"><span class="nav-number">2.2.2.</span> <span class="nav-text">2.2.2. 改造为 GPU 版本</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-3-%E7%BA%BF%E7%A8%8B%E7%BB%93%E6%9E%84-lt-lt-lt-numBlocks-threadsPerBlock-gt-gt-gt"><span class="nav-number">2.2.3.</span> <span class="nav-text">2.2.3. 线程结构 &lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-4-GPU-%E7%89%88%E6%9C%AC-2%EF%BC%88monolithic-kernel%EF%BC%89"><span class="nav-number">2.2.4.</span> <span class="nav-text">2.2.4. GPU 版本 2（monolithic kernel）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-2-5-GPU-%E7%89%88%E6%9C%AC-3%EF%BC%88grid-stride-loop%EF%BC%89"><span class="nav-number">2.2.5.</span> <span class="nav-text">2.2.5. GPU 版本 3（grid-stride loop）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-Function-Execution-Space-Specifiers"><span class="nav-number">2.3.</span> <span class="nav-text">2.3. Function Execution Space Specifiers</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-3-1-forceinline-and-noinline"><span class="nav-number">2.3.1.</span> <span class="nav-text">2.3.1. __forceinline__ and __noinline__</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-%E5%8F%AF%E4%BC%B8%E7%BC%A9%E7%9A%84%E5%B9%B6%E8%A1%8C%E6%89%A7%E8%A1%8C"><span class="nav-number">3.</span> <span class="nav-text">3. 可伸缩的并行执行</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-1-CUDA-%E7%BA%BF%E7%A8%8B%E7%BB%84%E7%BB%87"><span class="nav-number">3.1.</span> <span class="nav-text">3.1. CUDA 线程组织</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-1-%E5%90%84%E7%A7%8D%E7%BB%B4%E5%BA%A6%E6%83%85%E5%86%B5%E4%B8%8B%E7%BA%BF%E7%A8%8B%E7%9A%84%E7%BC%96%E5%8F%B7"><span class="nav-number">3.1.1.</span> <span class="nav-text">3.1.1. 各种维度情况下线程的编号</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-1-2-%E6%8A%BD%E8%B1%A1%E6%A6%82%E5%BF%B5%EF%BC%88Grid-Block-Thread%EF%BC%89%E5%92%8C%E7%A1%AC%E4%BB%B6%E7%9A%84%E6%98%A0%E5%B0%84%E5%85%B3%E7%B3%BB"><span class="nav-number">3.1.2.</span> <span class="nav-text">3.1.2. 抽象概念（Grid&#x2F;Block&#x2F;Thread）和硬件的映射关系</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-%E6%98%A0%E5%B0%84%E7%BA%BF%E7%A8%8B%E5%88%B0%E5%A4%9A%E7%BB%B4%E6%95%B0%E6%8D%AE%EF%BC%88RGB-%E8%BD%AC%E7%81%B0%E5%BA%A6%E5%9B%BE%E7%89%87%E5%AE%9E%E4%BE%8B%EF%BC%89"><span class="nav-number">3.2.</span> <span class="nav-text">3.2. 映射线程到多维数据（RGB 转灰度图片实例）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-3-%E5%9B%BE%E7%89%87%E6%A8%A1%E7%B3%8A%E5%A4%84%E7%90%86%E5%AE%9E%E4%BE%8B"><span class="nav-number">3.3.</span> <span class="nav-text">3.3. 图片模糊处理实例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-4-Barrier-Synchronization%EF%BC%88%E9%99%90%E4%BA%8E-block-%E5%86%85%EF%BC%89"><span class="nav-number">3.4.</span> <span class="nav-text">3.4. Barrier Synchronization（限于 block 内）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-5-Thread-Scheduling"><span class="nav-number">3.5.</span> <span class="nav-text">3.5. Thread Scheduling</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-Memory-and-Data-Locality"><span class="nav-number">4.</span> <span class="nav-text">4. Memory and Data Locality</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#4-1-Memory-Bound-Programs"><span class="nav-number">4.1.</span> <span class="nav-text">4.1. Memory-Bound Programs</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-2-%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95"><span class="nav-number">4.2.</span> <span class="nav-text">4.2. 矩阵乘法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-3-CUDA-%E5%86%85%E5%AD%98%E7%B1%BB%E5%9E%8B"><span class="nav-number">4.3.</span> <span class="nav-text">4.3. CUDA 内存类型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-4-%E7%9F%A9%E9%98%B5%E7%9B%B8%E4%B9%98%E4%BC%98%E5%8C%96%EF%BC%88Tile-%E4%BC%98%E5%8C%96%EF%BC%89"><span class="nav-number">4.4.</span> <span class="nav-text">4.4. 矩阵相乘优化（Tile 优化）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-Unified-Memory"><span class="nav-number">5.</span> <span class="nav-text">5. Unified Memory</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E6%A8%A1%E5%BC%8F"><span class="nav-number">6.</span> <span class="nav-text">6. 并行计算模式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-Compute-Capability"><span class="nav-number">7.</span> <span class="nav-text">7. Compute Capability</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7"><span class="nav-number">8.</span> <span class="nav-text">8. 开发工具</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#8-1-nvcc"><span class="nav-number">8.1.</span> <span class="nav-text">8.1. nvcc</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-2-nvprof"><span class="nav-number">8.2.</span> <span class="nav-text">8.2. nvprof</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-3-nvidia-smi"><span class="nav-number">8.3.</span> <span class="nav-text">8.3. nvidia-smi</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-%E5%8F%82%E8%80%83"><span class="nav-number">9.</span> <span class="nav-text">9. 参考</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hao Yu</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
