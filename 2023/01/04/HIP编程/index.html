<!DOCTYPE html>
<html lang="zn-ch">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="什么是rocm？Radeon Open Computing platform 全套驱动程序，开发工具，API和AMD GPU监控工具的集合。用来支持AMD的GPU以及其他现有的加速器。 CUDA到HIP转码CUDA与HIPCUDA是NVIDIA开发的GPU SDK（软件开发框架），主要针对NVIDIA GPU硬件开发，而HIP是AMD开发的GPU SDK，主要是针对AMD GPU硬件开发，同时兼容">
<meta property="og:type" content="article">
<meta property="og:title" content="HIP编程">
<meta property="og:url" content="http://yoursite.com/2023/01/04/HIP%E7%BC%96%E7%A8%8B/index.html">
<meta property="og:site_name" content="Hao Yu&#39;s blog">
<meta property="og:description" content="什么是rocm？Radeon Open Computing platform 全套驱动程序，开发工具，API和AMD GPU监控工具的集合。用来支持AMD的GPU以及其他现有的加速器。 CUDA到HIP转码CUDA与HIPCUDA是NVIDIA开发的GPU SDK（软件开发框架），主要针对NVIDIA GPU硬件开发，而HIP是AMD开发的GPU SDK，主要是针对AMD GPU硬件开发，同时兼容">
<meta property="og:locale" content="zn_CH">
<meta property="og:image" content="http://yoursite.com/img/1794499-20200417143326110-1808551587.png">
<meta property="og:image" content="http://yoursite.com/img/1794499-20200417143351557-2115965778.png">
<meta property="og:image" content="http://yoursite.com/img/1794499-20200424150554626-204754530.png">
<meta property="og:image" content="http://yoursite.com/img/1794499-20200424110629946-2145566218.png">
<meta property="og:image" content="http://yoursite.com/img/copycode.gif">
<meta property="og:image" content="http://yoursite.com/img/1794499-20200424140453323-1505101520.png">
<meta property="og:image" content="http://yoursite.com/img/1794499-20200424145857004-435911930.png">
<meta property="og:image" content="http://yoursite.com/img/1794499-20200424150302330-1828113155.png">
<meta property="article:published_time" content="2023-01-04T06:59:00.000Z">
<meta property="article:modified_time" content="2023-01-05T15:19:59.000Z">
<meta property="article:author" content="Hao Yu">
<meta property="article:tag" content="积累">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/img/1794499-20200417143326110-1808551587.png">

<link rel="canonical" href="http://yoursite.com/2023/01/04/HIP%E7%BC%96%E7%A8%8B/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zn-ch'
  };
</script>

  <title>HIP编程 | Hao Yu's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hao Yu's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">The program monkey was eaten by the siege lion.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/resume.pdf" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags<span class="badge">11</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives<span class="badge">128</span></a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>Schedule</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zn-ch">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2023/01/04/HIP%E7%BC%96%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Hao Yu">
      <meta itemprop="description" content="Introduce something interesting and recode learning process, some articles are written by others, the original link has been given as much as possible, thanks to the original author">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hao Yu's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          HIP编程
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-01-04 14:59:00" itemprop="dateCreated datePublished" datetime="2023-01-04T14:59:00+08:00">2023-01-04</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-01-05 23:19:59" itemprop="dateModified" datetime="2023-01-05T23:19:59+08:00">2023-01-05</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="什么是rocm？"><a href="#什么是rocm？" class="headerlink" title="什么是rocm？"></a>什么是rocm？</h1><p>Radeon Open Computing platform 全套驱动程序，开发工具，API和AMD GPU监控工具的集合。用来支持AMD的GPU以及其他现有的加速器。</p>
<h1 id="CUDA到HIP转码"><a href="#CUDA到HIP转码" class="headerlink" title="CUDA到HIP转码"></a>CUDA到HIP转码</h1><h2 id="CUDA与HIP"><a href="#CUDA与HIP" class="headerlink" title="CUDA与HIP"></a>CUDA与HIP</h2><p>CUDA是NVIDIA开发的GPU SDK（软件开发框架），主要针对NVIDIA GPU硬件开发，而HIP是AMD开发的GPU SDK，主要是针对AMD GPU硬件开发，同时兼容NVIDIA GPU硬件上的开发。试想AMD为何会如此雄心壮志？其实是无奈之举。显然当今CUDA的生态处于绝对优势（dominant），AMD要想迎头赶上，必须兼容CUDA。如何实现兼容CUDA？答案就是利用HIP。</p>
<p>HIP（Heterogeneous-Computing Interface for Portability）实际上就是构造异构计算的接口，一方面对接AMD HCC（Heterogeneous Compute Compiler），另一方面对接CUDA NVCC。HIP位于HCC和NVCC的上层（或者说在HC和CUDA的上层），HIP的API接口与CUDA API接口类似，但不完全相同。CUDA代码需要通过转码改写为HIP形式才可以在AMD GPU上编译运行，AMD编译环境称为ROCm（Radeon Open Compute Platform），早期使用HCC/HC模式，而今主要发展基于Clang和LLVM开发的编译器，实际上命令行在Clang模式下，hcc就是alias到clang命令。我们都知道Clang+LLVM是一个开源的编译器框架，除了支持C/C++编译，也支持<a href="https://llvm.org/docs/CompileCudaWithLLVM.html#compiling-cuda-code">CUDA的编译</a>。AMD将Clang+LLVM进行扩展形成HIP的底层编译器，以支持AMD GPU编译。实际上在ROCm环境，HIP有三种平台模式（通过环境变量HIP_PLATFORM区别）：clang、hcc和nvcc。而HIP提供的hipcc命令，实质是一个perl脚本，通过HIP_PLATFORM等环境变量，调用不同的底层编译器，实现统一编译模式。</p>
<h2 id="HIP转码的实现"><a href="#HIP转码的实现" class="headerlink" title="HIP转码的实现"></a>HIP转码的实现</h2><p>如果你留意，可以发现ROCm的HIP项目中提供了一个<a href="https://github.com/ROCm-Developer-Tools/HIP/tree/master/hipify-clang">hipify-clang</a>的工具。这个hipify-clang工具是基于Clang编译器的<a href="https://clang.llvm.org/docs/IntroductionToTheClangAST.html">抽象语法树</a>和<a href="https://clang.llvm.org/docs/RefactoringEngine.html">重构引擎</a>机制，实现CUDA到HIP的API函数名和type名的重命名和include头文件名的替换（详见下一节分析），理论上是最可靠的一种代码转换方式。因为字面意思的文本转换难以区分API语义，如分别函数名还是参数名。</p>
<p>hipify-clang从根本上可以解决CUDA到HIP的转码，但不等于说没有困难，困难在于CUDA的版本很多，各版本之间也有不兼容的API问题，而且CUDA少量函数或变量名，在HIP底层并没有实现对应体。</p>
<p>但总的来说，AMD的伙计们还是很给力，不断在更新hipify-clang，也支持最新CUDA 10.1的API转换。基于hipify-clang工具还可以生成perl转码的map文件或python转码的map文件，这里的map文件实质就是转码函数或变量名的映射代码行。一般hipify-clang是随着ROCm环境一起安装的，没法及时更新。导致hipify-clang的新功能没法应用。</p>
<p>HIP项目的<a href="https://github.com/ROCm-Developer-Tools/HIP/tree/master/bin">bin目录</a>中提供了一个名为hipify-perl的可执行的脚本，借助perl语言定义了CUDA到HIP转码的主体框架以及转换名称的map内容，这个map内容实际上是由hipify-clang工具生成。更新了hipify-clang工具，也应该更新hipify-perl脚本。但hipify-clang工具需要Clang+LLVM的SDK环境，这是一个较复杂的开发软件环境，一般用户难以驾驭，导致编译hipify-clang有困难。不过，本项目中直接提供了最新的hipify-perl脚本。</p>
<h2 id="hipify-clang代码简介"><a href="#hipify-clang代码简介" class="headerlink" title="hipify-clang代码简介"></a>hipify-clang代码简介</h2><p><a href="https://github.com/ROCm-Developer-Tools/HIP/tree/master/hipify-clang">hipify-clang</a>作为HIP的一个子模块而存在，官方代码文件见 <a href="https://github.com/ROCm-Developer-Tools/HIP/tree/master/hipify-clang">https://github.com/ROCm-Developer-Tools/HIP/tree/master/hipify-clang</a> ，理解其需要一些Clang和LLVM知识背景。相关代码文件简介如下：</p>
<ul>
<li><p><strong>main.cpp</strong> 入口函数main的定义文件。<br>首先完成命令行参数解析，支持Perl和Python的map导出（见其中的generatePerl和generatePython两个函数），对每个输入待转码的文件，会创建RefactoringTool和actionFactory对象，并填充相应的Clang RefactoringTool的工作参数，最终构建出Clang refactoring的基本框架，核心在于执行<code>Tool.runAndSave(&amp;actionFactory)</code>启动整个重构的工作流程，其中会调用重载的HipifyAction类中定义的转码函数。</p>
</li>
<li><p><strong>ArgParse.cpp/.h</strong> 定义命令行参数的解析。<br>在main函数中被调用。</p>
</li>
<li><p><strong>ReplacementsFrontendActionFactory.h</strong> 定义一个基于<code>clang::tooling::FrontendActionFactory</code>的工厂类。<br>main中实例化为对象actionFactory，供<code>Tool.runAndSave</code>函数调用。</p>
</li>
<li><p><strong>LLVMCompat.cpp/.h</strong> 新建了命令空间llcompat和定义版本兼容函数。<br>其中定义兼容不同版本的各类函数，包括SourceLocation的begin和end定位函数、getReplacements函数、insertReplacement函数和EnterPreprocessorTokenStream函数等等。</p>
</li>
<li><p><strong>CUDA2HIP.cpp/.h</strong> 定义转码映射关系对象。<br>定义了两个<code>std::map&lt;llvm::StringRef, hipCounter&gt;</code>类型的数据对象CUDA_RENAMES_MAP和CUDA_INCLUDE_MAP。在CUDA到HIP转码时，函数名和type名的转码映射关系定义在CUDA_RENAMES_MAP中，它们又由CUDA2HIP_XXX_API_functions.cpp和CUDA2HIP_XXX_API_types.cpp中定义的子类map组合而来。<br> 头文件名替换映射关系定义在CUDA_INCLUDE_MAP中。</p>
</li>
<li><p><strong>HipifyAction.cpp/.h</strong> 定义了HipifyAction类。<br>HipifyAction类继承了<code>clang::ASTFrontendAction</code>和<code>clang::ast_matchers::MatchFinder::MatchCallback</code>接口，实现基于Clang前端解析重命名机制的行为。这里是实现转码的重心之处。函数名和type名转码的重命名操作在RewriteToken函数中完成。HipifyAction的关键函数体结构为</p>
</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">HipifyAction::ExecuteAction</span><span class="params">()</span> </span>&#123; <span class="comment">//重载ASTFrontendAction的接口函数</span></span><br><span class="line"> <span class="keyword">while</span> (RawTok.<span class="built_in">isNot</span>(clang::tok::eof)) &#123;</span><br><span class="line">    <span class="built_in">RewriteToken</span>(RawTok); <span class="comment">//调用自定义函数，执行CUDA_RENAMES_MAP替换。</span></span><br><span class="line">    RawLex.<span class="built_in">LexFromRawLexer</span>(RawTok);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Register yourself as the preprocessor callback, by proxy.</span></span><br><span class="line">  <span class="comment">// 自定义预处理阶段的回调函数，跳转调用hipifyAction的InclusionDirective和PragmaDirective函数</span></span><br><span class="line">  <span class="comment">// InclusionDirective函数完成CUDA_INCLUDE_MAP替换。</span></span><br><span class="line">  PP.<span class="built_in">addPPCallbacks</span>(std::<span class="built_in">unique_ptr</span>&lt;PPCallbackProxy&gt;(<span class="keyword">new</span> <span class="built_in">PPCallbackProxy</span>(*<span class="keyword">this</span>)));</span><br><span class="line">  <span class="comment">// Now we&#x27;re done futzing with the lexer, have the subclass proceeed with Sema and AST matching.</span></span><br><span class="line">  clang::ASTFrontendAction::<span class="built_in">ExecuteAction</span>();<span class="comment">//完成基类的操作</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">HipifyAction::run</span><span class="params">(<span class="type">const</span> clang::ast_matchers::MatchFinder::MatchResult&amp; Result)</span> </span>&#123;<span class="comment">//重载MatchCallback的接口函数</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">cudaLaunchKernel</span>(Result)) <span class="keyword">return</span>; <span class="comment">//调用自定义函数</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">cudaSharedIncompleteArrayVar</span>(Result)) <span class="keyword">return</span>;<span class="comment">//调用自定义函数</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p> 其中cudaLaunchKernel实现CUDA <code>kernel&lt;&lt;&lt;*&gt;&gt;&gt;</code> 函数的替换。cudaSharedIncompleteArrayVar实现 CUDA <code>__shared__</code>变量定义的重构，即添加HIP_DYNAMIC_SHARED宏包装。</p>
<ul>
<li><strong>Statistics.cpp/.h</strong> 定义转码统计类，按子类型计数，便于最后输出统计结果。</li>
<li><strong>StringUitils.cpp/.h</strong> 定义String辅助操作的类。</li>
</ul>
<p>另外在HIP项目的tests目录，有hipify-clang的单元测试文件，可以作为hipify-clang和hipify-perl的测试输入文件。如</p>
<ul>
<li>tests/hipify-clang/unit_tests/headers/headers_test_10.cu   </li>
<li>tests/hipify-clang/unit_tests/headers/headers_test_11.cu   </li>
<li>tests/hipify-clang/unit_tests/libraries/cuRAND/poisson_api_example.cu  </li>
</ul>
<h2 id="hipify-perl程序简介"><a href="#hipify-perl程序简介" class="headerlink" title="hipify-perl程序简介"></a>hipify-perl程序简介</h2><p>hipify-perl是HIP项目提供的一个CUDA到HIP转码的perl脚本，官方代码文件见 <a href="https://github.com/ROCm-Developer-Tools/HIP/blob/master/bin/hipify-perl">https://github.com/ROCm-Developer-Tools/HIP/blob/master/bin/hipify-perl</a> ，本质上是基于文本字符串替换方式进行CUDA到HIP转码的关键字替换，包括类型名和函数名等替换。hipify-perl中的关键字替换的map可以从hipify-clang导出，hipify-perl提供了一个转码的框架。</p>
<h2 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h2><p>本项目中，主要文件简介：</p>
<ul>
<li>hipify-perl<br>基于hipify-clang最新map内容的版本</li>
<li>hipify-cmakefile<br>处理cmake文件(如CMakeList.txt)转码的脚本</li>
<li>cuda2hip.sh<br>调用hipify-perl实现文件夹的转码</li>
<li>cuda2hip.sed<br>供sed调用的脚本文件，补充hipify-perl没有实现的关键字转码</li>
<li>cuda2hipsed.sh<br>调用hipify-perl和sed脚本实现文件夹的转码</li>
</ul>
<p>CUDA到HIP转码通常基于hipify-clang或hipify-perl。</p>
<ul>
<li>直接使用hipify-clang进行代码转换，理论上hipify-clang是最准确的转码方式，但是它基于编译过程，对软件编译头文件有强烈依赖，容易导致编译过程中断，对转码产生一定影响。</li>
<li>还有一种折中的办法，是使用hipify-clang的输出map更新hipify-perl脚本。先用hipify-perl脚本进行主体转换，再用cuda2hip.sed脚本补充转换。应用这两个脚本转换之后，转码成功率相对高些。</li>
</ul>
<h2 id="hipify-clang"><a href="#hipify-clang" class="headerlink" title="hipify-clang"></a>hipify-clang</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./hipify-clang --help</span><br><span class="line">./hipify-clang --cuda-path=/usr/local/cuda-10.0 -I /usr/local/cuda-10.0/samples/common/inc lib/*.cu</span><br></pre></td></tr></table></figure>
<p>hipify-clang是基于Clang+LLVM SDK编译的二进制可执行文件。需要在Clang+LLVM的环境下编译获得，这个环境可以是LLVM官方版本，也可以是ROCm下LLVM分支版本（主要使用Clang前端API区别不大）。这里的CUDA头文件版本，需要与编译Clang时的一致，-I指定编译过程中搜索的include头文件目录，可能需要指定多个路径，便于hipify-clang对代码的扫描-编译-转码过程顺利通过。</p>
<h2 id="hipify-perl"><a href="#hipify-perl" class="headerlink" title="hipify-perl"></a>hipify-perl</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./hipify-perl &lt;file&gt;</span><br></pre></td></tr></table></figure>
<p><code>&lt;file&gt;</code>为待转换的CUDA代码文件名。程序在转码之后会检验代码是否还包含cuda、cublas和curand等字眼，如果存在则给出警告（warning）提示，这些警告需要我们确认是否需要转码。</p>
<h2 id="cuda2hip-sh"><a href="#cuda2hip-sh" class="headerlink" title="cuda2hip.sh"></a>cuda2hip.sh</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./cuda2hip.sh &lt;dir&gt;</span><br></pre></td></tr></table></figure>
<p>调用hipify-perl脚本进行文件夹内所有代码转换。默认通配<code>*.c*</code>、<code>*.h*</code>和<code>*.inl</code>文件（下同）。<br><code>&lt;dir&gt;</code>为待转换的CUDA代码所在目录名，可以使用空格隔空，输入多个文件目录名。</p>
<h2 id="cuda2hip-sed"><a href="#cuda2hip-sed" class="headerlink" title="cuda2hip.sed"></a>cuda2hip.sed</h2><ul>
<li><p>第一种使用方式</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./cuda2hip.sed &lt;files&gt;</span><br></pre></td></tr></table></figure>
<p><code>&lt;files&gt;</code>为待转换的CUDA代码文件名，可使用Shell通配符。<br>结果输出到标准输出端。</p>
</li>
<li><p>第二种使用方式</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i -f cuda2hip.sed &lt;files&gt;</span><br></pre></td></tr></table></figure>
<p><code>&lt;files&gt;</code>为待转换的CUDA代码文件名，可使用Shell通配符。<code>-i</code>表示in-place替换。</p>
</li>
<li><p>第三种使用方式</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find . -type f -name *.c* -o -name *.h* -o -name *.inl |xargs sed -i -f cuda2hip.sed</span><br></pre></td></tr></table></figure>
<p>这里借助find查找C/C++和CUDA代码文件，对每个查找到的文件调用cuda2hip.sed进行转码。</p>
</li>
</ul>
<h2 id="cuda2hipsed-sh"><a href="#cuda2hipsed-sh" class="headerlink" title="cuda2hipsed.sh"></a>cuda2hipsed.sh</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./cuda2hipsed.sh &lt;dir&gt;</span><br></pre></td></tr></table></figure>
<p>调用hipify-perl和cuda2hip.sed脚本进行文件夹内所有代码转换。默认通配<code>*.c*</code>、<code>*.h*</code>和<code>*.inl</code>文件。<code>&lt;dir&gt;</code>为待转换的CUDA代码所在目录名，可以使用空格输入多个文件目录。</p>
<h2 id="Getting-Started-with-HIP-API"><a href="#Getting-Started-with-HIP-API" class="headerlink" title="Getting Started with HIP API"></a>Getting Started with HIP API</h2><h3 id="HIP-API-Overview"><a href="#HIP-API-Overview" class="headerlink" title="HIP API Overview"></a>HIP API Overview</h3><p>HIP API包括hipMalloc、hipMemcpy和hipFree等函数。熟悉CUDA的程序员也将能够快速学习并开始使用HIPAPI进行编码。计算内核通过“hipLaunchKernel”宏调用启动。</p>
<h3 id="HIP-API-Examples"><a href="#HIP-API-Examples" class="headerlink" title="HIP API Examples"></a>HIP API Examples</h3><h4 id="Example-1"><a href="#Example-1" class="headerlink" title="Example 1"></a>Example 1</h4><p>下面是一个显示HIP API代码片段的示例：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">hipMalloc</span>(&amp;A_d, Nbytes));</span><br><span class="line"><span class="built_in">hipMalloc</span>(&amp;C_d, Nbytes));</span><br><span class="line"><span class="built_in">hipMemcpy</span>(A_d, A_h, Nbytes, hipMemcpyHostToDevice);</span><br><span class="line"><span class="type">const</span> <span class="type">unsigned</span> blocks = <span class="number">512</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">unsigned</span> threadsPerBlock = <span class="number">256</span>;</span><br><span class="line"><span class="built_in">hipLaunchKernel</span>(vector_square, <span class="comment">/* compute kernel*/</span></span><br><span class="line"><span class="built_in">dim3</span>(blocks), <span class="built_in">dim3</span>(threadsPerBlock), <span class="number">0</span><span class="comment">/*dynamic shared*/</span>, <span class="number">0</span><span class="comment">/*stream*/</span>, <span class="comment">/*launch config*/</span></span><br><span class="line">C_d, A_d, N); <span class="comment">/* arguments to the compute kernel */</span></span><br><span class="line"><span class="built_in">hipMemcpy</span>(C_h, C_d, Nbytes, hipMemcpyDeviceToHost);</span><br></pre></td></tr></table></figure>
<p>HIP内核语言定义了用于确定网格和块坐标、数学函数、短向量、原子和计时器函数的内置函数。它还为函数类型、地址空间和优化控件指定了其他定义和关键字。有关详细说明。</p>
<h4 id="Example-2"><a href="#Example-2" class="headerlink" title="Example 2"></a>Example 2</h4><p>下面是一个定义简单“vector_square”内核的示例。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span></span></span><br><span class="line"><span class="function"><span class="title">vector_square</span><span class="params">(T *C_d, <span class="type">const</span> T *A_d, <span class="type">size_t</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">size_t</span> offset = (blockIdx.x * blockDim.x + threadIdx.x);</span><br><span class="line">    <span class="type">size_t</span> stride = blockDim.x * gridDim.x;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i=offset; i&lt;N; i+=stride) &#123;</span><br><span class="line">	    C_d[i] = A_d[i] * A_d[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>HIP运行时API代码和计算内核定义可以存在于同一源文件中——HIP负责适当地生成主机和设备代码。</p>
<h2 id="Introduction-to-Memory-Allocation"><a href="#Introduction-to-Memory-Allocation" class="headerlink" title="Introduction to Memory Allocation"></a>Introduction to Memory Allocation</h2><h3 id="Host-Memory"><a href="#Host-Memory" class="headerlink" title="Host Memory"></a>Host Memory</h3><p>hipHostMalloc分配被映射到系统中所有GPU的地址空间的固定主机内存。此主机内存有两种使用情况：</p>
<ul>
<li>更快的HostToDevice和DeviceToHost数据传输：运行时跟踪hipHostMalloc分配，可以避免常规未固定内存所需的某些设置。要在特定系统上进行精确测量，请尝试使用hipBusBandwidth工具的—unpinted和—pinted开关。</li>
<li>零拷贝GPU访问：GPU可以通过CPU/GPU互连直接访问主机内存，无需复制数据。这避免了复制的需要，但在内核访问期间，每次内存访问都必须遍历互连，这可能比访问GPU的本地设备内存慢几十倍。当内存访问不频繁（可能只有一次）时，零拷贝内存可能是一个不错的选择。零拷贝内存通常是“一致”的，因此不会被GPU缓存，但如果需要，这可以被覆盖。</li>
</ul>
<h3 id="Memory-allocation-flags"><a href="#Memory-allocation-flags" class="headerlink" title="Memory allocation flags"></a>Memory allocation flags</h3><p>hipHostMalloc始终设置hipHostMalocPortable和hipHostMallocMapped标志。上述两种使用模型使用相同的分配标志，不同之处在于周围代码如何使用主机内存。</p>
<p>hipHostMallocNumaUser是允许主机内存分配遵循用户设置的NUMA策略的标志。</p>
<h3 id="NUMA-aware-host-memory-allocation"><a href="#NUMA-aware-host-memory-allocation" class="headerlink" title="NUMA-aware host memory allocation"></a>NUMA-aware host memory allocation</h3><p>非统一内存体系结构（NUMA）策略确定如何分配内存，并选择最接近每个GPU的CPU。</p>
<p>NUMA还测量GPU和CPU设备之间的距离。默认情况下，每个GPU选择一个Numa CPU节点，该节点之间的Numa距离最小；主机存储器被自动分配为最接近当前GPU设备的NUMA节点的存储器池。</p>
<p>注意，使用不同GPU的hipSetDevice API可以访问主机分配。然而，它可能具有更长的NUMA距离。</p>
<h3 id="Managed-memory-allocation"><a href="#Managed-memory-allocation" class="headerlink" title="Managed memory allocation"></a>Managed memory allocation</h3><p>HIP现在支持并自动管理异构内存管理（HMM）分配。HIP应用程序在进行托管内存API调用hipMallocManaged之前执行功能检查。</p>
<p>例如</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> managed_memory = <span class="number">0</span>;</span><br><span class="line"><span class="built_in">HIPCHECK</span>(<span class="built_in">hipDeviceGetAttribute</span>(&amp;managed_memory, hipDeviceAttributeManagedMemory,p_gpuDevice));</span><br><span class="line"><span class="keyword">if</span> (!managed_memory )` | &#123;</span><br><span class="line">	<span class="built_in">printf</span> (<span class="string">&quot;info: managed memory access not supported on the device %d\n Skipped\n&quot;</span>, p_gpuDevice);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">HIPCHECK</span>(<span class="built_in">hipSetDevice</span>(p_gpuDevice));</span><br><span class="line">    <span class="built_in">HIPCHECK</span>(<span class="built_in">hipMallocManaged</span>(&amp;Hmm, N * <span class="built_in">sizeof</span>(T)));</span><br><span class="line">	. . .</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="HIP-Stream-Memory-Operations"><a href="#HIP-Stream-Memory-Operations" class="headerlink" title="HIP Stream Memory Operations"></a>HIP Stream Memory Operations</h3><p>HIP支持流内存操作，以实现网络节点和GPU之间的直接同步。添加了以下API：</p>
<ul>
<li>hipStreamWaitValue32</li>
<li>hipStreamWaitValue64</li>
<li>hipStreamWriteValue32</li>
<li>hipStreamWriteValue64  </li>
</ul>
<h3 id="Coherency-Controls"><a href="#Coherency-Controls" class="headerlink" title="Coherency Controls"></a>Coherency Controls</h3><p>ROCm为主机内存定义了两个一致性选项：</p>
<ul>
<li>一致性内存：支持内核运行时的细粒度同步。例如，内核可以执行主机CPU或其他（对等）GPU可见的原子操作。同步指令包括threadfence_system和C++11风格的原子操作。然而，一致性存储器不能被GPU缓存，因此可能具有较低的性能。</li>
<li>非一致性内存：可由GPU缓存，但无法在内核运行时支持同步。非一致性内存可以选择性地仅在命令（内核结束或复制命令）边界处同步。当不需要细粒度同步时，此内存适用于高性能访问。</li>
</ul>
<p>HIP为开发人员提供控件，通过传递给hipHostMalloc的分配标志和HIP_HOST_COHERENT环境变量来选择使用哪种类型的内存。默认情况下，环境变量HIP_HOST_CONTENT在HIP中设置为0。HIP当前版本中的控制逻辑如下：</p>
<ul>
<li>没有传递任何标志：主机内存分配是一致的，HIP_host_coherent环境变量被忽略。</li>
<li>hipHostMallocCoherent=1：主机内存分配将是一致的，HIP_host_coherent环境变量将被忽略。</li>
<li>hipHostMallocMapped=1：主机内存分配将是一致的，HIP_host_CONTENT环境变量将被忽略。</li>
<li>hipHostMallocNonCoherent=1，hipHostMalocCoherent=0，hipHostMallocMapped=0：主机内存将是非一致的，HIP_host_CONTENT环境变量被忽略。</li>
<li>hipHostMallocCoherent=0，hipHostMalocNonCoherent=0，hipHostMallocMapped=0，但设置了其他HostMalloc标志之一：<ul>
<li>如果HIP_HOST_COHERENT定义为1，则主机内存分配是一致的。</li>
<li>如果未定义HIP_HOST_COHERENT，或定义为0，则主机内存分配是非一致的。</li>
<li>hipHostMallocCoherent=1，hipHostMalocNonCoherent=1:非法。</li>
</ul>
</li>
</ul>
<h3 id="Visibility-of-Zero-Copy-Host-Memory"><a href="#Visibility-of-Zero-Copy-Host-Memory" class="headerlink" title="Visibility of Zero-Copy Host Memory"></a>Visibility of Zero-Copy Host Memory</h3><p>​    下表描述了一致和非一致主机内存可见性。注意，一致主机内存在同步点自动可见。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>HIP API</th>
<th>Synchronization Effect</th>
<th>Fence</th>
<th>Coherent Host Memory Visibility</th>
<th>Non-Coherent Host Memory Visibility</th>
</tr>
</thead>
<tbody>
<tr>
<td>hipStreamSynchronize</td>
<td>主机等待指定流中的所有命令完成</td>
<td>system-scope release</td>
<td>yes</td>
<td>yes</td>
</tr>
<tr>
<td>hipDeviceSynchronize</td>
<td>主机等待指定设备上所有流中的所有命令完成</td>
<td>system-scope release</td>
<td>yes</td>
<td>yes</td>
</tr>
<tr>
<td>hipEventSynchronize</td>
<td>主机等待指定的事件完成</td>
<td>device-scope release</td>
<td>yes</td>
<td>depends - see the description below</td>
</tr>
<tr>
<td>hipStreamWaitEvent</td>
<td>流等待指定的事件完成</td>
<td>none</td>
<td>yes</td>
<td>no</td>
</tr>
</tbody>
</table>
</div>
<h4 id="hipEventSynchronize"><a href="#hipEventSynchronize" class="headerlink" title="hipEventSynchronize"></a>hipEventSynchronize</h4><p>开发人员可以控制hipEvents的发布范围。默认情况下，GPU对每个记录的事件执行设备范围获取和释放操作。这将使主机和设备内存对在同一设备上执行的其他命令可见。</p>
<p>当使用hipEventCreateWithFlags创建事件时，可以指定更强的系统级围栏。</p>
<ul>
<li>hipEventReleaseToSystem：在记录事件时执行系统范围释放操作。这将使一致和非一致主机内存对系统中的其他代理可见，但可能涉及诸如缓存刷新之类的重量级操作。一致内存通常在内核同步机制中使用较轻的权重，例如原子操作，因此不需要使用hipEventReleaseToSystem。</li>
<li>hipEventDisableTiming：使用此标志创建的事件不会记录分析数据，因此，如果用于同步，将提供最佳性能。</li>
</ul>
<p>注意：对于使用hipExtLaunchKernelGGL/hipExtLaunchKernel的内核调度中的HIP事件，API中传递的事件不会被显式记录，只能用于获取特定启动的经过时间。</p>
<p>例如，如果在多个分派中使用事件，来自不同hipExtLaunchKernelGGL/hipExtLaunchKernel调用的开始和停止事件将被视为无效的未记录事件，并且HIP显示来自hipEventElapsedTime的错误“hipErrorInvalidHandle”。</p>
<p>一致主机内存是默认的，也是最容易使用的，因为CPU在特定的同步点可以看到内存。该内存允许内核内同步命令（如threadfence_system）透明地工作。HIP/ROCm还支持GPU中使用“非一致”主机内存分配的缓存主机内存。这可以提高性能，但必须注意使用正确的同步。</p>
<h4 id="Direct-Dispatch"><a href="#Direct-Dispatch" class="headerlink" title="Direct Dispatch"></a>Direct Dispatch</h4><p>默认情况下，直接调度在HIP运行时启用。利用这一特性，传统的生产者-消费者模型不再适用，其中运行时为每个HIP流创建一个工作线程（消费者），而主机线程（生产者）将命令排入命令队列（每个流）。</p>
<p>对于直接调度，在调度和某些同步的情况下，运行时将直接将数据包排队到AQL队列（用户模式队列到GPU）。这显示了HIP调度API的总延迟和在GPU上启动第一波的延迟。</p>
<p>此外，随着线程调度延迟和原子/锁同步延迟的减少，在运行时消除线程减少了分派数量的差异。</p>
<p>可以通过设置以下环境变量AMD_DIRECT_DISPATCH=0禁用此功能</p>
<h4 id="HIP-Runtime-Compilation"><a href="#HIP-Runtime-Compilation" class="headerlink" title="HIP Runtime Compilation"></a>HIP Runtime Compilation</h4><p>HIP支持运行时编译（hipRTC），与其他API相比，通过常规离线静态编译，hipRTC的使用将提供优化和性能改进的可能性。</p>
<p>hipRTC API接受字符串格式的HIP源文件作为输入参数，并通过编译HIP源代码文件来创建程序句柄。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;test_common.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;hip/hiprtc.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;hip/hip_runtime.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cassert&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstddef&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;memory&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iterator&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="keyword">constexpr</span> <span class="keyword">auto</span> NUM_THREADS&#123;<span class="number">128</span>&#125;;</span><br><span class="line"><span class="type">static</span> <span class="keyword">constexpr</span> <span class="keyword">auto</span> NUM_BLOCKS&#123;<span class="number">32</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="keyword">constexpr</span> <span class="keyword">auto</span> saxpy&#123;</span><br><span class="line"><span class="string">R&quot;(</span></span><br><span class="line"><span class="string">#include &quot;test_header.h&quot;</span></span><br><span class="line"><span class="string">#include &quot;test_header1.h&quot;</span></span><br><span class="line"><span class="string">extern &quot;C&quot;</span></span><br><span class="line"><span class="string">__global__</span></span><br><span class="line"><span class="string">void saxpy(real a, realptr x, realptr y, realptr out, size_t n)</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">    size_t tid = blockIdx.x * blockDim.x + threadIdx.x;</span></span><br><span class="line"><span class="string">    if (tid &lt; n) &#123;</span></span><br><span class="line"><span class="string">       out[tid] = a * x[tid] + y[tid] ;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">)&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line">    hiprtcProgram prog;</span><br><span class="line">    <span class="type">int</span> num_headers = <span class="number">2</span>;</span><br><span class="line">    std::vector&lt;<span class="type">const</span> <span class="type">char</span>*&gt; header_names;</span><br><span class="line">    std::vector&lt;<span class="type">const</span> <span class="type">char</span>*&gt; header_sources;</span><br><span class="line">    header_names.<span class="built_in">push_back</span>(<span class="string">&quot;test_header.h&quot;</span>);</span><br><span class="line">    header_names.<span class="built_in">push_back</span>(<span class="string">&quot;test_header1.h&quot;</span>);</span><br><span class="line">    header_sources.<span class="built_in">push_back</span>(<span class="string">&quot;#ifndef HIPRTC_TEST_HEADER_H\n#define HIPRTC_TEST_HEADER_H\ntypedef float real;\n#endif //HIPRTC_TEST_HEADER_H\n&quot;</span>);</span><br><span class="line">    header_sources.<span class="built_in">push_back</span>(<span class="string">&quot;#ifndef HIPRTC_TEST_HEADER1_H\n#define HIPRTC_TEST_HEADER1_H\ntypedef float* realptr;\n#endif //HIPRTC_TEST_HEADER1_H\n&quot;</span>);</span><br><span class="line">    <span class="built_in">hiprtcCreateProgram</span>(&amp;prog,      <span class="comment">// prog</span></span><br><span class="line">        saxpy,      <span class="comment">// buffer</span></span><br><span class="line">        <span class="string">&quot;saxpy.cu&quot;</span>, <span class="comment">// name</span></span><br><span class="line">        num_headers,          <span class="comment">// numHeaders</span></span><br><span class="line">        &amp;header_sources[<span class="number">0</span>],    <span class="comment">// headers</span></span><br><span class="line">        &amp;header_names[<span class="number">0</span>]);   <span class="comment">// includeNames</span></span><br><span class="line"></span><br><span class="line">    hipDeviceProp_t props;</span><br><span class="line">    <span class="type">int</span> device = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">hipGetDeviceProperties</span>(&amp;props, device);</span><br><span class="line">    std::string sarg = std::<span class="built_in">string</span>(<span class="string">&quot;--gpu-architecture=&quot;</span>) + props.gcnArchName;</span><br><span class="line">    <span class="type">const</span> <span class="type">char</span>* options[] = &#123;</span><br><span class="line">        sarg.<span class="built_in">c_str</span>()</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    hiprtcResult compileResult&#123;<span class="built_in">hiprtcCompileProgram</span>(prog, <span class="number">1</span>, options)&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="type">size_t</span> logSize;</span><br><span class="line">    <span class="built_in">hiprtcGetProgramLogSize</span>(prog, &amp;logSize);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (logSize) &#123;</span><br><span class="line">        <span class="function">string <span class="title">log</span><span class="params">(logSize, <span class="string">&#x27;\0&#x27;</span>)</span></span>;</span><br><span class="line">        <span class="built_in">hiprtcGetProgramLog</span>(prog, &amp;log[<span class="number">0</span>]);</span><br><span class="line"></span><br><span class="line">        cout &lt;&lt; log &lt;&lt; <span class="string">&#x27;\n&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (compileResult != HIPRTC_SUCCESS) &#123; <span class="built_in">failed</span>(<span class="string">&quot;Compilation failed.&quot;</span>); &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">size_t</span> codeSize;</span><br><span class="line">    <span class="built_in">hiprtcGetCodeSize</span>(prog, &amp;codeSize);</span><br><span class="line"></span><br><span class="line">    <span class="function">vector&lt;<span class="type">char</span>&gt; <span class="title">code</span><span class="params">(codeSize)</span></span>;</span><br><span class="line">    <span class="built_in">hiprtcGetCode</span>(prog, code.<span class="built_in">data</span>());</span><br><span class="line"></span><br><span class="line">    <span class="built_in">hiprtcDestroyProgram</span>(&amp;prog);</span><br><span class="line"></span><br><span class="line">    hipModule_t <span class="keyword">module</span>;</span><br><span class="line">    hipFunction_t kernel;</span><br><span class="line">    <span class="built_in">hipModuleLoadData</span>(&amp;<span class="keyword">module</span>, code.<span class="built_in">data</span>());</span><br><span class="line">    <span class="built_in">hipModuleGetFunction</span>(&amp;kernel, <span class="keyword">module</span>, <span class="string">&quot;saxpy&quot;</span>);</span><br><span class="line"></span><br><span class="line">    <span class="type">size_t</span> n = NUM_THREADS * NUM_BLOCKS;</span><br><span class="line">    <span class="type">size_t</span> bufferSize = n * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> a = <span class="number">5.1f</span>;</span><br><span class="line">    unique_ptr&lt;<span class="type">float</span>[]&gt; hX&#123;<span class="keyword">new</span> <span class="type">float</span>[n]&#125;;</span><br><span class="line">    unique_ptr&lt;<span class="type">float</span>[]&gt; hY&#123;<span class="keyword">new</span> <span class="type">float</span>[n]&#125;;</span><br><span class="line">    unique_ptr&lt;<span class="type">float</span>[]&gt; hOut&#123;<span class="keyword">new</span> <span class="type">float</span>[n]&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">        hX[i] = <span class="built_in">static_cast</span>&lt;<span class="type">float</span>&gt;(i);</span><br><span class="line">        hY[i] = <span class="built_in">static_cast</span>&lt;<span class="type">float</span>&gt;(i * <span class="number">2</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    hipDeviceptr_t dX, dY, dOut;</span><br><span class="line">    <span class="built_in">hipMalloc</span>(&amp;dX, bufferSize);</span><br><span class="line">    <span class="built_in">hipMalloc</span>(&amp;dY, bufferSize);</span><br><span class="line">    <span class="built_in">hipMalloc</span>(&amp;dOut, bufferSize);</span><br><span class="line">    <span class="built_in">hipMemcpyHtoD</span>(dX, hX.<span class="built_in">get</span>(), bufferSize);</span><br><span class="line">    <span class="built_in">hipMemcpyHtoD</span>(dY, hY.<span class="built_in">get</span>(), bufferSize);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">struct</span> &#123;</span><br><span class="line">        <span class="type">float</span> a_;</span><br><span class="line">        hipDeviceptr_t b_;</span><br><span class="line">        hipDeviceptr_t c_;</span><br><span class="line">        hipDeviceptr_t d_;</span><br><span class="line">        <span class="type">size_t</span> e_;</span><br><span class="line">    &#125; args&#123;a, dX, dY, dOut, n&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> size = <span class="built_in">sizeof</span>(args);</span><br><span class="line">    <span class="type">void</span>* config[] = &#123;HIP_LAUNCH_PARAM_BUFFER_POINTER, &amp;args,</span><br><span class="line">      HIP_LAUNCH_PARAM_BUFFER_SIZE, &amp;size,</span><br><span class="line">      HIP_LAUNCH_PARAM_END&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">hipModuleLaunchKernel</span>(kernel, NUM_BLOCKS, <span class="number">1</span>, <span class="number">1</span>, NUM_THREADS, <span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">          <span class="number">0</span>, <span class="literal">nullptr</span>, <span class="literal">nullptr</span>, config);</span><br><span class="line">    <span class="built_in">hipMemcpyDtoH</span>(hOut.<span class="built_in">get</span>(), dOut, bufferSize);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; n; ++i) &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">fabs</span>(a * hX[i] + hY[i] - hOut[i]) &gt; <span class="built_in">fabs</span>(hOut[i])* <span class="number">1e-6</span>) &#123; <span class="built_in">failed</span>(<span class="string">&quot;Validation failed.&quot;</span>); &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">hipFree</span>(dX);</span><br><span class="line">    <span class="built_in">hipFree</span>(dY);</span><br><span class="line">    <span class="built_in">hipFree</span>(dOut);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">hipModuleUnload</span>(<span class="keyword">module</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">passed</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>该示例显示了如何使用运行时编译机制对HIP应用程序进行编程。</p>
<h4 id="Use-of-Long-Double-Type"><a href="#Use-of-Long-Double-Type" class="headerlink" title="Use of Long Double Type"></a>Use of Long Double Type</h4><p>在HIP-Clang中，长双精度类型是x86_64的80位扩展精度格式，AMD GPU不支持这种格式。HIP-Clang将长双类型视为AMD GPU的IEEE双类型。只要长双类型的数据不在主机和设备之间传输，在HIP源代码中使用长双类型不会导致问题。但是，长双精度类型不应用作内核参数类型。</p>
<h4 id="FMA-and-Contractions"><a href="#FMA-and-Contractions" class="headerlink" title="FMA and Contractions"></a>FMA and Contractions</h4><p>默认情况下，HIP Clang假设-ffp-contract=fast。对于x86_64，FMA默认关闭，因为通用x86_64目标默认不支持FMA。要在x86_64上打开FMA，请在CPU支持的FMA上使用-mfma或-march=native。当启用收缩且CPU未启用FMA指令时，GPU可以为可收缩的表达式生成与CPU不同的数值结果。</p>
<h4 id="Use-of-Float16-Type"><a href="#Use-of-Float16-Type" class="headerlink" title="Use of _Float16 Type"></a>Use of _Float16 Type</h4><p>如果在x86_64的Clang（或hipcc）和gcc之间使用宿主函数，则其定义由一个编译器编译，但由不同的编译器编译调用方，_Float16或包含Float16的聚合不能用作函数参数或返回类型。这是因为x86_64上的<code>_Float16</code>缺少稳定的ABI。在clang和gcc之间传递<code>_Float16</code>或包含<code>_Float6</code>的聚合可能会导致未定义的行为。</p>
<h4 id="Math-Functions-with-Special-Rounding-Modes"><a href="#Math-Functions-with-Special-Rounding-Modes" class="headerlink" title="Math Functions with Special Rounding Modes"></a>Math Functions with Special Rounding Modes</h4><p>HIP不支持舍入模式为ru（向上舍入）、rd（向下舍入）和rz（向零舍入）的数学函数。HIP仅支持舍入模式为rn（舍入到最近值）的数学函数。带有后缀<code>_ru</code>、<code>_rd</code>和<code>_rz</code>的数学函数的实现方式与带有后缀<code>_rn</code>的数学函数相同。它们是一种变通方法，可以让程序使用它们进行编译。</p>
<h4 id="Creating-Static-Libraries"><a href="#Creating-Static-Libraries" class="headerlink" title="Creating Static Libraries"></a>Creating Static Libraries</h4><p>HIP Clang支持生成两种类型的静态库。</p>
<ul>
<li>第一类静态库不导出设备功能，仅导出和启动同一库中的主机功能。这种类型的优点是能够与非hipcc编译器（如gcc）链接。</li>
<li>第二种类型导出设备功能，以便由其他代码对象链接。然而，这需要使用hipcc作为链接器。此外，第一类库包含主机对象，其中设备代码嵌入为胖二进制文件。它是使用标志—emit-static lib生成的。第二类库包含可重定位的设备对象，并使用ar生成。</li>
</ul>
<p>以下是创建和使用静态库的示例：</p>
<p>Type 1 using —emit-static-lib:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hipcc hipOptLibrary.cpp --emit-static-lib -fPIC -o libHipOptLibrary.a</span><br><span class="line">gcc test.cpp -L. -lhipOptLibrary -L/path/to/hip/lib -lamdhip64 -o test.out</span><br></pre></td></tr></table></figure>
<p>Type 2 using system ar:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hipcc hipDevice.cpp -c -fgpu-rdc -o hipDevice.o</span><br><span class="line">ar rcsD libHipDevice.a hipDevice.o</span><br><span class="line">hipcc libHipDevice.a test.cpp -fgpu-rdc -o test.out  </span><br></pre></td></tr></table></figure>
<h2 id="HIP-Kernel-Language"><a href="#HIP-Kernel-Language" class="headerlink" title="HIP Kernel Language"></a>HIP Kernel Language</h2><p>HIP提供了一种C++语法，适用于编译通常出现在计算内核中的大多数代码，包括类、名称空间、运算符重载、模板等。此外，它还定义了专门针对加速器设计的其他语言功能，例如以下内容：</p>
<ul>
<li>使用标准C++的内核启动语法，类似于函数调用，可移植到所有HIP目标</li>
<li>可用于主机或设备的短矢量标头</li>
<li>类似于标准C++编译器中包含的“Math.h”标头中的数学函数</li>
<li>用于访问特定GPU硬件功能的内置功能</li>
</ul>
<p>本节描述了可以从HIP内核访问的内置变量和函数。它面向熟悉CUDA内核语法并希望了解HIP的不同之处的读者。</p>
<h3 id="Function-Type-Qualifiers"><a href="#Function-Type-Qualifiers" class="headerlink" title="Function-Type Qualifiers"></a>Function-Type Qualifiers</h3><p><code>__device__</code>：在设备上运行，只被设备调用。</p>
<p><code>__global__</code>：在设备上执行，从主机调用。必须是void返回类型。</p>
<p><code>__host__</code>：在主机上调用并执行。<code>__host__</code>可以与<code>__device__</code>组合，在这种情况下，函数同时为主机和设备编译。这些函数不能使用HIP网格坐标函数。例如，“threadIdx_x”。一种可能的解决方法是将必要的坐标信息作为参数传递给函数。<code>__host__</code>不能与<code>__global__</code>组合。</p>
<p>HIP解析<code>__noinline__</code>和<code>__forceinline__</code>关键字，并将它们转换为相应的Clang属性。</p>
<h4 id="Calling-global-Functions"><a href="#Calling-global-Functions" class="headerlink" title="Calling global Functions"></a>Calling <strong>global</strong> Functions</h4><p><code>__global__</code>函数通常称为内核，调用一个函数称为启动内核。这些函数要求调用者指定包含网格和块维度的“执行配置”。执行配置还可以包括用于启动的其他信息，例如要分配的额外共享内存量以及内核应该执行的流。HIP除了Cuda&lt;&lt;&lt;&gt;&gt;&gt;语法之外，还引入了一个标准的C++调用约定，将执行配置传递给内核。</p>
<ul>
<li>在HIP中，内核使用&lt;&lt;&lt;&gt;&gt;&gt;语法或“hipLaunchKernel”函数启动。</li>
<li>hipLaunchKernel的前五个参数如下：<ul>
<li>symbol kernelName：要启动的内核的名称。要支持包含“,”的模板内核，请使用HIP_KERNEL_NAME宏。hipify工具自动地插入这个宏</li>
<li>dim3 gridDim：指定要启动的块数的三维网格尺寸。</li>
<li>dim3 blockDim：指定每个块中线程数的3D块尺寸。</li>
<li>size_t dynamicShared：启动内核时要分配的额外共享内存量（请参阅shared）</li>
<li>hipStream_t：内核应该执行的流。值0对应于NULL流（请参阅同步函数）。</li>
</ul>
</li>
<li>内核参数必须遵循五个参数</li>
</ul>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Example pseudo code introducing hipLaunchKernel:</span></span><br><span class="line"><span class="function">__global__ <span class="title">MyKernel</span><span class="params">(hipLaunchParm lp, <span class="type">float</span> *A, <span class="type">float</span> *B, <span class="type">float</span> *C, <span class="type">size_t</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br><span class="line">MyKernel&lt;&lt;&lt;<span class="built_in">dim3</span>(gridDim), <span class="built_in">dim3</span>(groupDim), <span class="number">0</span>, <span class="number">0</span>&gt;&gt;&gt; (a,b,c,n);</span><br><span class="line"><span class="comment">// Alternatively, kernel can be launched by</span></span><br><span class="line"><span class="comment">// hipLaunchKernel(MyKernel, dim3(gridDim), dim3(groupDim), 0/*dynamicShared*/, 0/*stream), a, b, c, n);</span></span><br></pre></td></tr></table></figure>
<p>hipLaunchKernel宏始终以上面指定的五个参数开头，后跟内核参数。HIPIFY工具可以选择将CUDA启动语法转换为hipLaunchKernel，包括将&lt;&lt;&lt;&gt;&gt;&gt;中的可选参数转换为五个所需的hipLaunchKer参数。dim3构造函数接受零到三个参数，默认情况下将未指定的维度初始化为1。见dim3。内核使用坐标内置（线程、块、网格）来确定当前正在执行的工作项的坐标索引和坐标边界。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Example showing device function, __device__ __host__</span></span><br><span class="line"><span class="comment">// &lt;- compile for both device and host</span></span><br><span class="line"><span class="function"><span class="type">float</span> <span class="title">PlusOne</span><span class="params">(<span class="type">float</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">return</span> x + <span class="number">1.0</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">__global__</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">MyKernel</span> <span class="params">(<span class="type">const</span> <span class="type">float</span> *a, <span class="type">const</span> <span class="type">float</span> *b, <span class="type">float</span> *c, <span class="type">unsigned</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">unsigned</span> gid = threadIdx.x; <span class="comment">// &lt;- coordinate index function</span></span><br><span class="line">    <span class="keyword">if</span> (gid &lt; N) &#123;</span><br><span class="line">	    c[gid] = a[gid] + <span class="built_in">PlusOne</span>(b[gid]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">callMyKernel</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">float</span> *a, *b, *c; <span class="comment">// initialization not shown...</span></span><br><span class="line">    <span class="type">unsigned</span> N = <span class="number">1000000</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">unsigned</span> blockSize = <span class="number">256</span>;</span><br><span class="line">    MyKernel&lt;&lt;&lt;<span class="built_in">dim3</span>(gridDim), <span class="built_in">dim3</span>(groupDim), <span class="number">0</span>, <span class="number">0</span>&gt;&gt;&gt; (a,b,c,n);</span><br><span class="line">	<span class="comment">// Alternatively, kernel can be launched by</span></span><br><span class="line">	<span class="comment">// hipLaunchKernel(MyKernel, dim3(N/blockSize), dim3(blockSize), 0, 0, a,b,c,N);</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Variable-Type-Qualifiers"><a href="#Variable-Type-Qualifiers" class="headerlink" title="Variable-Type Qualifiers"></a>Variable-Type Qualifiers</h3><h4 id="constant"><a href="#constant" class="headerlink" title="constant"></a><strong>constant</strong></h4><p>目前支持<code>__constant__</code>关键字，主机在启动内核之前先写常量内存，在内核运行时这块内存对GPU而言是只读的。获取常量内存的函数主要有hipGetSymbolAddress(), hipGetSymbolSize(),<br>hipMemcpyToSymbol(), hipMemcpyToSymbolAsync(), hipMemcpyFromSymbol(),<br>hipMemcpyFromSymbolAsync()。</p>
<h4 id="shared"><a href="#shared" class="headerlink" title="shared"></a><strong>shared</strong></h4><p><code>extern __shared__</code>允许主机动态分配共享内存，并指定为启动参数。</p>
<p>以前，为了准确起见，必须使用HIP_dynamic_shared宏声明动态共享内存，因为在同一内核中使用静态共享内存可能会导致内存范围重叠和数据竞争。</p>
<p>现在，HIPClang编译器支持外部共享声明，不再需要HIP_DYNAMIC_shared选项。</p>
<h4 id="managed"><a href="#managed" class="headerlink" title="managed"></a><strong>managed</strong></h4><p>HIP组合主机/设备编译中支持托管内存（<code>__managed__</code>关键字除外）。这个关键字的支持正在开发。</p>
<h4 id="restrict"><a href="#restrict" class="headerlink" title="restrict"></a><strong>restrict</strong></h4><p><code>__restrict__</code>关键字告诉编译器，关联的内存指针不会与内核或函数中的任何其他指针别名。此功能可以帮助编译器生成更好的代码。</p>
<p>在大多数情况下，所有指针参数都必须使用此关键字来实现好处。</p>
<h3 id="Built-In-Variables"><a href="#Built-In-Variables" class="headerlink" title="Built-In Variables"></a>Built-In Variables</h3><h4 id="Coordinate-Built-Ins"><a href="#Coordinate-Built-Ins" class="headerlink" title="Coordinate Built-Ins"></a>Coordinate Built-Ins</h4><p>这些内建的变量表明了运行中的grid的工作线程坐标。在hip_runtime.h中定义，而不是被编译器隐式定义。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>HIP Syntax</th>
<th>CUDA Syntax</th>
</tr>
</thead>
<tbody>
<tr>
<td>threadIdx.x</td>
<td>threadIdx.x</td>
</tr>
<tr>
<td>threadIdx.y</td>
<td>threadIdx.y</td>
</tr>
<tr>
<td>threadIdx.z</td>
<td>threadIdx.z</td>
</tr>
<tr>
<td>blockIdx.x</td>
<td>blockIdx.x</td>
</tr>
<tr>
<td>blockIdx.y</td>
<td>blockIdx.y</td>
</tr>
<tr>
<td>blockIdx.z</td>
<td>blockIdx.z</td>
</tr>
<tr>
<td>blockDim.x</td>
<td>blockDim.x</td>
</tr>
<tr>
<td>blockDim.y</td>
<td>blockDim.y</td>
</tr>
<tr>
<td>blockDim.z</td>
<td>blockDim.z</td>
</tr>
<tr>
<td>gridDim.x</td>
<td>gridDim.x</td>
</tr>
<tr>
<td>gridDim.y</td>
<td>gridDim.y</td>
</tr>
<tr>
<td>gridDim.z</td>
<td>gridDim.z</td>
</tr>
</tbody>
</table>
</div>
<h4 id="warpSize"><a href="#warpSize" class="headerlink" title="warpSize"></a>warpSize</h4><p>warpSize变量的类型为int，包含目标设备的warp大小（以线程为单位）。</p>
<p>注意，所有当前的Nvidia设备返回32作为该变量，所有当前AMD设备返回64。设备代码应使用内置的warpSize来开发便携式波形感知代码。</p>
<h3 id="Vector-Types"><a href="#Vector-Types" class="headerlink" title="Vector Types"></a>Vector Types</h3><p>请注意，这些类型是在hip_runtime.h中定义的，编译器不会自动提供。</p>
<h4 id="Short-Vector-Types"><a href="#Short-Vector-Types" class="headerlink" title="Short Vector Types"></a>Short Vector Types</h4><p>短向量类型派生自基本整数和浮点类型。它们是在<code>hip_vector_types.h</code>中定义的结构。向量的第一、第二、第三和第四个分量分别通过x、y、z和w字段访问。所有短向量类型都支持<code>make_&lt;type_name&gt;()</code>形式的构造函数。例如，<code>float4 make_float4(float x, float y, float z, float w)</code>创建float4类型和值<code>(x, y, z, w)</code>的向量。</p>
<p>HIP支持以下短矢量格式：</p>
<ul>
<li>Signed Integers<ul>
<li>char1, char2, char3, char4</li>
<li>short1, short2, short3, short4</li>
<li>int1, int2, int3, int4</li>
<li>long1, long2, long3, long4</li>
<li>longlong1, longlong2, longlong3, longlong4</li>
</ul>
</li>
<li>Unsigned Integers<ul>
<li>uchar1, uchar2, uchar3, uchar4</li>
<li>ushort1, ushort2, ushort3, ushort4</li>
<li>uint1, uint2, uint3, uint4</li>
<li>ulong1, ulong2, ulong3, ulong4</li>
<li>ulonglong1, ulonglong2, ulonglong3, ulonglong4</li>
</ul>
</li>
<li>Floating Points<ul>
<li>float1, float2, float3, float4</li>
<li>double1, double2, double3, double4  </li>
</ul>
</li>
</ul>
<h4 id="dim3"><a href="#dim3" class="headerlink" title="dim3"></a>dim3</h4><p>dim3 是一个三维整型数组，用于指定grid和线程组的维度，未指定的维度会被初始化为1。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span> <span class="title class_">dim3</span> &#123;</span><br><span class="line">    <span class="type">uint32_t</span> x;</span><br><span class="line">    <span class="type">uint32_t</span> y;</span><br><span class="line">    <span class="type">uint32_t</span> z;</span><br><span class="line">    <span class="built_in">dim3</span>(<span class="type">uint32_t</span> _x=<span class="number">1</span>, <span class="type">uint32_t</span> _y=<span class="number">1</span>, <span class="type">uint32_t</span> _z=<span class="number">1</span>) : <span class="built_in">x</span>(_x), <span class="built_in">y</span>(_y), <span class="built_in">z</span>(_z) &#123;&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="Memory-Fence-Instructions"><a href="#Memory-Fence-Instructions" class="headerlink" title="Memory-Fence Instructions"></a>Memory-Fence Instructions</h3><p>HIP支持<code>__threadfence()</code>和<code>__threadfence_block()</code>。HIP为HIP-Clang路径下的<code>threadfence_system()</code>提供了一种解决方法。要启用此解决方法，应在启用环境变量<code>HIP_COHERENT_HOST_ALLOC</code>的情况下构建HIP 。</p>
<p>使用了<code>__threadfence_system()</code>的内核需要作如下修改：</p>
<ul>
<li>内核应该只在细粒度系统内存上运行；它应该与<code>hipHostMalloc()</code>一起分配。</li>
<li>删除分配的细粒度系统内存区域的所有内存。</li>
</ul>
<h3 id="Synchronization-Functions"><a href="#Synchronization-Functions" class="headerlink" title="Synchronization Functions"></a>Synchronization Functions</h3><p>HIP支持<code>__syncthreads()</code> . <code>__syncthreads_count(int)</code>，<code>__syncthreads_and(int)</code>和<code>__syncthreads_or(int)</code>正在开发中。</p>
<h3 id="Math-Functions"><a href="#Math-Functions" class="headerlink" title="Math Functions"></a>Math Functions</h3><p>HIP-Clang 支持一系列数学操作，能够在设备处调用。</p>
<h4 id="Single-Precision-Mathematical-Functions"><a href="#Single-Precision-Mathematical-Functions" class="headerlink" title="Single Precision Mathematical Functions"></a>Single Precision Mathematical Functions</h4><div class="table-container">
<table>
<thead>
<tr>
<th>Function</th>
<th>use</th>
<th>Supported on Host</th>
<th>Supported on Device</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>float acosf ( float x )</code></td>
<td>Calculate the arc cosine of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float acoshf ( float x )</code></td>
<td>Calculate the nonnegative arc hyperbolic cosine of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float asinf ( float x )</code></td>
<td>Calculate the arc sine of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float asinhf ( float x )</code></td>
<td>Calculate the arc hyperbolic sine of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float atan2f ( float y, float x )</code></td>
<td>Calculate the arc tangent of the ratio of first and second input arguments.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float atanf ( float x )</code></td>
<td>Calculate the arc tangent of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float atanhf ( float x )</code></td>
<td>Calculate the arc hyperbolic tangent of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float cbrtf ( float x )</code></td>
<td>Calculate the cube root of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float ceilf ( float x )</code></td>
<td>Calculate ceiling of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float copysignf ( float x, float y )</code></td>
<td>Create value with given magnitude, copying sign of second value.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float cosf ( float x )</code></td>
<td>Calculate the cosine of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float coshf ( float x )</code></td>
<td>Calculate the hyperbolic cosine of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float erfcf ( float x )</code></td>
<td>Calculate the complementary error function of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float erff ( float x )</code></td>
<td>Calculate the error function of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float exp10f ( float x )</code></td>
<td>Calculate the base 10 exponential of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float exp2f ( float x )</code></td>
<td>Calculate the base 2 exponential of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float expf ( float x )</code></td>
<td>Calculate the base e exponential of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float expm1f ( float x )</code></td>
<td>Calculate the base e exponential of the input argument, minus 1.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float fabsf ( float x )</code></td>
<td>Calculate the absolute value of its argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float fdimf ( float x, float y )</code></td>
<td>Compute the positive difference between x and y.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float floorf ( float x )</code></td>
<td>Calculate the largest integer less than or equal to x.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float fmaf ( float x, float y, float z )</code></td>
<td>Compute x × y + z as a single operation.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float fmaxf ( float x, float y )</code></td>
<td>Determine the maximum numeric value of the arguments.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float fminf ( float x, float y )</code></td>
<td>Determine the minimum numeric value of the arguments.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float fmodf ( float x, float y )</code></td>
<td>Calculate the floating-point remainder of x / y.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float frexpf ( float x, int* nptr )</code></td>
<td>Extract mantissa and exponent of a floating-point value.</td>
<td>✔</td>
<td>x</td>
</tr>
<tr>
<td><code>float hypotf ( float x, float y )</code></td>
<td>Calculate the square root of the sum of squares of two arguments.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>int ilogbf ( float x )</code></td>
<td>Compute the unbiased integer exponent of the argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>__RETURN_TYPE1 isfinite ( float a )</code></td>
<td>Determine whether the argument is finite.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>__RETURN_TYPE1 isinf ( float a )</code></td>
<td>Determine whether the argument is infinite.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>__RETURN_TYPE1 isnan ( float a )</code></td>
<td>Determine whether the argument is a NaN.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float ldexpf ( float x, int exp )</code></td>
<td>Calculate the value of x ⋅ 2exp.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float log10f ( float x )</code></td>
<td>Calculate the base 10 logarithm of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float log1pf ( float x )</code></td>
<td>Calculate the value of loge( 1 + x ).</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float logbf ( float x )</code></td>
<td>Calculate the floating-point representation of the exponent of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float log2f ( float x )</code></td>
<td>Calculate the base 2 logarithm of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float logf ( float x )</code></td>
<td>Calculate the natural logarithm of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float modff ( float x, float* iptr )</code></td>
<td>Break down the input argument into fractional and integral parts.</td>
<td>✔</td>
<td>x</td>
</tr>
<tr>
<td><code>float nanf ( const char* tagp )</code></td>
<td>Returns “Not a Number” value.</td>
<td>x</td>
<td>✔</td>
</tr>
<tr>
<td><code>float nearbyintf ( float x )</code></td>
<td>Round the input argument to the nearest integer.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float powf ( float x, float y )</code></td>
<td>Calculate the value of the first argument to the power of the second argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float remainderf ( float x, float y )</code></td>
<td>Compute single-precision floating-point remainder.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float remquof ( float x, float y, int* quo )</code></td>
<td>Compute single-precision floating-point remainder and part of quotient.</td>
<td>✔</td>
<td>x</td>
</tr>
<tr>
<td><code>float roundf ( float x )</code></td>
<td>Round to nearest integer value in floating-point.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float scalbnf ( float x, int n )</code></td>
<td>Scale floating-point input by an integer power of two.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>__RETURN_TYPE1 signbit ( float a )</code></td>
<td>Return the sign bit of the input.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>void sincosf ( float x, float* sptr, float* cptr )</code></td>
<td>Calculate the sine and cosine of the first input argument.</td>
<td>✔</td>
<td>x</td>
</tr>
<tr>
<td><code>float sinf ( float x )</code></td>
<td>Calculate the sine of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float sinhf ( float x )</code></td>
<td>Calculate the hyperbolic sine of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float sqrtf ( float x )</code></td>
<td>Calculate the square root of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float tanf ( float x )</code></td>
<td>Calculate the tangent of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float tanhf ( float x )</code></td>
<td>Calculate the hyperbolic tangent of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float truncf ( float x )</code></td>
<td>Truncate input argument to an integral part.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float tgammaf ( float x )</code></td>
<td>Calculate the gamma function of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float erfcinvf ( float y )</code></td>
<td>Calculate the inverse complementary function of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float erfcxf ( float x )</code></td>
<td>Calculate the scaled complementary error function of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float erfinvf ( float y )</code></td>
<td>Calculate the inverse error function of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float fdividef ( float x, float y )</code></td>
<td>Divide two floating-point values.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float frexpf ( float x, int *nptr )</code></td>
<td>Extract mantissa and exponent of a floating-point value.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float j0f ( float x )</code></td>
<td>Calculate the value of the Bessel function of the first kind of order 0 for the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float j1f ( float x )</code></td>
<td>Calculate the value of the Bessel function of the first kind of order 1 for the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float jnf ( int n, float x )</code></td>
<td>Calculate the value of the Bessel function of the first kind of order n for the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float lgammaf ( float x )</code></td>
<td>Calculate the natural logarithm of the absolute value of the gamma function of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>long long int llrintf ( float x )</code></td>
<td>Round input to nearest integer value.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>long long int llroundf ( float x )</code></td>
<td>Round to nearest integer value.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>long int lrintf ( float x )</code></td>
<td>Round input to the nearest integer value.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>long int lroundf ( float x )</code></td>
<td>Round to nearest integer value.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float modff ( float x, float *iptr )</code></td>
<td>Break down the input argument into fractional and integral parts.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float nextafterf ( float x, float y )</code></td>
<td>Returns next representable single-precision floating-point value after an argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float norm3df ( float a, float b, float c )</code></td>
<td>Calculate the square root of the sum of squares of three coordinates of the argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float norm4df ( float a, float b, float c, float d )</code></td>
<td>Calculate the square root of the sum of squares of four coordinates of the argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float normcdff ( float y )</code></td>
<td>Calculate the standard normal cumulative distribution function.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float normcdfinvf ( float y )</code></td>
<td>Calculate the inverse of the standard normal cumulative distribution function.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float normf ( int dim, const float *a )</code></td>
<td>Calculate the square root of the sum of squares of any number of coordinates.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float rcbrtf ( float x )</code></td>
<td>Calculate the reciprocal cube root function.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float remquof ( float x, float y, int *quo )</code></td>
<td>Compute single-precision floating-point remainder and part of quotient.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float rhypotf ( float x, float y )</code></td>
<td>Calculate one over the square root of the sum of squares of two arguments.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float rintf ( float x )</code></td>
<td>Round input to nearest integer value in floating-point.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float rnorm3df ( float a, float b, float c )</code></td>
<td>Calculate one over the square root of the sum of squares of three coordinates of the argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float rnorm4df ( float a, float b, float c, float d )</code></td>
<td>Calculate one over the square root of the sum of squares of four coordinates of the argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float rnormf ( int dim, const float *a )</code></td>
<td>Calculate the reciprocal of square root of the sum of squares of any number of coordinates.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float scalblnf ( float x, long int n )</code></td>
<td>Scale floating-point input by an integer power of two.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>void sincosf ( float x, float *sptr, float *cptr )</code></td>
<td>Calculate the sine and cosine of the first input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>void sincospif ( float x, float *sptr, float *cptr )</code></td>
<td>Calculate the sine and cosine of the first input argument multiplied by PI.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float y0f ( float x )</code></td>
<td>Calculate the value of the Bessel function of the second kind of order 0 for the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float y1f ( float x )</code></td>
<td>Calculate the value of the Bessel function of the second kind of order 1 for the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float ynf ( int n, float x )</code></td>
<td>Calculate the value of the Bessel function of the second kind of order n for the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
</tbody>
</table>
</div>
<h4 id="Double-Precision-Mathematical-Functions"><a href="#Double-Precision-Mathematical-Functions" class="headerlink" title="Double Precision Mathematical Functions"></a>Double Precision Mathematical Functions</h4><div class="table-container">
<table>
<thead>
<tr>
<th>Function</th>
<th>use</th>
<th>Supported on Host</th>
<th>Supported on Device</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>double acos ( double x )</code></td>
<td>Calculate the arc cosine of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double acosh ( double x )</code></td>
<td>Calculate the nonnegative arc hyperbolic cosine of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double asin ( double x )</code></td>
<td>Calculate the arc sine of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double asinh ( double x )</code></td>
<td>Calculate the arc hyperbolic sine of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double atan ( double x )</code></td>
<td>Calculate the arc tangent of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double atan2 ( double y, double x )</code></td>
<td>Calculate the arc tangent of the ratio of first and second input arguments.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double atanh ( double x )</code></td>
<td>Calculate the arc hyperbolic tangent of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double cbrt ( double x )</code></td>
<td>Calculate the cube root of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double ceil ( double x )</code></td>
<td>Calculate ceiling of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double copysign ( double x, double y )</code></td>
<td>Create value with given magnitude, copying sign of second value.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double cos ( double x )</code></td>
<td>Calculate the cosine of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double cosh ( double x )</code></td>
<td>Calculate the hyperbolic cosine of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double erf ( double x )</code></td>
<td>Calculate the error function of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double erfc ( double x )</code></td>
<td>Calculate the complementary error function of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double exp ( double x )</code></td>
<td>Calculate the base e exponential of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double exp10 ( double x )</code></td>
<td>Calculate the base 10 exponential of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double exp2 ( double x )</code></td>
<td>Calculate the base 2 exponential of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double expm1 ( double x )</code></td>
<td>Calculate the base e exponential of the input argument, minus 1.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double fabs ( double x )</code></td>
<td>Calculate the absolute value of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double fdim ( double x, double y )</code></td>
<td>Compute the positive difference between x and y.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double floor ( double x )</code></td>
<td>Calculate the largest integer less than or equal to x.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double fma ( double x, double y, double z )</code></td>
<td>Compute x × y + z as a single operation.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double fmax ( double , double )</code></td>
<td>Determine the maximum numeric value of the arguments.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double fmin ( double x, double y )</code></td>
<td>Determine the minimum numeric value of the arguments.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double fmod ( double x, double y )</code></td>
<td>Calculate the floating-point remainder of x / y.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double frexp ( double x, int* nptr )</code></td>
<td>Extract mantissa and exponent of a floating-point value.</td>
<td>✔</td>
<td>x</td>
</tr>
<tr>
<td><code>double hypot ( double x, double y )</code></td>
<td>Calculate the square root of the sum of squares of two arguments.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>int ilogb ( double x )</code></td>
<td>Compute the unbiased integer exponent of the argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>__RETURN_TYPE1 isfinite ( double a )</code></td>
<td>Determine whether an argument is finite.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>__RETURN_TYPE1 isinf ( double a )</code></td>
<td>Determine whether an argument is infinite.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>__RETURN_TYPE1 isnan ( double a )</code></td>
<td>Determine whether an argument is a NaN.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double ldexp ( double x, int exp )</code></td>
<td>Calculate the value of x ⋅ 2exp.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double log ( double x )</code></td>
<td>Calculate the base e logarithm of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double log10 ( double x )</code></td>
<td>Calculate the base 10 logarithm of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double log1p ( double x )</code></td>
<td>Calculate the value of loge( 1 + x ).</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double log2 ( double x )</code></td>
<td>Calculate the base 2 logarithm of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double logb ( double x )</code></td>
<td>Calculate the floating-point representation of the exponent of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double modf ( double x, double* iptr )</code></td>
<td>Break down the input argument into fractional and integral parts.</td>
<td>✔</td>
<td>x</td>
</tr>
<tr>
<td><code>double nan ( const char* tagp )</code></td>
<td>Returns “Not a Number” value.</td>
<td>x</td>
<td>✔</td>
</tr>
<tr>
<td><code>double nearbyint ( double x )</code></td>
<td>Round the input argument to the nearest integer.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double pow ( double x, double y )</code></td>
<td>Calculate the value of the first argument to the power of the second argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double remainder ( double x, double y )</code></td>
<td>Compute double-precision floating-point remainder.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double remquo ( double x, double y, int* quo )</code></td>
<td>Compute double-precision floating-point remainder and part of quotient.</td>
<td>✔</td>
<td>x</td>
</tr>
<tr>
<td><code>double round ( double x )</code></td>
<td>Round to nearest integer value in floating-point.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double scalbn ( double x, int n )</code></td>
<td>Scale floating-point input by an integer power of two.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>__RETURN_TYPE1 signbit ( double a )</code></td>
<td>Return the sign bit of the input.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double sin ( double x )</code></td>
<td>Calculate the sine of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>void sincos ( double x, double* sptr, double* cptr )</code></td>
<td>Calculate the sine and cosine of the first input argument.</td>
<td>✔</td>
<td>x</td>
</tr>
<tr>
<td><code>double sinh ( double x )</code></td>
<td>Calculate the hyperbolic sine of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double sqrt ( double x )</code></td>
<td>Calculate the square root of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double tan ( double x )</code></td>
<td>Calculate the tangent of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double tanh ( double x )</code></td>
<td>Calculate the hyperbolic tangent of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double tgamma ( double x )</code></td>
<td>Calculate the gamma function of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double trunc ( double x )</code></td>
<td>Truncate input argument to an integral part.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double erfcinv ( double y )</code></td>
<td>Calculate the inverse complementary function of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double erfcx ( double x )</code></td>
<td>Calculate the scaled complementary error function of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double erfinv ( double y )</code></td>
<td>Calculate the inverse error function of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double frexp ( float x, int *nptr )</code></td>
<td>Extract mantissa and exponent of a floating-point value.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double j0 ( double x )</code></td>
<td>Calculate the value of the Bessel function of the first kind of order 0 for the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double j1 ( double x )</code></td>
<td>Calculate the value of the Bessel function of the first kind of order 1 for the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double jn ( int n, double x )</code></td>
<td>Calculate the value of the Bessel function of the first kind of order n for the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double lgamma ( double x )</code></td>
<td>Calculate the natural logarithm of the absolute value of the gamma function of the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>long long int llrint ( double x )</code></td>
<td>Round input to a nearest integer value.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>long long int llround ( double x )</code></td>
<td>Round to nearest integer value.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>long int lrint ( double x )</code></td>
<td>Round input to a nearest integer value.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>long int lround ( double x )</code></td>
<td>Round to nearest integer value.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double modf ( double x, double *iptr )</code></td>
<td>Break down the input argument into fractional and integral parts.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double nextafter ( double x, double y )</code></td>
<td>Returns next representable single-precision floating-point value after an argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double norm3d ( double a, double b, double c )</code></td>
<td>Calculate the square root of the sum of squares of three coordinates of the argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>float norm4d ( double a, double b, double c, double d )</code></td>
<td>Calculate the square root of the sum of squares of four coordinates of the argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double normcdf ( double y )</code></td>
<td>Calculate the standard normal cumulative distribution function.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double normcdfinv ( double y )</code></td>
<td>Calculate the inverse of the standard normal cumulative distribution function.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double rcbrt ( double x )</code></td>
<td>Calculate the reciprocal cube root function.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double remquo ( double x, double y, int *quo )</code></td>
<td>Compute single-precision floating-point remainder and part of quotient.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double rhypot ( double x, double y )</code></td>
<td>Calculate one over the square root of the sum of squares of two arguments.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double rint ( double x )</code></td>
<td>Round input to the nearest integer value in floating-point.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double rnorm3d ( double a, double b, double c )</code></td>
<td>Calculate one over the square root of the sum of squares of three coordinates of the argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double rnorm4d ( double a, double b, double c, double d )</code></td>
<td>Calculate one over the square root of the sum of squares of four coordinates of the argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double rnorm ( int dim, const double *a )</code></td>
<td>Calculate the reciprocal of the square root of the sum of squares of any number of coordinates.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double scalbln ( double x, long int n )</code></td>
<td>Scale floating-point input by an integer power of two.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>void sincos ( double x, double *sptr, double *cptr )</code></td>
<td>Calculate the sine and cosine of the first input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>void sincospi ( double x, double *sptr, double *cptr )</code></td>
<td>Calculate the sine and cosine of the first input argument multiplied by PI.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double y0f ( double x )</code></td>
<td>Calculate the value of the Bessel function of the second kind of order 0 for the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double y1 ( double x )</code></td>
<td>Calculate the value of the Bessel function of the second kind of order 1 for the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
<tr>
<td><code>double yn ( int n, double x )</code></td>
<td>Calculate the value of the Bessel function of the second kind of order n for the input argument.</td>
<td>✔</td>
<td>✔</td>
</tr>
</tbody>
</table>
</div>
<p><code>__RETURN_TYPE</code> 取决于编译器，通常在C里是int，在C++里是bool。</p>
<h4 id="Integer-Intrinsics"><a href="#Integer-Intrinsics" class="headerlink" title="Integer Intrinsics"></a>Integer Intrinsics</h4><p>下表列出了支持的整数内部函数。注意，内部函数仅在设备上受支持。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Function</th>
<th>use</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>unsigned int __brev ( unsigned int x )</code></td>
<td>Reverse the bit order of a 32-bit unsigned integer.</td>
</tr>
<tr>
<td><code>unsigned long long int __brevll (unsigned long long int x )</code></td>
<td>Reverse the bit order of a 64-bit unsigned integer.</td>
</tr>
<tr>
<td><code>int __clz ( int x )</code></td>
<td>Return the number of consecutive high-order zero bits in a 32-bit integer.</td>
</tr>
<tr>
<td><code>unsigned int __clz(unsigned int x )</code></td>
<td>Return the number of consecutive high-order zero bits in 32-bit unsigned integer.</td>
</tr>
<tr>
<td><code>int __clzll ( long long int x )</code></td>
<td>Count the number of consecutive high-order zero bits in a 64-bit integer.</td>
</tr>
<tr>
<td><code>unsigned int __clzll(long long int x )</code></td>
<td>Return the number of consecutive high-order zero bits in 64-bit signed integer.</td>
</tr>
<tr>
<td><code>unsigned int __ffs(unsigned int x )</code></td>
<td>Find the position of least significant bit set to 1 in a 32-bit unsigned integer.1</td>
</tr>
<tr>
<td><code>unsigned int __ffs( int x )</code></td>
<td>Find the position of least significant bit set to 1 in a 32-bit signed integer.</td>
</tr>
<tr>
<td><code>unsigned int __ffsll(unsigned long long int x )</code></td>
<td>Find the position of least significant bit set to 1 in a 64-bit unsigned integer.1</td>
</tr>
<tr>
<td><code>unsigned int __ffsll(long long int x )</code></td>
<td>Find the position of least significant bit set to 1 in a 64 bit signed integer.</td>
</tr>
<tr>
<td><code>unsigned int __popc ( unsigned int x )</code></td>
<td>Count the number of bits that are set to 1 in a 32-bit integer.</td>
</tr>
<tr>
<td><code>int __popcll ( unsigned long long int x )</code></td>
<td>Count the number of bits that are set to 1 in a 64-bit integer.</td>
</tr>
<tr>
<td><code>int __mul24 ( int x, int y )</code></td>
<td>Multiply two 24-bit integers.</td>
</tr>
<tr>
<td><code>unsigned int __umul24 ( unsigned int x, unsigned int y )</code></td>
<td>Multiply two 24-bit unsigned integers.</td>
</tr>
</tbody>
</table>
</div>
<p><code>__ffs()</code>和<code>__ffsll()</code>的HIP-Clang实现包含添加constant+1以生成ffs结果格式的代码。对于这种开销是不可接受的，并且程序员愿意专门针对平台的情况优化，HIP-Clang提供<code>__lastbit_u32_u32</code>和<code>__lastbit_u32_u64</code>。</p>
<h4 id="Floating-point-Intrinsics"><a href="#Floating-point-Intrinsics" class="headerlink" title="Floating-point Intrinsics"></a>Floating-point Intrinsics</h4><p>下表列出了支持的浮点内部函数。注意，内部函数仅在设备上受支持。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Function</th>
<th>use</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>float __cosf ( float x )</code></td>
<td>Calculate the fast approximate cosine of the input argument.</td>
</tr>
<tr>
<td><code>float __expf ( float x )</code></td>
<td>Calculate the fast approximate base e exponential of the input argument.</td>
</tr>
<tr>
<td><code>float __frsqrt_rn ( float x )</code></td>
<td>Compute 1 / √x in round-to-nearest-even mode.</td>
</tr>
<tr>
<td><code>float __fsqrt_rd ( float x )</code></td>
<td>Compute √x in round-down mode.</td>
</tr>
<tr>
<td><code>float __fsqrt_rn ( float x )</code></td>
<td>Compute √x in round-to-nearest-even mode.</td>
</tr>
<tr>
<td><code>float __fsqrt_ru ( float x )</code></td>
<td>Compute √x in round-up mode.</td>
</tr>
<tr>
<td><code>float __fsqrt_rz ( float x )</code></td>
<td>Compute √x in round-towards-zero mode.</td>
</tr>
<tr>
<td><code>float __log10f ( float x )</code></td>
<td>Calculate the fast approximate base 10 logarithm of the input argument.</td>
</tr>
<tr>
<td><code>float __log2f ( float x )</code></td>
<td>Calculate the fast approximate base 2 logarithm of the input argument.</td>
</tr>
<tr>
<td><code>float __logf ( float x )</code></td>
<td>Calculate the fast approximate base e logarithm of the input argument.</td>
</tr>
<tr>
<td><code>float __powf ( float x, float y )</code></td>
<td>Calculate the fast approximate of xy.</td>
</tr>
<tr>
<td><code>float __sinf ( float x )</code></td>
<td>Calculate the fast approximate sine of the input argument.</td>
</tr>
<tr>
<td><code>float __tanf ( float x )</code></td>
<td>Calculate the fast approximate tangent of the input argument.</td>
</tr>
<tr>
<td><code>double __dsqrt_rd ( double x )</code></td>
<td>Compute √x in round-down mode.</td>
</tr>
<tr>
<td><code>double __dsqrt_rn ( double x )</code></td>
<td>Compute √x in round-to-nearest-even mode.</td>
</tr>
<tr>
<td><code>double __dsqrt_ru ( double x )</code></td>
<td>Compute √x in round-up mode.</td>
</tr>
<tr>
<td><code>double __dsqrt_rz ( double x )</code></td>
<td>Compute √x in round-towards-zero mode.</td>
</tr>
</tbody>
</table>
</div>
<h4 id="Texture-Functions"><a href="#Texture-Functions" class="headerlink" title="Texture Functions"></a>Texture Functions</h4><p>以下头文件中列出了支持的纹理函数：”texture_functions.h”和”texture_indirect_functions.h”  。</p>
<h4 id="Timer-Functions"><a href="#Timer-Functions" class="headerlink" title="Timer Functions"></a>Timer Functions</h4><p>HIP提供以下内置功能，用于从设备读取高分辨率计时器。</p>
<ul>
<li><code>clock_t clock()</code></li>
<li><code>long long int clock64()</code></li>
</ul>
<p>返回设备上每个时钟周期递增的计数器值。返回值的差异就是计时间隔。</p>
<h4 id="Atomic-Functions"><a href="#Atomic-Functions" class="headerlink" title="Atomic Functions"></a>Atomic Functions</h4><p>原子函数作为驻留在全局或共享内存中的读-修改-写操作执行。在原子操作期间，没有其他设备或线程可以观察或修改内存位置。如果来自不同设备或线程的多条指令以同一内存位置为目标，指令以未定义的顺序序列化。</p>
<p>HIP添加了以<code>_system</code>为后缀的新API，以支持系统范围的原子操作。例如，<code>atomicAnd</code> 专用于GPU设备，<code>atomicAnd_system</code>将允许开发人员将原子操作扩展到系统范围，从GPU设备扩展到系统中的其他CPU和GPU设备。</p>
<p>HIP支持以下原子操作：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Function</th>
<th>Supported in HIP</th>
<th>Supported in CUDA</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>int atomicAdd(int* address, int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>int atomicAdd_system(int* address, int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned int atomicAdd(unsigned int* address,unsigned int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned int atomicAdd_system(unsigned int* address, unsigned int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned long long atomicAdd(unsigned long long* address,unsigned long long val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned long long atomicAdd_system(unsigned long long* address, unsigned long long val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>float atomicAdd(float* address, float val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>float atomicAdd_system(float* address, float val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>double atomicAdd(double* address, double val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>double atomicAdd_system(double* address, double val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>int atomicSub(int* address, int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>int atomicSub_system(int* address, int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned int atomicSub(unsigned int* address,unsigned int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned int atomicSub_system(unsigned int* address, unsigned int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>int atomicExch(int* address, int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>int atomicExch_system(int* address, int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned int atomicExch(unsigned int* address,unsigned int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned int atomicExch_system(unsigned int* address, unsigned int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned long long atomicExch(unsigned long long int* address,unsigned long long int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned long long atomicExch_system(unsigned long long* address, unsigned long long val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned long long atomicExch_system(unsigned long long* address, unsigned long long val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>float atomicExch(float* address, float val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>int atomicMin(int* address, int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>int atomicMin_system(int* address, int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned int atomicMin(unsigned int* address,unsigned int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned int atomicMin_system(unsigned int* address, unsigned int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned long long atomicMin(unsigned long long* address,unsigned long long val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>int atomicMax(int* address, int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>int atomicMax_system(int* address, int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned int atomicMax(unsigned int* address,unsigned int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned int atomicMax_system(unsigned int* address, unsigned int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned long long atomicMax(unsigned long long* address,unsigned long long val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned int atomicInc(unsigned int* address)</code></td>
<td>✗</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned int atomicDec(unsigned int* address)</code></td>
<td>✗</td>
<td>✓</td>
</tr>
<tr>
<td><code>int atomicCAS(int* address, int compare, int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>int atomicCAS_system(int* address, int compare, int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned int atomicCAS(unsigned int* address,unsigned int compare,unsigned int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned int atomicCAS_system(unsigned int* address, unsigned int compare, unsigned int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned long long atomicCAS(unsigned long long* address,unsigned long long compare,unsigned long long val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned long long atomicCAS_system(unsigned long long* address, unsigned long long compare, unsigned long long val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>int atomicAnd(int* address, int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>int atomicAnd_system(int* address, int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned int atomicAnd(unsigned int* address,unsigned int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned int atomicAnd_system(unsigned int* address, unsigned int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned long long atomicAnd(unsigned long long* address,unsigned long long val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned long long atomicAnd_system(unsigned long long* address, unsigned long long val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>int atomicOr(int* address, int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>int atomicOr_system(int* address, int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned int atomicOr(unsigned int* address,unsigned int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned int atomicOr_system(unsigned int* address, unsigned int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned int atomicOr_system(unsigned int* address, unsigned int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned long long atomicOr(unsigned long long int* address,unsigned long long val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned long long atomicOr_system(unsigned long long* address, unsigned long long val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>int atomicXor(int* address, int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>int atomicXor_system(int* address, int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned int atomicXor(unsigned int* address,unsigned int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned int atomicXor_system(unsigned int* address, unsigned int val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned long long atomicXor(unsigned long long* address,unsigned long long val)</code>)</td>
<td>✓</td>
<td>✓</td>
</tr>
<tr>
<td><code>unsigned long long atomicXor_system(unsigned long long* address, unsigned long long val)</code></td>
<td>✓</td>
<td>✓</td>
</tr>
</tbody>
</table>
</div>
<p>注意：为了保持浮点/双原子加法函数的向后兼容性，CMake文件中引入了一个新的编译标志<code>__HIP_USE_CMPXCHG_FOR_FP_ATOMICS</code>。默认情况下未设置此编译标志（“0”），因此HIP运行时使用当前的float/double atomicAdd函数。如果使用CMake选项将编译标志设置为1，<code>D__HIP_USE_CMPXCHG_FOR_FP_ATOMICS=1</code>，则旧的浮点/双原子加法函数用于与不支持浮点原子的编译器兼容。有关如何构建HIP运行时的详细信息，请参阅本指南中的HIP安装部分。</p>
<p>开发中的注意事项和功能HIP支持32位整数的原子操作。此外，它还支持原子浮点加法运算。</p>
<p>然而，AMD硬件使用CAS循环实现浮点加法，因此此函数可能无法有效执行。</p>
<h4 id="Warp-Cross-Lane-Functions"><a href="#Warp-Cross-Lane-Functions" class="headerlink" title="Warp Cross-Lane Functions"></a>Warp Cross-Lane Functions</h4><p>在warp中的所有lane上运行。硬件保证所有warp lane将同步执行，因此不需要额外的同步，指令也不使用共享内存。</p>
<p>注意，英伟达和AMD设备具有不同的warp尺寸，因此代码应使用warpSize内置来查询warp尺寸。CUDA路径中的代码需要仔细审查，以确保其不假定warpSize为32。假设warpSize为32的代码在Warp-64机器上运行，它将仅使用一半的机器资源。</p>
<p>WarpSize 内置应该只能使用在设备函数中，它的值仅取决于GPU的架构。主机函数应该使用<code>hipGetDeviceProperties</code>来获取GPU设备的默认warpSize。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cudaDeviceProp props;</span><br><span class="line"><span class="built_in">cudaGetDeviceProperties</span>(&amp;props, deviceID);</span><br><span class="line"><span class="type">int</span> w = props.warpSize;</span><br><span class="line"><span class="comment">// implement portable algorithm based on w (rather than assume 32 or 64)</span></span><br></pre></td></tr></table></figure>
<h4 id="Warp-Vote-and-Ballot-Functions"><a href="#Warp-Vote-and-Ballot-Functions" class="headerlink" title="Warp Vote and Ballot Functions"></a>Warp Vote and Ballot Functions</h4><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> __all(<span class="type">int</span> predicate)</span><br><span class="line"><span class="type">int</span> __any(<span class="type">int</span> predicate)</span><br><span class="line"><span class="type">uint64_t</span> __ballot(<span class="type">int</span> predicate)</span><br></pre></td></tr></table></figure>
<p>warp中的线程称为lane，编号从0到warpSize-1。对于这些函数，每个warp lane通道贡献1——比特值，它被有效地广播到warp中的所有lane。每个通道中的32位整型减少为1位值：0（predicate=0）或1（predicate!=0）<code>__any</code>和<code>__all</code>提供了其他warp lane贡献的参数的概要视图：</p>
<ul>
<li><p><code>__any()</code>如果任何warp lane提供非零谓词，则返回1，否则返回0</p>
</li>
<li><p><code>__all()</code>如果所有其他warp lane贡献非零谓词，则返回1，否则返回0</p>
</li>
</ul>
<p>应用程序可以使用hasWarpVote设备属性或<code>HIP_ARCH_AS_WARP_VOTE</code>编译器定义测试目标平台是否支持任意/所有指令。</p>
<p><code>__ballot</code>提供包含来自每个通道的1位谓词值的位掩码。结果的第n位包含第n个warp lane贡献的1位。请注意，HIP的<code>__ballot</code>函数支持64位返回值（与32位相比）。从CUDA移植的代码应该支持HIP版本的此指令支持的更大的warp大小。应用程序可以使用<code>hasWarpBallot</code>设备属性或<code>HIP_ARCH_AS_WARP_ballot</code>编译器定义测试目标平台是否支持ballot指令。</p>
<h4 id="Cooperative-Groups-Functions"><a href="#Cooperative-Groups-Functions" class="headerlink" title="Cooperative Groups Functions"></a>Cooperative Groups Functions</h4><p>协作组是以不同于块的粒度在线程之间形成和通信的机制。CUDA 9中引入了此功能。HIP支持以下内核语言协作组类型或函数。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Function</th>
<th>HIP</th>
<th>CUDA</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>void thread_group.sync() ;</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>unsigned thread_group.size();</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>unsigned thread_group.thread_rank() ;</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>bool thread_group.is_valid();</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>grid_group this_grid();</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>void grid_group.sync() ;</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>unsigned grid_group.size() ;</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>unsigned grid_group.thread_rank() ;</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>bool grid_group.is_valid();</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>multi_grid_group this_multi_grid() ;</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>void multi_grid_group.sync();</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>unsigned multi_grid_group.size() ;</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>unsigned multi_grid_group.thread_rank() ;</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>bool multi_grid_group.is_valid() ;</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>unsigned multi_grid_group.num_grids() ;</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>unsigned multi_grid_group.grid_rank();</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>thread_block this_thread_block() ;</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>multi_grid_group this_multi_grid() ;</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>void multi_grid_group.sync();</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>void thread_block.sync() ;</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>unsigned thread_block.size() ;</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>unsigned thread_block.thread_rank() ;</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>bool thread_block.is_valid() ;</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>dim3 thread_block.group_index() ;</code></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>dim3 thread_block.thread_index()</code></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<h4 id="Warp-Matrix-Functions"><a href="#Warp-Matrix-Functions" class="headerlink" title="Warp Matrix Functions"></a>Warp Matrix Functions</h4><p>warp矩阵函数允许warp在元素以未指定的方式分布在lane上的小矩阵上协同操作。CUDA 9中引入了此功能。</p>
<p>HIP不支持任何内核语言warp矩阵类型或函数。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Function</th>
<th>Supported in HIP</th>
<th>Supported in CUDA</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>void load_matrix_sync(fragment&lt;...&gt; &amp;a, const T* mptr, unsigned lda)</code></td>
<td></td>
<td>✓</td>
</tr>
<tr>
<td><code>void load_matrix_sync(fragment&lt;...&gt; &amp;a, const T* mptr, unsigned lda, layout_t layout)</code></td>
<td></td>
<td>✓</td>
</tr>
<tr>
<td><code>void store_matrix_sync(T* mptr, fragment&lt;...&gt; &amp;a, unsigned lda, layout_t layout)</code></td>
<td></td>
<td>✓</td>
</tr>
<tr>
<td><code>void fill_fragment(fragment&lt;...&gt; &amp;a, const T &amp;value)</code></td>
<td></td>
<td>✓</td>
</tr>
<tr>
<td><code>void mma_sync(fragment&lt;...&gt; &amp;d, const fragment&lt;...&gt; &amp;a, const fragment&lt;...&gt; &amp;b, const fragment&lt;...&gt; &amp;c , bool sat)</code></td>
<td></td>
<td>✓</td>
</tr>
</tbody>
</table>
</div>
<h4 id="Independent-Thread-Scheduling"><a href="#Independent-Thread-Scheduling" class="headerlink" title="Independent Thread Scheduling"></a>Independent Thread Scheduling</h4><p>在支持CUDA的某些体系结构中引入的对独立线程调度的硬件支持允许线程彼此独立地进行，并启用以前不允许的经内同步。</p>
<p>HIP不支持这种类型的线程调度。</p>
<h4 id="Assert"><a href="#Assert" class="headerlink" title="Assert"></a>Assert</h4><p>assert函数正在开发中，HIP不支持abort调用。</p>
<h4 id="Printf"><a href="#Printf" class="headerlink" title="Printf"></a>Printf</h4><p>支持printf函数</p>
<h3 id="Device-Side-Dynamic-Global-Memory-Allocation"><a href="#Device-Side-Dynamic-Global-Memory-Allocation" class="headerlink" title="Device-Side Dynamic Global Memory Allocation"></a>Device-Side Dynamic Global Memory Allocation</h3><p>设备端动态全局内存分配正在开发中。</p>
<h3 id="launch-bounds"><a href="#launch-bounds" class="headerlink" title="__launch_bounds__"></a><code>__launch_bounds__</code></h3><p>GPU多处理器有一个固定的资源池（主要是寄存器和共享内存），这些资源由主动运行的warp共享。使用更多资源可以增加内核的IPC，但会减少可用于其他warp的资源，并限制可以同时运行的warp的数量。因此，GPU在资源使用和性能之间有着复杂的关系。</p>
<p><code>__launchbounds__</code>允许应用程序提供影响生成代码所使用的资源（主要是寄存器）的使用提示。它是必须附加到<code>__global__</code>函数的函数属性：</p>
<p><code>__global__ void __launch_bounds__ (MAX_THREADS_PER_BLOCK, MIN_WARPS_PER_EU) MyKernel(...) ... MyKernel(...)</code></p>
<p><code>launch_bounds</code>支持两个参数：</p>
<ul>
<li><p><code>MAX_THREADS_PER_BLOCK</code>-程序员保证内核将以少于<code>MAX_THREADS_PER_BLOCK</code>的线程启动。（在NVCC上，这映射到.mantid PTX指令）。如果未指定<code>launch_bounds</code>，则<code>MAX_THREADS_PER_BLOCK</code>是设备支持的最大块大小（通常为1024或更大）。指定<code>MAX_THREADS_PER_BLOCK</code>小于最大值有效地允许编译器使用比默认无约束编译更多的资源，该编译在启动时支持所有可能的块大小。每个块的线程数是<code>(hipBlockDim_x*hipBlockDim_y*hipBlockDim_z)</code>的乘积。</p>
</li>
<li><p><code>MIN_WARPS_PER_EU</code>—指导编译器最小化资源使用，以便在多处理器上同时激活所请求的warp数。由于活动warp会争夺相同的固定资源池，编译器必须减少每个warp所需的资源（主要是寄存器）。<code>MIN_WARPS_PER_EU</code>是可选的，如果未指定，则默认为1。指定大于默认值1的<code>MIN_WARPS_PER_EU</code>有效地限制了编译器的资源使用。</p>
</li>
</ul>
<p>当使用HIPAPI（例如，<code>hipModuleLaunchKernel()</code>）启动内核时，HIP将进行验证，以确保输入内核维度大小不大于指定的<code>launch_bounds</code>。如果<code>AMD_LOG_LEVEL</code>设置为正确的值，则如果超过指定的<code>launch_bounds</code>，HIP将返回启动失败。错误详细信息显示在错误日志消息中，包括内核大小、启动边界和出错内核的名称的启动参数。通常有助于识别断层内核。此外，内核dim大小和启动边界值也有助于调试此类故障。</p>
<h4 id="Compiler-Impact"><a href="#Compiler-Impact" class="headerlink" title="Compiler Impact"></a>Compiler Impact</h4><p>编译器使用这些参数如下：</p>
<ul>
<li>编译器仅使用提示来管理寄存器使用，不会自动减少共享内存或其他资源。</li>
<li>如果编译器无法生成满足指定启动边界要求的内核，则编译失败。</li>
<li>编译器从<code>MAX_THREADS_PER_BLOCK</code>导出启动时可使用的最大warp/块数。<code>MAX_THREADS_PER_BLOCK</code>的值小于默认值允许编译器使用更大的寄存器池：每个warp使用寄存器，此提示包含启动到小于最大值的warp/块大小。</li>
<li>编译器从<code>MIN_WARPS_PER_EU</code>导出内核可使用的最大寄存器数（以满足所需的同时活动块）。如果<code>MIN_WARPS_PER_EU</code>为1，则内核可以使用多处理器支持的所有寄存器。</li>
<li>编译器通过溢出寄存器（到共享或全局内存）或使用更多指令，确保内核中使用的寄存器小于两个允许的最大值。</li>
<li>编译器可以使用启发式方法来增加寄存器使用量，或者可以简单地避免溢出。<code>MAX_THREADS_PER_BLOCK</code>在这种情况下特别有用，因为它允许编译器使用更多寄存器，并避免编译器限制寄存器使用（可能溢出）以满足启动时从未使用过的大数据块大小的要求。</li>
</ul>
<h4 id="CU-and-EU-Definitions"><a href="#CU-and-EU-Definitions" class="headerlink" title="CU and EU Definitions"></a>CU and EU Definitions</h4><p>计算单元（CU）负责执行一个工作组的wave。它由一个或多个负责执行wave的执行单元（EU）组成。一个EU可以有足够的资源来维持不止一个执行wave的状态。这使得EU可以通过以与CPU上的对称多线程类似的方式在wave之间切换来隐藏延迟。为了适应EU的多个wave，一个wave所使用的资源必须受到限制。限制这样的资源可以允许更大的延迟隐藏，但这可能导致不得不将某些寄存器状态泄漏到内存中。该属性允许高级开发人员调整能够适应EU资源的wave数量。它可以用于确保至少有一个特定的数字适合于隐藏延迟，也可以用于确保不超过某个特定的数量适合于限制缓存抖动。</p>
<h4 id="Porting-from-CUDA-launch-bounds"><a href="#Porting-from-CUDA-launch-bounds" class="headerlink" title="Porting from CUDA __launch_bounds"></a>Porting from CUDA __launch_bounds</h4><p>CUDA 定义了<code>__launch_bounds</code>，用于去控制占用。</p>
<p><code>__launch_bounds(MAX_THREADS_PER_BLOCK, MIN_BLOCKS_PER_MULTIPROCESSOR)</code></p>
<p>第二个参数 <code>__launch_bounds</code>必须被转换为<code>__hip_launch_bounds</code>的格式，它使用warps和执行单元EU，而不是blocks 和multiprocessors</p>
<p><code>MIN_WARPS_PER_EXECUTION_UNIT = (MIN_BLOCKS_PER_MULTIPROCESSOR * MAX_THREADS_PER_BLOCK) / 32</code></p>
<p>接口的主要区别在于：</p>
<ul>
<li>Warps（而不是块）：开发人员试图告诉编译器控制资源利用率，以保证一定数量的活动Warps/EU用于延迟隐藏。以块为单位指定活动warp似乎隐藏了warp大小的微观结构细节，然而，这会使接口更加混乱，因为开发人员最终需要计算warp的数量以获得所需的控制级别。</li>
<li>执行单元（而非多处理器）：使用执行单元而不是多处理器为具有多个执行单元/多处理器的体系结构提供支持。例如，AMD GCN架构每个多处理器有4个执行单元。<code>hipDeviceProps</code>有一个字段<code>executionUnitsPerMultiprocessor</code>。如果需要，可以使用平台特定的编码技术（如<code>#ifdef</code>）为NVCC和HIP Clang平台指定不同的<code>launch_bound</code>。</li>
</ul>
<h4 id="Maxregcount"><a href="#Maxregcount" class="headerlink" title="Maxregcount"></a>Maxregcount</h4><p>与nvcc不同，HIP Clang不支持<code>--maxregcount</code>选项。相反，我们鼓励用户使用<code>hip_launch_bounds</code>指令，因为这些参数比寄存器等微架构细节更直观和可移植，而且该指令允许每个内核控制，而不是整个文件。<code>hip_launch_bounds</code>同时适用于hip Clang和nvcc</p>
<h3 id="Register-Keyword"><a href="#Register-Keyword" class="headerlink" title="Register Keyword"></a>Register Keyword</h3><p>register关键字在C++中被弃用，nvcc和HIP Clang都会默默忽略。可以将选项“-Wdeprecated register”传递给编译器警告消息。</p>
<h3 id="Pragma-Unroll"><a href="#Pragma-Unroll" class="headerlink" title="Pragma Unroll"></a>Pragma Unroll</h3><p>支持使用编译时已知的绑定展开。例如：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> unroll 16 <span class="comment">/* hint to compiler to unroll next loop by 16 */</span></span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>; i&lt;<span class="number">16</span>; i++) ...</span><br><span class="line"><span class="meta">#<span class="keyword">pragma</span> unroll 1 <span class="comment">/* tell compiler to never unroll the loop */</span></span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>; i&lt;<span class="number">16</span>; i++) ...</span><br><span class="line"><span class="meta">#<span class="keyword">pragma</span> unroll <span class="comment">/* hint to compiler to completely unroll next loop. */</span></span></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>; i&lt;<span class="number">16</span>; i++) ...</span><br></pre></td></tr></table></figure>
<h3 id="In-Line-Assembly"><a href="#In-Line-Assembly" class="headerlink" title="In-Line Assembly"></a>In-Line Assembly</h3><p>支持GCN ISA内联汇编。例如：</p>
<p><code>asm volatile (&quot;v_mac_f32_e32 %0, %2, %3&quot; : &quot;=v&quot; (out[i]) : &quot;0&quot;(out[i]), &quot;v&quot; (a), &quot;v&quot; (in[i]));</code></p>
<p>HIP编译器使用<code>asm()</code> 语句将GCN插入内核。使用volatile关键字，以便优化器不得改变volatile操作的数量或相对于其他volatile运算改变其执行顺序。<code>v_mac_f32_e32</code>是GCN指令。有关更多信息，请参阅AMD GCN3 ISA体系结构手册。按顺序排列的各个操作数的索引由<code>%</code>提供，后跟操作数列表中的位置“v”是32位VGPR寄存器的约束代码（针对特定于目标的AMDGPU）。有关更多信息，请参阅AMDGPU支持的约束代码列表。输出约束由“=”前缀指定，如上所示（“=v”）。这表示程序集将写入此操作数，然后该操作数将作为asm表达式的返回值可用。输入约束没有前缀-只有约束代码。约束字符串“0”表示将指定的输出寄存器也用作输入（它是第0个约束）。</p>
<h3 id="C-Support"><a href="#C-Support" class="headerlink" title="C++ Support"></a>C++ Support</h3><p>以下C++特性不支持:</p>
<ul>
<li>Run-time-type information (RTTI)</li>
<li>Virtual functions</li>
<li>Try/catch  </li>
</ul>
<h3 id="Kernel-Compilation"><a href="#Kernel-Compilation" class="headerlink" title="Kernel Compilation"></a>Kernel Compilation</h3><p>hipcc现在支持将C++/HIP内核编译为二进制代码对象。</p>
<p>二进制文件的文件格式为“.co”，表示代码对象。以下命令使用“hipcc”构建代码对象。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">`hipcc --genco --offload-arch=[TARGET GPU] [INPUT FILE] -o [OUTPUT FILE]`</span><br><span class="line">[TARGET GPU] = GPU architecture</span><br><span class="line">[INPUT FILE] = Name of the file containing kernels</span><br><span class="line">[OUTPUT FILE] = Name of the generated code object file</span><br></pre></td></tr></table></figure>
<h2 id="ROCm-Code-Object-Tooling"><a href="#ROCm-Code-Object-Tooling" class="headerlink" title="ROCm Code Object Tooling"></a>ROCm Code Object Tooling</h2><p>ROCm编译器生成的代码对象（可执行文件、对象文件和共享对象库）可以使用本节中列出的工具进行检查和提取。</p>
<h3 id="roc-obj"><a href="#roc-obj" class="headerlink" title="roc-obj"></a>roc-obj</h3><h4 id="Examples"><a href="#Examples" class="headerlink" title="Examples"></a>Examples</h4><p>从一系列可执行文件中抽取对象</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">roc-obj &lt;executable&gt;...</span><br></pre></td></tr></table></figure>
<p>从所有可执行文件中抽取ROCm代码对象，并反汇编：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">roc-obj --disassemble &lt;executable&gt;...</span><br><span class="line">roc-obj -d &lt;executable&gt;...</span><br></pre></td></tr></table></figure>
<h2 id="HIP-Logging"><a href="#HIP-Logging" class="headerlink" title="HIP Logging"></a>HIP Logging</h2><p>HIP提供了日志机制来监控HIP代码运行，根据日志级别和掩码，HIP将为不同的函数类别打印出不同的日志信息。</p>
<h3 id="HIP-Logging-Level"><a href="#HIP-Logging-Level" class="headerlink" title="HIP Logging Level"></a>HIP Logging Level</h3><p>HIP日志默认关闭，可以通过设置<code>AMD_LOG_LEVEL</code>打开，不同的值定义了不同的日志级别。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">LogLevel</span> &#123;</span><br><span class="line">    LOG_NONE = <span class="number">0</span>,</span><br><span class="line">    LOG_ERROR = <span class="number">1</span>,</span><br><span class="line">    LOG_WARNING = <span class="number">2</span>,</span><br><span class="line">    LOG_INFO = <span class="number">3</span>,</span><br><span class="line">    LOG_DEBUG = <span class="number">4</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="HIP-Logging-Mask"><a href="#HIP-Logging-Mask" class="headerlink" title="HIP Logging Mask"></a>HIP Logging Mask</h3><p>日志掩码在运行时可以被设置为不同的值以输出不同的函数。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">LogMask</span> &#123;</span><br><span class="line">    LOG_API = <span class="number">0x00000001</span>, <span class="comment">//!&lt; API call</span></span><br><span class="line">    LOG_CMD = <span class="number">0x00000002</span>, <span class="comment">//!&lt; Kernel and Copy Commands and Barriers</span></span><br><span class="line">    LOG_WAIT = <span class="number">0x00000004</span>, <span class="comment">//!&lt; Synchronization and waiting for commands to finish</span></span><br><span class="line">    LOG_AQL = <span class="number">0x00000008</span>, <span class="comment">//!&lt; Decode and display AQL packets</span></span><br><span class="line">    LOG_QUEUE = <span class="number">0x00000010</span>, <span class="comment">//!&lt; Queue commands and queue contents</span></span><br><span class="line">    LOG_SIG = <span class="number">0x00000020</span>, <span class="comment">//!&lt; Signal creation, allocation, pool</span></span><br><span class="line">    LOG_LOCK = <span class="number">0x00000040</span>, <span class="comment">//!&lt; Locks and thread-safety code.</span></span><br><span class="line">    LOG_KERN = <span class="number">0x00000080</span>, <span class="comment">//!&lt; kernel creations and arguments, etc.</span></span><br><span class="line">    LOG_COPY = <span class="number">0x00000100</span>, <span class="comment">//!&lt; Copy debug</span></span><br><span class="line">    LOG_COPY2 = <span class="number">0x00000200</span>, <span class="comment">//!&lt; Detailed copy debug</span></span><br><span class="line">    LOG_RESOURCE = <span class="number">0x00000400</span>, <span class="comment">//!&lt; Resource allocation, performance-impacting events.</span></span><br><span class="line">    LOG_INIT = <span class="number">0x00000800</span>, <span class="comment">//!&lt; Initialization and shutdown</span></span><br><span class="line">    LOG_MISC = <span class="number">0x00001000</span>, <span class="comment">//!&lt; misc debug, not yet classified</span></span><br><span class="line">    LOG_AQL2 = <span class="number">0x00002000</span>, <span class="comment">//!&lt; Show raw bytes of AQL packet</span></span><br><span class="line">    LOG_CODE = <span class="number">0x00004000</span>, <span class="comment">//!&lt; Show code creation debug</span></span><br><span class="line">    LOG_CMD2 = <span class="number">0x00008000</span>, <span class="comment">//!&lt; More detailed command info, including barrier commands</span></span><br><span class="line">    LOG_LOCATION = <span class="number">0x00010000</span>, <span class="comment">//!&lt; Log message location</span></span><br><span class="line">    LOG_ALWAYS = <span class="number">0xFFFFFFFF</span>, <span class="comment">//!&lt; Log always even mask flag is zero</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>一旦<code>AMD_LOG_LEVEL</code>被设置，日志掩码将被设置为默认的0x7FFFFFFF，同样有一个环境变量<code>AMD_LOG_MASK</code>可以被设置。</p>
<h3 id="HIP-Logging-Command"><a href="#HIP-Logging-Command" class="headerlink" title="HIP Logging Command"></a>HIP Logging Command</h3><p>为了输出HIP日志信息，函数被定义为：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> ClPrint(level, mask, format, ...)</span></span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (AMD_LOG_LEVEL &gt;= level) &#123;</span><br><span class="line">            <span class="keyword">if</span> (AMD_LOG_MASK &amp; mask || mask == amd::LOG_ALWAYS) &#123;</span><br><span class="line">                <span class="keyword">if</span> (AMD_LOG_MASK &amp; amd::LOG_LOCATION) &#123;</span><br><span class="line">	                amd::<span class="built_in">log_printf</span>(level, __FILENAME__, __LINE__, format, ##__VA_ARGS__);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    	            amd::<span class="built_in">log_printf</span>(level, <span class="string">&quot;&quot;</span>, <span class="number">0</span>, format, ##__VA_ARGS__);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">while</span> (<span class="literal">false</span>)</span><br></pre></td></tr></table></figure>
<p>在HIP代码中，调用<code>ClPrint()</code>，例如：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">ClPrint</span>(amd::LOG_INFO, amd::LOG_INIT, <span class="string">&quot;Initializing HSA stack.&quot;</span>);  </span><br></pre></td></tr></table></figure>
<h3 id="HIP-Logging-Example"><a href="#HIP-Logging-Example" class="headerlink" title="HIP Logging Example"></a>HIP Logging Example</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line">user@user-test:~/hip/bin$ <span class="built_in">export</span> AMD_LOG_LEVEL=4</span><br><span class="line">user@user-test:~/hip/bin$ ./hipinfo</span><br><span class="line">:3:rocdevice.cpp :453 : 23647210092: Initializing HSA stack.</span><br><span class="line">:3:comgrctx.cpp :33 : 23647639336: Loading COMGR library.</span><br><span class="line">:3:rocdevice.cpp :203 : 23647687108: Numa <span class="keyword">select</span> cpu</span><br><span class="line">agent[0]=0x13407c0(fine=0x13409a0,coarse=0x1340ad0) <span class="keyword">for</span> gpu agent=0x1346150</span><br><span class="line">:4:runtime.cpp :82 : 23647698669: init</span><br><span class="line">:3:hip_device_runtime.cpp :473 : 23647698869: 5617 : [7fad295dd840] hipGetDeviceCount: Returned hipSuccess</span><br><span class="line">:3:hip_device_runtime.cpp :502 : 23647698990: 5617 : [7fad295dd840] hipSetDevice ( 0 )</span><br><span class="line">:3:hip_device_runtime.cpp :507 : 23647699042: 5617 : [7fad295dd840] hipSetDevice: Returned hipSuccess</span><br><span class="line">--------------------------------------------------------------------------------</span><br><span class="line">device# 0</span><br><span class="line">:3:hip_device.cpp :150 : 23647699276: 5617 : [7fad295dd840] hipGetDeviceProperties (0x7ffdbe7db730, 0 )</span><br><span class="line">:3:hip_device.cpp :237 : 23647699335: 5617 : [7fad295dd840] hipGetDeviceProperties: Returned hipSuccess</span><br><span class="line">Name: Device 7341</span><br><span class="line">pciBusID: 3</span><br><span class="line">pciDeviceID: 0</span><br><span class="line">pciDomainID: 0</span><br><span class="line">multiProcessorCount: 11</span><br><span class="line">maxThreadsPerMultiProcessor: 2560</span><br><span class="line">isMultiGpuBoard: 0</span><br><span class="line">clockRate: 1900 Mhz</span><br><span class="line">memoryClockRate: 875 Mhz</span><br><span class="line">memoryBusWidth: 0</span><br><span class="line">clockInstructionRate: 1000 Mhz</span><br><span class="line">totalGlobalMem: 7.98 GB</span><br><span class="line">maxSharedMemoryPerMultiProcessor: 64.00 KB</span><br><span class="line">totalConstMem: 8573157376</span><br><span class="line">sharedMemPerBlock: 64.00 KB</span><br><span class="line">canMapHostMemory: 1</span><br><span class="line">regsPerBlock: 0</span><br><span class="line">warpSize: 32</span><br><span class="line">l2CacheSize: 0</span><br><span class="line">computeMode: 0</span><br><span class="line">maxThreadsPerBlock: 1024</span><br><span class="line">maxThreadsDim.x: 1024</span><br><span class="line">maxThreadsDim.y: 1024</span><br><span class="line">maxThreadsDim.z: 1024</span><br><span class="line">maxGridSize.x: 2147483647</span><br><span class="line">maxGridSize.y: 2147483647</span><br><span class="line">maxGridSize.z: 2147483647</span><br><span class="line">major: 10</span><br><span class="line">minor: 12</span><br><span class="line">concurrentKernels: 1</span><br><span class="line">cooperativeLaunch: 0</span><br><span class="line">cooperativeMultiDeviceLaunch: 0</span><br><span class="line">arch.hasGlobalInt32Atomics: 1</span><br><span class="line">arch.hasGlobalFloatAtomicExch: 1</span><br><span class="line">arch.hasSharedInt32Atomics: 1</span><br><span class="line">arch.hasSharedFloatAtomicExch: 1</span><br><span class="line">arch.hasFloatAtomicAdd: 1</span><br><span class="line">arch.hasGlobalInt64Atomics: 1</span><br><span class="line">arch.hasSharedInt64Atomics: 1</span><br><span class="line">arch.hasDoubles: 1</span><br><span class="line">arch.hasWarpVote: 1</span><br><span class="line">arch.hasWarpBallot: 1</span><br><span class="line">arch.hasWarpShuffle: 1</span><br><span class="line">arch.hasFunnelShift: 0</span><br><span class="line">arch.hasThreadFenceSystem: 1</span><br><span class="line">arch.hasSyncThreadsExt: 0</span><br><span class="line">arch.hasSurfaceFuncs: 0</span><br><span class="line">arch.has3dGrid: 1</span><br><span class="line">arch.hasDynamicParallelism: 0</span><br><span class="line">gcnArch: 1012</span><br><span class="line">isIntegrated: 0</span><br><span class="line">maxTexture1D: 65536</span><br><span class="line">maxTexture2D.width: 16384</span><br><span class="line">maxTexture2D.height: 16384</span><br><span class="line">maxTexture3D.width: 2048</span><br><span class="line">maxTexture3D.height: 2048</span><br><span class="line">maxTexture3D.depth: 2048</span><br><span class="line">isLargeBar: 0</span><br><span class="line">:3:hip_device_runtime.cpp :471 : 23647701557: 5617 : [7fad295dd840] hipGetDeviceCount (0x7ffdbe7db714 )</span><br><span class="line">:3:hip_device_runtime.cpp :473 : 23647701608: 5617 : [7fad295dd840] hipGetDeviceCount:Returned hipSuccess</span><br><span class="line">:3:hip_peer.cpp :76 : 23647701731: 5617 : [7fad295dd840] hipDeviceCanAccessPeer (0x7ffdbe7db728, 0, 0 )</span><br><span class="line">:3:hip_peer.cpp :60 : 23647701784: 5617 : [7fad295dd840] canAccessPeer: Returned hipSuccess</span><br><span class="line">:3:hip_peer.cpp :77 : 23647701831: 5617 : [7fad295dd840] hipDeviceCanAccessPeer: Returned hipSuccess</span><br><span class="line">peers:</span><br><span class="line">:3:hip_peer.cpp :76 : 23647701921: 5617 : [7fad295dd840] hipDeviceCanAccessPeer ( 0x7ffdbe7db728, 0, 0 )</span><br><span class="line">:3:hip_peer.cpp :60 : 23647701965: 5617 : [7fad295dd840] canAccessPeer: Returned hipSuccess</span><br><span class="line">:3:hip_peer.cpp :77 : 23647701998: 5617 : [7fad295dd840] hipDeviceCanAccessPeer: Returned hipSuccess</span><br><span class="line">non-peers: device#0</span><br><span class="line">:3:hip_memory.cpp :345 : 23647702191: 5617 : [7fad295dd840] hipMemGetInfo ( 0x7ffdbe7db718, 0x7ffdbe7db720 )</span><br><span class="line">:3:hip_memory.cpp :360 : 23647702243: 5617 : [7fad295dd840] hipMemGetInfo: Returned hipSuccess</span><br><span class="line">memInfo.total: 7.98 GB</span><br><span class="line">memInfo.free: 7.98 GB (100%)</span><br></pre></td></tr></table></figure>
<h2 id="Debugging-HIP"><a href="#Debugging-HIP" class="headerlink" title="Debugging HIP"></a>Debugging HIP</h2><h3 id="Debugging-tools"><a href="#Debugging-tools" class="headerlink" title="Debugging tools"></a>Debugging tools</h3><h4 id="Using-ltrace"><a href="#Using-ltrace" class="headerlink" title="Using ltrace"></a>Using ltrace</h4><p>ltrace是一个标准的linux工具，它在每次动态库调用时都会向stderr提供消息。由于ROCr和ROCt（ROC thunk，是ROC内核驱动程序的用户空间接口）都是动态库，因此这提供了一种简单的方法来跟踪这些库中的活动。在使用命令行调试器深入了解细节之前，跟踪可以是快速观察应用程序流的强大方式。ltrace是可视化整个ROCm软件堆栈的运行时行为的有用工具。跟踪还可以显示与关键路径上对费时API的意外调用相关的性能问题。</p>
<p>跟踪HIP API和输出的命令行：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ ltrace -C -e <span class="string">&quot;hip*&quot;</span> ./hipGetChanDesc</span><br><span class="line">hipGetChanDesc-&gt;hipCreateChannelDesc(0x7ffdc4b66860, 32, 0, 0) = 0x7ffdc4b66860</span><br><span class="line">hipGetChanDesc-&gt;hipMallocArray(0x7ffdc4b66840, 0x7ffdc4b66860, 8, 8) = 0</span><br><span class="line">hipGetChanDesc-&gt;hipGetChannelDesc(0x7ffdc4b66848, 0xa63990, 5, 1) = 0</span><br><span class="line">hipGetChanDesc-&gt;hipFreeArray(0xa63990, 0, 0x7f8c7fe13778, 0x7ffdc4b66848) = 0</span><br><span class="line">PASSED!</span><br><span class="line">+++ exited (status 0) +++</span><br></pre></td></tr></table></figure>
<p>命令行仅跟踪API和输出：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">$ ltrace -C -e <span class="string">&quot;hsa*&quot;</span> ./hipGetChanDesc</span><br><span class="line">libamdhip64.so.4-&gt;hsa_init(0, 0x7fff325a69d0, 0x9c80e0, 0 &lt;unfinished ...&gt;</span><br><span class="line">libhsa-runtime64.so.1-&gt;hsaKmtOpenKFD(0x7fff325a6590, 0x9c38c0, 0, 1) = 0</span><br><span class="line">libhsa-runtime64.so.1-&gt;hsaKmtGetVersion(0x7fff325a6608, 0, 0, 0) = 0</span><br><span class="line">libhsa-runtime64.so.1-&gt;hsaKmtReleaseSystemProperties(3, 0x80084b01, 0, 0) = 0</span><br><span class="line">libhsa-runtime64.so.1-&gt;hsaKmtAcquireSystemProperties(0x7fff325a6610, 0, 0, 1) = 0</span><br><span class="line">libhsa-runtime64.so.1-&gt;hsaKmtGetNodeProperties(0, 0x7fff325a66a0, 0, 0) = 0</span><br><span class="line">libhsa-runtime64.so.1-&gt;hsaKmtGetNodeMemoryProperties(0, 1, 0x9c42b0, 0x936012) = 0</span><br><span class="line">...</span><br><span class="line">&lt;... hsaKmtCreateEvent resumed&gt; ) = 0</span><br><span class="line">libhsa-runtime64.so.1-&gt;hsaKmtAllocMemory(0, 4096, 64, 0x7fff325a6690) = 0</span><br><span class="line">libhsa-runtime64.so.1-&gt;hsaKmtMapMemoryToGPUNodes(0x7f1202749000, 4096, 0x7fff325a6690, 0) = 0</span><br><span class="line">libhsa-runtime64.so.1-&gt;hsaKmtCreateEvent(0x7fff325a6700, 0, 0, 0x7fff325a66f0) = 0</span><br><span class="line">libhsa-runtime64.so.1-&gt;hsaKmtAllocMemory(1, 0x100000000, 576, 0x7fff325a67d8) = 0</span><br><span class="line">libhsa-runtime64.so.1-&gt;hsaKmtAllocMemory(0, 8192, 64, 0x7fff325a6790) = 0</span><br><span class="line">libhsa-runtime64.so.1-&gt;hsaKmtMapMemoryToGPUNodes(0x7f120273c000, 8192, 0x7fff325a6790, 0) = 0</span><br><span class="line">libhsa-runtime64.so.1-&gt;hsaKmtAllocMemory(0, 4096, 4160, 0x7fff325a6450) = 0</span><br><span class="line">libhsa-runtime64.so.1-&gt;hsaKmtMapMemoryToGPUNodes(0x7f120273a000, 4096, 0x7fff325a6450, 0) = 0</span><br><span class="line">libhsa-runtime64.so.1-&gt;hsaKmtSetTrapHandler(1, 0x7f120273a000, 4096, 0x7f120273c000) = 0</span><br><span class="line">&lt;... hsa_init resumed&gt; ) = 0</span><br><span class="line">libamdhip64.so.4-&gt;hsa_system_get_major_extension_table(513, 1, 24, 0x7f1202597930) = 0</span><br><span class="line">libamdhip64.so.4-&gt;hsa_iterate_agents(0x7f120171f050, 0, 0x7fff325a67f8, 0 &lt;unfinished ...&gt;</span><br><span class="line">libamdhip64.so.4-&gt;hsa_agent_get_info(0x94f110, 17, 0x7fff325a67e8, 0) = 0</span><br><span class="line">libamdhip64.so.4-&gt;hsa_amd_agent_iterate_memory_pools(0x94f110, 0x7f1201722816, 0x7fff325a67f0,</span><br><span class="line">0x7f1201722816 &lt;unfinished ...&gt;</span><br><span class="line">libamdhip64.so.4-&gt;hsa_amd_memory_pool_get_info(0x9c7fb0, 0, 0x7fff325a6744, 0x7fff325a67f0) = 0</span><br><span class="line">libamdhip64.so.4-&gt;hsa_amd_memory_pool_get_info(0x9c7fb0, 1, 0x7fff325a6748, 0x7f1200d82df4) = 0</span><br><span class="line">...</span><br><span class="line">&lt;... hsa_amd_agent_iterate_memory_pools resumed&gt; ) = 0</span><br><span class="line">libamdhip64.so.4-&gt;hsa_agent_get_info(0x9dbf30, 17, 0x7fff325a67e8, 0) = 0</span><br><span class="line">&lt;... hsa_iterate_agents resumed&gt; ) = 0</span><br><span class="line">libamdhip64.so.4-&gt;hsa_agent_get_info(0x9dbf30, 0, 0x7fff325a6850, 3) = 0</span><br><span class="line">libamdhip64.so.4-&gt;hsa_agent_get_info(0x9dbf30, 0xa000, 0x9e7cd8, 0) = 0</span><br><span class="line">libamdhip64.so.4-&gt;hsa_agent_iterate_isas(0x9dbf30, 0x7f1201720411, 0x7fff325a6760,</span><br><span class="line">0x7f1201720411) = 0</span><br><span class="line">libamdhip64.so.4-&gt;hsa_isa_get_info_alt(0x94e7c8, 0, 0x7fff325a6728, 1) = 0</span><br><span class="line">libamdhip64.so.4-&gt;hsa_isa_get_info_alt(0x94e7c8, 1, 0x9e7f90, 0) = 0</span><br><span class="line">libamdhip64.so.4-&gt;hsa_agent_get_info(0x9dbf30, 4, 0x9e7ce8, 0) = 0</span><br><span class="line">...</span><br><span class="line">&lt;... hsa_amd_memory_pool_allocate resumed&gt; ) = 0</span><br><span class="line">libamdhip64.so.4-&gt;hsa_ext_image_create(0x9dbf30, 0xa1c4c8, 0x7f10f2800000, 3 &lt;unfinished ...&gt;</span><br><span class="line">libhsa-runtime64.so.1-&gt;hsaKmtAllocMemory(0, 4096, 64, 0x7fff325a6740) = 0</span><br><span class="line">libhsa-runtime64.so.1-&gt;hsaKmtQueryPointerInfo(0x7f1202736000, 0x7fff325a65e0, 0, 0) = 0</span><br><span class="line">libhsa-runtime64.so.1-&gt;hsaKmtMapMemoryToGPUNodes(0x7f1202736000, 4096, 0x7fff325a66e8, 0) = 0</span><br><span class="line">&lt;... hsa_ext_image_create resumed&gt; ) = 0</span><br><span class="line">libamdhip64.so.4-&gt;hsa_ext_image_destroy(0x9dbf30, 0x7f1202736000, 0x9dbf30, 0 &lt;unfinished ...&gt;</span><br><span class="line">libhsa-runtime64.so.1-&gt;hsaKmtUnmapMemoryToGPU(0x7f1202736000, 0x7f1202736000, 4096, 0x9c8050) =</span><br><span class="line">0</span><br><span class="line">libhsa-runtime64.so.1-&gt;hsaKmtFreeMemory(0x7f1202736000, 4096, 0, 0) = 0</span><br><span class="line">&lt;... hsa_ext_image_destroy resumed&gt; ) = 0</span><br><span class="line">libamdhip64.so.4-&gt;hsa_amd_memory_pool_free(0x7f10f2800000, 0x7f10f2800000, 256, 0x9e76f0) = 0</span><br><span class="line">PASSED!</span><br></pre></td></tr></table></figure>
<h4 id="Using-ROCgdb"><a href="#Using-ROCgdb" class="headerlink" title="Using ROCgdb"></a>Using ROCgdb</h4><p>ROCm上的HIP开发人员可以使用AMD的ROCgdb进行调试和分析。ROCgdb是Linux的ROCm源代码级调试器，基于GNU源代码级调试程序GDB。它类似于cuda gdb。它可以用于调试器前端，如eclipse、vscode或gdbdashboard。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:/opt/rocm/bin</span><br><span class="line">$ rocgdb ./hipTexObjPitch</span><br><span class="line">GNU gdb (rocm-dkms-no-npi-hipclang-6549) 10.1</span><br><span class="line">Copyright (C) 2020 Free Software Foundation, Inc.</span><br><span class="line">License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;</span><br><span class="line">...</span><br><span class="line">For bug reporting instructions, please see:</span><br><span class="line">&lt;https://github.com/ROCm-Developer-Tools/ROCgdb/issues&gt;.</span><br><span class="line">Find the GDB manual and other documentation resources online at:</span><br><span class="line">&lt;http://www.gnu.org/software/gdb/documentation/&gt;.</span><br><span class="line">...</span><br><span class="line">Reading symbols from ./hipTexObjPitch...</span><br><span class="line">(gdb) <span class="built_in">break</span> main</span><br><span class="line">Breakpoint 1 at 0x4013d1: file /home/test/hip/tests/src/texture/hipTexObjPitch.cpp, line 98.</span><br><span class="line">(gdb) run</span><br><span class="line">Starting program: /home/test/hip/build/directed_tests/texture/hipTexObjPitch</span><br><span class="line">[Thread debugging using libthread_db enabled]</span><br><span class="line">Using host libthread_db library <span class="string">&quot;/lib/x86_64-linux-gnu/libthread_db.so.1&quot;</span>.</span><br><span class="line">Breakpoint 1, main ()</span><br><span class="line">at /home/test/hip/tests/src/texture/hipTexObjPitch.cpp:98</span><br><span class="line">98 texture2Dtest&lt;<span class="built_in">float</span>&gt;();</span><br><span class="line">(gdb)c</span><br></pre></td></tr></table></figure>
<h3 id="Debugging-HIP-Applications"><a href="#Debugging-HIP-Applications" class="headerlink" title="Debugging HIP Applications"></a>Debugging HIP Applications</h3><p>下面的示例显示了如何在运行应用程序时从调试器获取有用的信息，这会导致GPUVM错误问题。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">Memory access fault by GPU node-1 on address 0x5924000. Reason: Page not present or supervisor</span><br><span class="line">privilege.</span><br><span class="line">Program received signal SIGABRT, Aborted.</span><br><span class="line">[Switching to Thread 0x7fffdffb5700 (LWP 14893)]</span><br><span class="line">0x00007ffff2057c37 <span class="keyword">in</span> __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56</span><br><span class="line">56 ../nptl/sysdeps/unix/sysv/linux/raise.c: No such file or directory.</span><br><span class="line">(gdb) bt</span><br><span class="line"><span class="comment">#0 0x00007ffff2057c37 in __GI_raise (sig=sig@entry=6) at</span></span><br><span class="line">../nptl/sysdeps/unix/sysv/linux/raise.c:56</span><br><span class="line"><span class="comment">#1 0x00007ffff205b028 in __GI_abort () at abort.c:89</span></span><br><span class="line"><span class="comment">#2 0x00007ffff6f960eb in ?? () from /opt/rocm/hsa/lib/libhsa-runtime64.so.1</span></span><br><span class="line"><span class="comment">#3 0x00007ffff6f99ea5 in ?? () from /opt/rocm/hsa/lib/libhsa-runtime64.so.1</span></span><br><span class="line"><span class="comment">#4 0x00007ffff6f78107 in ?? () from /opt/rocm/hsa/lib/libhsa-runtime64.so.1</span></span><br><span class="line"><span class="comment">#5 0x00007ffff744f184 in start_thread (arg=0x7fffdffb5700) at pthread_create.c:312</span></span><br><span class="line"><span class="comment">#6 0x00007ffff211b37d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111</span></span><br><span class="line">(gdb) info threads</span><br><span class="line">Id Target Id Frame</span><br><span class="line">4 Thread 0x7fffdd521700 (LWP 14895) <span class="string">&quot;caffe&quot;</span> pthread_cond_wait@@GLIBC_2.3.2 () at</span><br><span class="line">../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185</span><br><span class="line">3 Thread 0x7fffddd22700 (LWP 14894) <span class="string">&quot;caffe&quot;</span> pthread_cond_wait@@GLIBC_2.3.2 () at</span><br><span class="line">../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185</span><br><span class="line">* 2 Thread 0x7fffdffb5700 (LWP 14893) <span class="string">&quot;caffe&quot;</span> 0x00007ffff2057c37 <span class="keyword">in</span> __GI_raise</span><br><span class="line">(sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56</span><br><span class="line">1 Thread 0x7ffff7fa6ac0 (LWP 14892) <span class="string">&quot;caffe&quot;</span> 0x00007ffff6f934d5 <span class="keyword">in</span> ?? () from</span><br><span class="line">/opt/rocm/hsa/lib/libhsa-runtime64.so.1</span><br><span class="line">(gdb) thread 1</span><br><span class="line">[Switching to thread 1 (Thread 0x7ffff7fa6ac0 (LWP 14892))]</span><br><span class="line"><span class="comment">#0 0x00007ffff6f934d5 in ?? () from /opt/rocm/hsa/lib/libhsa-runtime64.so.1</span></span><br><span class="line">(gdb) bt</span><br><span class="line"><span class="comment">#0 0x00007ffff6f934d5 in ?? () from /opt/rocm/hsa/lib/libhsa-runtime64.so.1</span></span><br><span class="line"><span class="comment">#1 0x00007ffff6f929ba in ?? () from /opt/rocm/hsa/lib/libhsa-runtime64.so.1</span></span><br><span class="line"><span class="comment">#2 0x00007fffe080beca in HSADispatch::waitComplete() () from /opt/rocm/hcc/lib/libmcwamp_hsa.so</span></span><br><span class="line"><span class="comment">#3 0x00007fffe080415f in HSADispatch::dispatchKernelAsync(Kalmar::HSAQueue*, void const*, int,</span></span><br><span class="line">bool) () from /opt/rocm/hcc/lib/libmcwamp_hsa.so</span><br><span class="line"><span class="comment">#4 0x00007fffe080238e in Kalmar::HSAQueue::dispatch_hsa_kernel(hsa_kernel_dispatch_packet_s</span></span><br><span class="line">const*, void const*, unsigned long, hc::completion_future*) () from</span><br><span class="line">/opt/rocm/hcc/lib/libmcwamp_hsa.so</span><br><span class="line"><span class="comment">#5 0x00007ffff7bb7559 in hipModuleLaunchKernel () from /opt/rocm/hip/lib/libhip_hcc.so</span></span><br><span class="line"><span class="comment">#6 0x00007ffff2e6cd2c in mlopen::HIPOCKernel::run (this=0x7fffffffb5a8, args=0x7fffffffb2a8,</span></span><br><span class="line">size=80) at /root/MIOpen/src/hipoc/hipoc_kernel.cpp:15</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<h3 id="Useful-Environment-Variables"><a href="#Useful-Environment-Variables" class="headerlink" title="Useful Environment Variables"></a>Useful Environment Variables</h3><p>HIP提供了允许HIP、HIP-clang或HSA驱动程序禁用功能或优化的环境变量。这些不适用于生产，但可用于诊断应用程序（或驱动程序）中的同步问题。有关环境变量的描述，请参见以下章节。它们在ROCm路径上受支持。</p>
<h4 id="Kernel-Enqueue-Serialization-内核排队序列化"><a href="#Kernel-Enqueue-Serialization-内核排队序列化" class="headerlink" title="Kernel Enqueue Serialization  内核排队序列化"></a>Kernel Enqueue Serialization  内核排队序列化</h4><p>开发人员可以使用环境变量从主机控制内核命令序列化，</p>
<ul>
<li>AMD_SERIALIZE_KERNEL，用于序列化内核队列。</li>
<li>AMD_SERIALIZE_KERNEL=1，排队前等待完成，</li>
<li>AMD_SERIALIZE_KERNEL=2，排队后等待完成，</li>
<li>AMD_SERIALIZE_KERNEL=3，两者都有。或AMD_SERIALIZE_COPY，用于序列化副本。</li>
<li>AMD_SERIALIZE_COPY=1，排队前等待完成</li>
<li>AMD_SERIALIZE_COPY=2，排队后等待完成</li>
<li>AMD_SERIALIZE_COPY=3，两者都有。</li>
</ul>
<h4 id="Making-Device-Visible"><a href="#Making-Device-Visible" class="headerlink" title="Making Device Visible"></a>Making Device Visible</h4><p>对于具有多个设备的系统，可以通过设置环境变量<code>-HIP_visible_devices</code>使HIP只能看到某些设备。HIP只能看到序列中存在索引的设备。例如：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ HIP_VISIBLE_DEVICES=0,1</span><br></pre></td></tr></table></figure>
<p>或者在应用中：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (totalDeviceNum &gt; <span class="number">2</span>) &#123;</span><br><span class="line">    <span class="built_in">setenv</span>(<span class="string">&quot;HIP_VISIBLE_DEVICES&quot;</span>, <span class="string">&quot;0,1,2&quot;</span>, <span class="number">1</span>);</span><br><span class="line">    <span class="built_in">assert</span>(<span class="built_in">getDeviceNumber</span>(<span class="literal">false</span>) == <span class="number">3</span>);</span><br><span class="line">    ... ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="Dump-code-object"><a href="#Dump-code-object" class="headerlink" title="Dump code object"></a>Dump code object</h4><p>开发人员可以通过设置环境变量<code>GPU_dump_code_object</code>转储代码对象以分析编译器相关问题</p>
<h4 id="HSA-related-environment-variables"><a href="#HSA-related-environment-variables" class="headerlink" title="HSA related environment variables"></a>HSA related environment variables</h4><p>HSA提供环境变量帮助分析驱动程序或硬件中的问题。例如</p>
<ul>
<li><code>HSA_ENABLE_SDMA=0</code>它使主机到设备和设备到主机的副本使用计算着色器blit内核，而不是专用DMA复制引擎。计算着色器副本具有较低的延迟（通常小于5us），可以实现DMA副本引擎大约80%的带宽。此环境变量用于隔离硬件复制引擎的问题。</li>
<li><code>HSA_ENABLE_INTERRUPT=0</code>使用基于内存的轮询而非中断检测完成信号。此环境变量可用于诊断驱动程序中的中断风暴问题。</li>
</ul>
<h4 id="Summary-of-Environment-Variables-in-HIP"><a href="#Summary-of-Environment-Variables-in-HIP" class="headerlink" title="Summary of Environment Variables in HIP"></a>Summary of Environment Variables in HIP</h4><div class="table-container">
<table>
<thead>
<tr>
<th>Environment Variable</th>
<th>Default Value</th>
<th>Usage</th>
</tr>
</thead>
<tbody>
<tr>
<td>AMD_LOG_LEVEL Enable HIP log on different Levels.</td>
<td>0</td>
<td>0: Disable log. 1: Enable log on error level. 2: Enable log on warning and below levels. 0x3: Enable log on information and below levels. 0x4: Decode and display AQL packets.</td>
</tr>
<tr>
<td>AMD_LOG_MASK Enable HIP log on different Levels.</td>
<td>0x7FFFFFFF</td>
<td>0x1: Log API calls. 0x02: Kernel and Copy Commands and Barriers. 0x4: Synchronization and waiting for commands to finish. 0x8: Enable log on information and below levels. 0x20: Queue commands and queue contents. 0x40:Signal creation, allocation, pool. 0x80: Locks and thread-safety code. 0x100: Copy debug. 0x200: Detailed copy debug. 0x400: Resource allocation, performance-impacting events. 0x800: Initialization and shutdown. 0x1000: Misc debug, not yet classified. 0x2000: Show raw bytes of AQL packet. 0x4000: Show code creation debug. 0x8000: More detailed command info, including barrier commands. 0x10000: Log message location. 0xFFFFFFFF: Log always even mask flag is zero.</td>
</tr>
<tr>
<td>HIP_VISIBLE_DEVICES Only devices whose index is present in the sequence are visible to HIP.</td>
<td></td>
<td>0,1,2: Depending on the number of devices on the system.</td>
</tr>
<tr>
<td>GPU_DUMP_CODE_OBJECT Dump code object.</td>
<td>0</td>
<td>0: Disable. 1: Enable.</td>
</tr>
<tr>
<td>AMD_SERIALIZE_KERNEL Serialize kernel enqueue.</td>
<td>0</td>
<td>1: Wait for completion before enqueue. 2: Wait for completion after enqueue. 3: Both.</td>
</tr>
<tr>
<td>AMD_SERIALIZE_COPY Serialize copies.</td>
<td>0</td>
<td>1: Wait for completion before enqueue. 2: Wait for completion after enqueue. 3: Both.</td>
</tr>
<tr>
<td>HIP_HOST_COHERENT Coherent memory in hipHostMalloc.</td>
<td>0</td>
<td>0: memory is not coherent between host and GPU. 1: memory is coherent with host.</td>
</tr>
<tr>
<td>AMD_DIRECT_DISPATCH Enable direct kernel dispatch.</td>
<td>0</td>
<td>0: Disable. 1: Enable</td>
</tr>
</tbody>
</table>
</div>
<h3 id="General-Debugging-Tips"><a href="#General-Debugging-Tips" class="headerlink" title="General Debugging Tips"></a>General Debugging Tips</h3><ul>
<li>“gdb —args”可用于方便地将可执行文件和参数传递给gdb。</li>
<li>从GDB中，您可以设置环境变量“set env”。请注意，该命令不使用“=”符号：<code>（gdb）set env AMD_SERIALIZE_KERNEL 3</code></li>
<li>故障将由运行时捕获，但实际上是由GPU上运行的异步命令生成的。因此，GDB回溯将在运行时显示路径。</li>
<li>为了确定故障的真实位置，通过查看环境变量<code>AMD_SERIALIZE_KERNEL=3 AMD_SERALIZE_COPY=3</code>，强制内核同步执行。这将迫使HIP运行时在重新调整之前等待内核完成执行。如果错误发生在内核执行过程中，您可以在回溯中看到启动内核的代码。需要进行一些猜测来确定哪个线程实际导致了问题——通常是在<code>libhsaruntime64.so</code>中等待的线程。</li>
<li>内核内部的VM故障可能由以下原因引起：<ul>
<li>不正确的代码（即延伸超过阵列边界的循环），</li>
<li>内存问题-无效的内核参数（空指针、未注册的主机指针、坏指针），</li>
<li>同步问题，</li>
<li>编译器问题（编译器生成的代码不正确），</li>
<li>运行时问题。</li>
</ul>
</li>
</ul>
<h2 id="HIP-Version"><a href="#HIP-Version" class="headerlink" title="HIP Version"></a>HIP Version</h2><p>自ROCm v4.2发布以来，HIP版本定义更新如下：<code>HIP_VERSION=HIP_VERSION_MAJOR * 10000000 + HIP_VERSION_MINOR * 100000 + HIP_VERSION_PATCH)</code>，HIP版本可以从以下HIP API调用中查询，<code>hipRuntimeGetVersion(&amp;runtimeVersion);</code>。</p>
<h1 id="Transiting-from-CUDA-to-HIP"><a href="#Transiting-from-CUDA-to-HIP" class="headerlink" title="Transiting from CUDA to HIP"></a>Transiting from CUDA to HIP</h1><h2 id="Transition-Tool-HIPIFY"><a href="#Transition-Tool-HIPIFY" class="headerlink" title="Transition Tool: HIPIFY"></a>Transition Tool: HIPIFY</h2><h3 id="Sample-and-Practice"><a href="#Sample-and-Practice" class="headerlink" title="Sample and Practice"></a>Sample and Practice</h3><p>Add hip/bin path to the PATH.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:[MYHIP]/bin</span><br></pre></td></tr></table></figure>
<p>Define the environment variable.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">export</span> HIP_PATH=[MYHIP]</span><br></pre></td></tr></table></figure>
<p>Build an executable file.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> ~/hip/samples/0_Intro/square</span><br><span class="line">$ make</span><br><span class="line">/home/user/hip/bin/hipify-perl square.cu &gt; square.cpp</span><br><span class="line">/home/user/hip/bin/hipcc square.cpp -o square.out</span><br><span class="line">/home/user/hip/bin/hipcc -use-staticlib square.cpp -o square.out.static</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>Execute the file.</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ ./square.out</span><br><span class="line">info: running on device Vega20 [Radeon Pro W5500]</span><br><span class="line">info: allocate host mem ( 7.63 MB)</span><br><span class="line">info: allocate device mem ( 7.63 MB)</span><br><span class="line">info: copy Host2Device</span><br><span class="line">info: launch <span class="string">&#x27;vector_square&#x27;</span> kernel</span><br><span class="line">info: copy Device2Host</span><br><span class="line">info: check result</span><br><span class="line">PASSED!  </span><br></pre></td></tr></table></figure>
<h2 id="HIP-Porting-Process"><a href="#HIP-Porting-Process" class="headerlink" title="HIP Porting Process"></a>HIP Porting Process</h2><h3 id="Porting-a-New-CUDA-Project"><a href="#Porting-a-New-CUDA-Project" class="headerlink" title="Porting a New CUDA Project"></a>Porting a New CUDA Project</h3><h4 id="General-Tips"><a href="#General-Tips" class="headerlink" title="General Tips"></a>General Tips</h4><ul>
<li>在CUDA机器上启动端口通常是最简单的方法，因为您可以将部分代码增量地移植到HIP，而将其余代码留在CUDA中。（回想一下，在CUDA机器上，HIP只是CUDA上的一个薄层，因此这两种代码类型可以在nvcc平台上互操作。）此外，HIP端口可以与原始CUDA代码进行功能和性能比较。</li>
<li>CUDA代码移植到HIP并在CUDA机器上运行后，在AMD机器上使用HIP编译器编译HIP代码。</li>
<li>HIP端口可以取代CUDA版本：HIP可以提供与本地CUDA实现相同的性能，同时具有对Nvidia和AMD架构的可移植性以及未来C++标准支持的优势。您可以通过条件编译或将其添加到开源HIP基础结构来处理特定于平台的特性。</li>
<li>使用<code>bin/hipconvertinplace-perl.sh</code>发送CUDA源目录中的所有代码文件。</li>
</ul>
<h4 id="Scanning-existing-CUDA-code-to-scope-the-porting-effort-扫描现有CUDA代码以确定移植工作的范围"><a href="#Scanning-existing-CUDA-code-to-scope-the-porting-effort-扫描现有CUDA代码以确定移植工作的范围" class="headerlink" title="Scanning existing CUDA code to scope the porting effort  扫描现有CUDA代码以确定移植工作的范围"></a>Scanning existing CUDA code to scope the porting effort  扫描现有CUDA代码以确定移植工作的范围</h4><p><code>hipinspecte-perl.sh</code>工具将扫描源目录，以确定哪些文件包含CUDA代码，以及其中有多少代码可以自动转换。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&gt; <span class="built_in">cd</span> examples/rodinia_3.0/cuda/kmeans</span><br><span class="line">&gt; <span class="variable">$HIP_DIR</span>/bin/hipexamine-perl.sh.</span><br><span class="line">info: hipify ./kmeans.h =====&gt;</span><br><span class="line">info: hipify ./unistd.h =====&gt;</span><br><span class="line">info: hipify ./kmeans.c =====&gt;</span><br><span class="line">info: hipify ./kmeans_cuda_kernel.cu =====&gt;</span><br><span class="line">info: converted 40 CUDA-&gt;HIP refs( dev:0 mem:0 kern:0 <span class="built_in">builtin</span>:37 math:0 stream:0 event:0 err:0</span><br><span class="line">def:0 tex:3 other:0 ) warn:0 LOC:185</span><br><span class="line">info: hipify ./getopt.h =====&gt;</span><br><span class="line">info: hipify ./kmeans_cuda.cu =====&gt;</span><br><span class="line">info: converted 49 CUDA-&gt;HIP refs( dev:3 mem:32 kern:2 <span class="built_in">builtin</span>:0 math:0 stream:0 event:0 err:0</span><br><span class="line">def:0 tex:12 other:0 ) warn:0 LOC:311</span><br><span class="line">info: hipify ./rmse.c =====&gt;</span><br><span class="line">info: hipify ./cluster.c =====&gt;</span><br><span class="line">info: hipify ./getopt.c =====&gt;</span><br><span class="line">info: hipify ./kmeans_clustering.c =====&gt;</span><br><span class="line">info: TOTAL-converted 89 CUDA-&gt;HIP refs( dev:3 mem:32 kern:2 <span class="built_in">builtin</span>:37 math:0 stream:0 event:0</span><br><span class="line">err:0 def:0 tex:15 other:0 ) warn:0 LOC:3607</span><br><span class="line">kernels (1 total) : kmeansPoint(1)</span><br></pre></td></tr></table></figure>
<p>hipinspect-perl扫描指定目录中找到的每个代码文件（cpp、c、h、hpp等）：</p>
<ul>
<li>没有CUDA代码（kmeans.h）的文件只打印一行摘要，列出源文件名。</li>
<li>带有CUDA代码的文件打印找到的内容的摘要-例如，kmeans_CUDA_kernel.cu文件：</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">info: hipify ./kmeans_cuda_kernel.cu =====&gt;</span><br><span class="line">info: converted 40 CUDA-&gt;HIP refs( dev:0 mem:0 kern:0 <span class="built_in">builtin</span>:37 math:0 stream:0 event:0</span><br></pre></td></tr></table></figure>
<ul>
<li><p>kmeans_cuda_kernel.cu中的信息：</p>
<ul>
<li>有多少CUDA调用转换为HIP（40）</li>
<li>所用CUDA功能的分解（dev:0 mem:0等）。此文件使用了许多CUDA内置（37）和纹理函数（3）。</li>
<li>类似CUDA API但未转换的代码的警告（此文件中为0）。</li>
<li>计算此文件的代码行数（LOC）-185。</li>
</ul>
</li>
<li><p>hipinspect-perl还在流程结束时为所有文件收集的统计数据提供一份摘要。这与每文件报告的格式类似，还包括所有已调用内核的列表。上面的示例：</p>
</li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">info: TOTAL-converted 89 CUDA-&gt;HIP refs( dev:3 mem:32 kern:2 <span class="built_in">builtin</span>:37 math:0 stream:0 event:0</span><br><span class="line">err:0 def:0 tex:15 other:0 ) warn:0 LOC:3607</span><br><span class="line">kernels (1 total) : kmeansPoint(1)</span><br></pre></td></tr></table></figure>
<h4 id="Converting-a-project-in-place"><a href="#Converting-a-project-in-place" class="headerlink" title="Converting a project in-place"></a>Converting a project in-place</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hipify-perl --inplace  </span><br></pre></td></tr></table></figure>
<p>对于每个输入文件file，此脚本将：</p>
<ul>
<li>如果file.prehip文件不存在，请将原始代码复制到扩展名为.prehip的新文件中。然后将代码文件发送。</li>
<li>如果“FILE.previip”文件存在，请将FILE.prehip发送并保存到FILE。这对于测试hipify工具集的改进非常有用。</li>
</ul>
<p><code>hipconvertinplace-perl.sh</code>脚本将对指定目录中的所有代码文件执行就地转换。这在处理现有CUDA代码库时非常方便，因为脚本保留了现有的目录结构和文件名，并包含了工作。就地转换后，您可以查看代码以向目录名添加其他参数。</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt; hipconvertinplace-perl.sh MY_SRC_DIR</span><br></pre></td></tr></table></figure>
<h4 id="Library-Equivalents"><a href="#Library-Equivalents" class="headerlink" title="Library Equivalents"></a>Library Equivalents</h4><div class="table-container">
<table>
<thead>
<tr>
<th>CUDA Library</th>
<th>ROCm Library</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr>
<td>cuBLAS</td>
<td>rocBLAS</td>
<td>Basic Linear Algebra Subroutines</td>
</tr>
<tr>
<td>cuFFT</td>
<td>rocFFT</td>
<td>Fast Fourier Transfer Library</td>
</tr>
<tr>
<td>cuSPARSE</td>
<td>rocSPARSE</td>
<td>Sparse BLAS + SPMV</td>
</tr>
<tr>
<td>cuSolver</td>
<td>rocSOLVER</td>
<td>Lapack library</td>
</tr>
<tr>
<td>AMG-X</td>
<td>rocALUTION</td>
<td>Sparse iterative solvers and preconditioners with Geometric and Algebraic MultiGrid</td>
</tr>
<tr>
<td>Thrust</td>
<td>rocThrust</td>
<td>C++ parallel algorithms library</td>
</tr>
<tr>
<td>CUB</td>
<td>rocPRIM</td>
<td>Low Level Optimized Parallel Primitives</td>
</tr>
<tr>
<td>cuDNN</td>
<td>MIOpen</td>
<td>Deep learning Solver Library</td>
</tr>
<tr>
<td>cuRAND</td>
<td>rocRAND</td>
<td>Random Number Generator Library</td>
</tr>
<tr>
<td>EIGEN</td>
<td>EIGEN</td>
<td>C++ template library for linear algebra: matrices, vectors, numerical solvers,</td>
</tr>
<tr>
<td>NCCL</td>
<td>RCCL</td>
<td>Communications Primitives Library based on the MPI equivalents</td>
</tr>
</tbody>
</table>
</div>
<h3 id="Distinguishing-Compiler-Modes"><a href="#Distinguishing-Compiler-Modes" class="headerlink" title="Distinguishing Compiler Modes"></a>Distinguishing Compiler Modes</h3><h4 id="Identifying-HIP-Target-Platform"><a href="#Identifying-HIP-Target-Platform" class="headerlink" title="Identifying HIP Target Platform"></a>Identifying HIP Target Platform</h4><p>所有HIP项目都以AMD或NVIDIA平台为目标。平台会影响包含的头文件和用于链接的库。</p>
<ul>
<li>如果HIP平台以AMD为目标，则定义HIP_PLATFORM_AMD。注意，如果HIP平台针对AMD，则先前定义了HIP_PLATFORM_HCC。现在已弃用。</li>
<li>如果HIP平台以NVIDIA为目标，则定义HIP_PLATFORM_NVDIA。注意，如果HIP平台针对NVIDIA，则先前定义了HIP_PLATFORM_NVCC。现在已弃用</li>
</ul>
<h4 id="Identifying-the-Compiler-HIP-Clang-or-NVIDIA"><a href="#Identifying-the-Compiler-HIP-Clang-or-NVIDIA" class="headerlink" title="Identifying the Compiler: HIP-Clang or NVIDIA"></a>Identifying the Compiler: HIP-Clang or NVIDIA</h4><p>通常，了解底层编译器是HIP Clang还是NVIDIA是很有用的。这些知识可以保护特定于平台的代码或有助于特定于平台性能的调整</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __HIP_PLATFORM_AMD__</span></span><br><span class="line"><span class="comment">// Compiled with HIP-Clang</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __HIP_PLATFORM_NVIDIA__</span></span><br><span class="line"><span class="comment">// Compiled with nvcc</span></span><br><span class="line"><span class="comment">// Could be compiling with CUDA language extensions enabled (for example, a &quot;.cu file)</span></span><br><span class="line"><span class="comment">// Could be in pass-through mode to an underlying host compile OR (for example, a .cpp file)</span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __CUDACC__</span></span><br><span class="line"><span class="comment">// Compiled with nvcc (CUDA language extensions enabled)</span></span><br></pre></td></tr></table></figure>
<p>HIP Clang直接生成主机代码（使用Clang x86目标），而无需将代码传递给另一个主机编译器。因此，它们没有<code>__CUDACC__</code>定义的等价物。</p>
<h4 id="Identifying-Current-Compilation-Pass-Host-or-Device-识别当前编译过程：主机或设备"><a href="#Identifying-Current-Compilation-Pass-Host-or-Device-识别当前编译过程：主机或设备" class="headerlink" title="Identifying Current Compilation Pass: Host or Device  识别当前编译过程：主机或设备"></a>Identifying Current Compilation Pass: Host or Device  识别当前编译过程：主机或设备</h4><p>NVCC对代码进行两次传递：一次传递主机代码，一次传递设备代码。HIP Clang将对代码进行多次传递：一次用于主机代码，一次用于设备代码上的每个架构。当编译器（HIP-Clang或nvcc）为<code>__global__</code>内核内的设备或设备函数编译代码时，<code>__HIP_DEVICE_COMPILE__</code>设置为非零值。<code>__HIP_DEVICE_COMPILE__</code>可以替换<code>__CUDA_ARCH__</code>定义上的#ifdef检查。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//#ifdef__CUDA_ARCH__</span></span><br><span class="line"><span class="meta">#<span class="keyword">if</span> __HIP_DEVICE_COMPILE__</span></span><br></pre></td></tr></table></figure>
<p>与<code>__CUDA_ARCH__</code>不同，<code>__HIP_DEVICE_COMPILE__</code>值为1或未定义，它不表示目标设备的功能。</p>
<h3 id="Compiler-Defines-Summary"><a href="#Compiler-Defines-Summary" class="headerlink" title="Compiler Defines: Summary"></a>Compiler Defines: Summary</h3><div class="table-container">
<table>
<thead>
<tr>
<th>Define</th>
<th>HIP-Clang</th>
<th>nvcc</th>
<th>Other (GCC, ICC, Clang, etc.)</th>
</tr>
</thead>
<tbody>
<tr>
<td>HIP-related defines:</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>__HIP_PLATFORM_AMD__</code></td>
<td>Defined</td>
<td>Undefined</td>
<td>Defined if targeting AMD platform; undefined otherwise</td>
</tr>
<tr>
<td><code>__HIP_PLATFORM_NVIDIA__</code></td>
<td>Undefined</td>
<td>Defined</td>
<td>Defined if targeting NVIDIA platform; undefined otherwise</td>
</tr>
<tr>
<td><code>__HIP_DEVICE_COMPILE__</code></td>
<td>1 if compiling for device; undefined if compiling for host</td>
<td>1 if compiling for device; undefined if compiling for host</td>
<td>Undefined</td>
</tr>
<tr>
<td><code>__HIPCC__</code></td>
<td>Defined</td>
<td>Defined</td>
<td>Undefined</td>
</tr>
<tr>
<td><code>__HIP_ARCH_*</code></td>
<td>0 or 1 depending on feature support (see below)</td>
<td>0 or 1 depending on feature support (see below)</td>
<td>0</td>
</tr>
<tr>
<td>nvcc-related defines:</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>__CUDACC__</code></td>
<td>Defined if source code is compiled by nvcc; undefined otherwise</td>
<td>Undefined</td>
<td></td>
</tr>
<tr>
<td><code>__NVCC__</code></td>
<td>Undefined</td>
<td>Defined</td>
<td>Undefined</td>
</tr>
<tr>
<td><code>__CUDA_ARCH__</code></td>
<td>Undefined</td>
<td>Unsigned representing compute capability (e.g., “130”) if in device code; 0 if in host code</td>
<td>Undefined</td>
</tr>
<tr>
<td>hip-clang-related defines:</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>__HIP__</code></td>
<td>Defined</td>
<td>Undefined</td>
<td>Undefined</td>
</tr>
<tr>
<td>HIP-Clang common defines:</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>__clang__</code></td>
<td>Defined</td>
<td>Defined</td>
<td>Undefined</td>
</tr>
</tbody>
</table>
</div>
<h2 id="Identifying-Architecture-Features"><a href="#Identifying-Architecture-Features" class="headerlink" title="Identifying Architecture Features"></a>Identifying Architecture Features</h2><h3 id="HIP-ARCH-Defines"><a href="#HIP-ARCH-Defines" class="headerlink" title="HIP_ARCH Defines"></a>HIP_ARCH Defines</h3><p>一些CUDA代码会检查<code>__CUDA_ARCH__</code>是否是特定值来判断设备有无某种特性。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">if</span> (__CUDA_ARCH__ &gt;= 130)</span></span><br><span class="line"><span class="comment">// doubles are supported</span></span><br></pre></td></tr></table></figure>
<p>这种类型的代码需要特别注意，因为AMD和CUDA设备具有不同的架构能力。此外，您无法通过与体系结构版本号的简单比较来确定功能的存在。HIP提供一组定义和设备属性，以查询是否支持特定的体系结构特性。</p>
<p><code>__HIP_ARCH_*</code>定义可以替换<code>__CUDA_ARCH__</code>值的比较：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//#if (__CUDA_ARCH__ &gt;= 130) // non-portable</span></span><br><span class="line"><span class="keyword">if</span> __HIP_ARCH_HAS_DOUBLES__ &#123; <span class="comment">// portable HIP feature query</span></span><br><span class="line">	<span class="comment">// doubles are supported</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对于主机代码，<code>__HIP_ARCH_*</code>定义设置为0。您只应在设备代码中使用<code>HIP_ARCH</code>字段。</p>
<h3 id="Device-Architecture-Properties"><a href="#Device-Architecture-Properties" class="headerlink" title="Device-Architecture Properties"></a>Device-Architecture Properties</h3><p>主机代码应该查询<code>hipGetDeviceProperties</code>返回的设备属性中的体系结构功能标志，而不是直接测试“major”和“minor”字段：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">hipGetDeviceProperties</span>(&amp;deviceProp, device);</span><br><span class="line"><span class="comment">//if ((deviceProp.major == 1 &amp;&amp; deviceProp.minor &lt; 2)) // non-portable</span></span><br><span class="line"><span class="keyword">if</span> (deviceProp.arch.hasSharedInt32Atomics) &#123; <span class="comment">// portable HIP feature query</span></span><br><span class="line">	<span class="comment">// has shared int32 atomic operations ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="Table-of-Architecture-Properties"><a href="#Table-of-Architecture-Properties" class="headerlink" title="Table of Architecture Properties"></a>Table of Architecture Properties</h3><p>下表显示了HIP支持的一整套体系结构属性。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Define (use only in device code)</th>
<th>Device Property (run time query)</th>
<th>Comment</th>
</tr>
</thead>
<tbody>
<tr>
<td>32-bit atomics:</td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>__HIP_ARCH_HAS_GLOBAL_INT32_ATOMICS__</code></td>
<td>hasGlobalInt32Atomics</td>
<td>32-bit integer atomics for global memory</td>
</tr>
<tr>
<td><code>__HIP_ARCH_HAS_GLOBAL_FLOAT_ATOMIC_EXCH__</code></td>
<td>hasGlobalFloatAtomicExc h</td>
<td>32-bit float atomic exchange for global memory</td>
</tr>
<tr>
<td><code>__HIP_ARCH_HAS_SHARED_INT32_ATOMICS__</code></td>
<td>hasSharedInt32Atomics</td>
<td>32-bit integer atomics for shared memory</td>
</tr>
<tr>
<td><code>__HIP_ARCH_HAS_SHARED_FLOAT_ATOMIC_EXCH__</code></td>
<td>hasSharedFloatAtomicExc h</td>
<td>32-bit float atomic exchange for shared memory</td>
</tr>
<tr>
<td><code>__HIP_ARCH_HAS_FLOAT_ATOMIC_ADD__</code></td>
<td>hasFloatAtomicAdd</td>
<td>32-bit float atomic add in global and shared memory</td>
</tr>
<tr>
<td>64-bit atomics</td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>__HIP_ARCH_HAS_GLOBAL_INT64_ATOMICS__</code></td>
<td>hasGlobalInt64Atomics</td>
<td>64-bit integer atomics for global memory</td>
</tr>
<tr>
<td><code>__HIP_ARCH_HAS_SHARED_INT64_ATOMICS__</code></td>
<td>hasSharedInt64Atomics</td>
<td>64-bit integer atomics for shared memory</td>
</tr>
<tr>
<td>Doubles</td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>__HIP_ARCH_HAS_DOUBLES__</code></td>
<td>hasDoubles</td>
<td>Double-precision floating point</td>
</tr>
<tr>
<td>Warp cross-lane operations:</td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>__HIP_ARCH_HAS_WARP_VOTE__</code></td>
<td>hasWarpVote</td>
<td>Warp vote instructions (any, all)</td>
</tr>
<tr>
<td><code>__HIP_ARCH_HAS_WARP_BALLOT__</code></td>
<td>hasWarpBallot</td>
<td>Warp ballot instructions</td>
</tr>
<tr>
<td><code>__HIP_ARCH_HAS_WARP_SHUFFLE__</code></td>
<td>hasWarpShuffle</td>
<td>Warp shuffle operations (shfl_*)</td>
</tr>
<tr>
<td><code>__HIP_ARCH_HAS_WARP_FUNNEL_SHIFT__</code></td>
<td>hasFunnelShift</td>
<td>Funnel shift two input words into one</td>
</tr>
<tr>
<td>Sync</td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>__HIP_ARCH_HAS_THREAD_FENCE_SYSTEM__</code></td>
<td>hasThreadFenceSystem</td>
<td>threadfence_syste m</td>
</tr>
<tr>
<td><code>__HIP_ARCH_HAS_SYNC_THREAD_EXT__</code></td>
<td>hasSyncThreadsExt</td>
<td>syncthreads_count, syncthreads_and, syncthreads_or</td>
</tr>
<tr>
<td>Miscellaneous</td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>__HIP_ARCH_HAS_SURFACE_FUNCS__</code></td>
<td>hasSurfaceFuncs</td>
<td></td>
</tr>
<tr>
<td><code>__HIP_ARCH_HAS_3DGRID__</code></td>
<td>has3dGrid</td>
<td>Grids and groups are 3D</td>
</tr>
<tr>
<td><code>__HIP_ARCH_HAS_DYNAMIC_PARALLEL__</code></td>
<td>hasDynamicParallelism</td>
</tr>
</tbody>
</table>
</div>
<h3 id="Finding-HIP"><a href="#Finding-HIP" class="headerlink" title="Finding HIP"></a>Finding HIP</h3><p>如果不存在默认HIP_PATH，Makefile可以使用以下语法有条件地提供默认HIP_PATH:</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HIP_PATH ?= $(shell hipconfig --path)</span><br></pre></td></tr></table></figure>
<h3 id="Identifying-HIP-Runtime"><a href="#Identifying-HIP-Runtime" class="headerlink" title="Identifying HIP Runtime"></a>Identifying HIP Runtime</h3><p>HIP可以依赖于ROCclr或CUDA作为运行时。</p>
<p>AMD平台HIP使用名为ROCclr的Radeon Open Compute公共语言运行时。ROCclr是一个虚拟设备接口，HIP运行时可以与不同的后端交互，允许运行时在Linux和Windows上工作而不需要付出太多努力。</p>
<p>在NVIDIA平台上，HIP只是CUDA之上的一个薄层。在非AMD平台上，HIP运行时确定CUDA是否可用并可以使用。如果可用，<code>HIP_PLATFORM</code>设置为NVIDIA，并使用CUDA路径下面的路径。</p>
<h3 id="hipLaunchKernel"><a href="#hipLaunchKernel" class="headerlink" title="hipLaunchKernel"></a>hipLaunchKernel</h3><p><code>hipLaunchKernel</code>是一个可变的宏，它接受启动配置（网格dims、组dims、流、动态共享大小）和数量可变的内核参数作为参数。然后根据平台的不同，将该序列扩展为适当的内核启动语法。虽然这可能是一种方便的单行内核启动语法，但当嵌套在其他宏中时，宏实现可能会导致问题。例如，考虑以下内容：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Will cause compile error:</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MY_LAUNCH(command, doTrace) \</span></span><br><span class="line"><span class="meta">    &#123;\</span></span><br><span class="line"><span class="meta">    <span class="keyword">if</span> (doTrace) printf (<span class="string">&quot;TRACE: %s\n&quot;</span>, #command); \</span></span><br><span class="line"><span class="meta">    (command); <span class="comment">/* The nested ( ) will cause compile error */</span>\</span></span><br><span class="line"><span class="meta">    &#125;</span></span><br><span class="line"><span class="built_in">MY_LAUNCH</span> (<span class="built_in">hipLaunchKernel</span>(vAdd, <span class="built_in">dim3</span>(<span class="number">1024</span>), <span class="built_in">dim3</span>(<span class="number">1</span>), <span class="number">0</span>, <span class="number">0</span>, Ad), <span class="literal">true</span>, <span class="string">&quot;firstCall&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>注意：避免在括号内嵌套宏参数-这里有一个可行的替代方案：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> MY_LAUNCH(command, doTrace) \</span></span><br><span class="line"><span class="meta">    &#123;\</span></span><br><span class="line"><span class="meta">    <span class="keyword">if</span> (doTrace) printf (<span class="string">&quot;TRACE: %s\n&quot;</span>, #command); \</span></span><br><span class="line"><span class="meta">    command;\</span></span><br><span class="line"><span class="meta">    &#125;</span></span><br><span class="line"><span class="built_in">MY_LAUNCH</span> (<span class="built_in">hipLaunchKernel</span>(vAdd, <span class="built_in">dim3</span>(<span class="number">1024</span>), <span class="built_in">dim3</span>(<span class="number">1</span>), <span class="number">0</span>, <span class="number">0</span>, Ad), <span class="literal">true</span>, <span class="string">&quot;firstCall&quot;</span>);</span><br></pre></td></tr></table></figure>
<h3 id="Compiler-Options"><a href="#Compiler-Options" class="headerlink" title="Compiler Options"></a>Compiler Options</h3><p>HIPcc是一个可移植的编译器驱动程序，它调用nvcc或HIP Clang（取决于目标系统）并附加所有必需的include和library选项。它将选项传递给目标编译器。调用hipcc的工具必须确保编译器选项适合目标编译器。hipconfig脚本可能有助于识别目标平台、编译器和运行时。它还可以帮助适当设置选项。</p>
<h4 id="Compiler-Options-Supported-on-AMD-Platforms"><a href="#Compiler-Options-Supported-on-AMD-Platforms" class="headerlink" title="Compiler Options Supported on AMD Platforms"></a>Compiler Options Supported on AMD Platforms</h4><div class="table-container">
<table>
<thead>
<tr>
<th>Option</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>—amdgpu-target=<gpu_arch></td>
<td>[DEPRECATED] This option is replaced by <code>--offload-arch=&lt;target&gt;</code>. Generate code for the given GPU target. Supported targets are gfx701, gfx801, gfx802, gfx803, gfx900, gfx906, gfx908, gfx1010, gfx1011, gfx1012, gfx1030, gfx1031. This option could appear multiple times on the same command line to generate a fat binary for multiple targets.</td>
</tr>
<tr>
<td>—fgpu-rdc</td>
<td>Generate relocatable device code, which allows kernels or device functions calling device functions in different translation units.</td>
</tr>
<tr>
<td>-ggdb</td>
<td>Equivalent to <code>-g</code> plus tuning for GDB. This is recommended when using ROCm’s GDB to debug GPU code.</td>
</tr>
<tr>
<td>—gpu-max-threads-per block=<num></td>
<td>Generate code to support up to the specified number of threads per block.</td>
</tr>
<tr>
<td>-O<n></td>
<td>Specify the optimization level.</td>
</tr>
<tr>
<td>-offload-arch=<target></td>
<td>Specify the AMD GPU [target ID] <a href="https://clang.llvm.org/docs/ClangOffloadBundlerFileFormat.html#target-id">https://clang.llvm.org/docs/ClangOffloadBundlerFileFormat.html#target-id</a></td>
</tr>
<tr>
<td>-save-temps</td>
<td>Save the compiler-generated intermediate files.</td>
</tr>
<tr>
<td>-v</td>
<td>Show the compilation steps.</td>
</tr>
</tbody>
</table>
</div>
<h4 id="Option-for-specifying-GPU-processor"><a href="#Option-for-specifying-GPU-processor" class="headerlink" title="Option for specifying GPU processor"></a>Option for specifying GPU processor</h4><p>—offload-arch=X  </p>
<h3 id="Linking-Issues"><a href="#Linking-Issues" class="headerlink" title="Linking Issues"></a>Linking Issues</h3><h4 id="Linking-with-hipcc"><a href="#Linking-with-hipcc" class="headerlink" title="Linking with hipcc"></a>Linking with hipcc</h4><p>hipcc为HIP以及加速器编译器（nvcc或AMD编译器）添加了必要的库。建议与hipcc链接，因为它会自动将二进制文件链接到必要的HIP运行库。它还支持链接和管理GPU对象。<code>-lm Option</code></p>
<h2 id="Linking-Code-with-Other-Compilers"><a href="#Linking-Code-with-Other-Compilers" class="headerlink" title="Linking Code with Other Compilers"></a>Linking Code with Other Compilers</h2><p>CUDA代码通常使用nvcc作为加速器代码（定义和启动内核，通常在.cu或.cuh文件中定义）。它还为应用程序的其余部分使用标准编译器（g++）。nvcc是一个使用标准主机编译器（gcc）生成主机代码的预处理器。使用此工具编译的代码只能使用nvcc和宿主编译器支持的语言特性的交集。在某些情况下，您必须注意确保主机编译器的数据类型和对齐方式与设备编译器的相同。仅支持某些主机编译器，例如，最近的nvcc版本缺少Clang主机编译器功能。HIP Clang使用相同的基于Clang的编译器生成设备和主机代码。该代码使用与gcc相同的API，这允许不同的gcc兼容编译器生成的代码链接在一起。例如，使用HIP Clang编译的代码可以与使用“标准”编译器（如gcc、ICC和Clang）编译的代码链接。注意确保所有编译器使用相同的标准C++头和库格式。</p>
<h3 id="libc-and-libstdc"><a href="#libc-and-libstdc" class="headerlink" title="libc++ and libstdc++"></a>libc++ and libstdc++</h3><p>默认情况下，hipcc链接到libstdc++。这在g++和HIP之间提供了更好的兼容性。</p>
<p>如果将<code>--stdlib=libc++</code>传递给hipcc，hipcc将使用libc++库。通常，libc++提供了一组更广泛的C++特性，而libstdc++是更多编译器（特别是包括g++）的标准。</p>
<p>当交叉链接C++代码时，任何使用C++标准库中类型的C++函数（包括std::string、std::vector和其他容器）都必须使用相同的标准库实现。它们包括以下内容：</p>
<ul>
<li>HIP-Clang中定义的从标准编译器调用的函数或内核</li>
<li>标准编译器中定义的函数从HIP Clang调用。</li>
<li>具有这些接口的应用程序应使用默认的libstdc++链接。</li>
</ul>
<p>完全使用hipcc编译的应用程序，受益于libstdc++不支持的高级C++功能，并且不需要nvcc的可移植性，可以选择使用libc++。</p>
<h3 id="HIP-Headers-hip-runtime-h-hip-runtime-api-h"><a href="#HIP-Headers-hip-runtime-h-hip-runtime-api-h" class="headerlink" title="HIP Headers (hip_runtime.h, hip_runtime_api.h)"></a>HIP Headers (hip_runtime.h, hip_runtime_api.h)</h3><p>hip_runtime.h和hip_runtime_api.h文件定义了编译hip程序所需的类型、函数和枚举：</p>
<ul>
<li>hip_runtime_api.h：定义所有hip运行时api（例如，hipMalloc）以及调用它们所需的类型。仅调用HIPAPI但既不定义也不启动任何内核的源文件都可以包含hip_runtime_api.h。hip_runtime _api.h不使用自定义hc语言特性，可以使用标准C++编译器编译。</li>
<li>hip_runtime.h：包含在hip_runtme_api.h中。它还提供了创建和启动内核所需的类型和定义。它可以使用标准C++编译器编译，但将暴露可用函数的子集。</li>
</ul>
<p>CUDA对这两个文件的内容略有不同。在某些情况下，您可能需要将hipified代码转换为包含更丰富的hip_runtime.h，而不是hip_runtme_api.h。</p>
<h3 id="Using-a-Standard-C-Compiler"><a href="#Using-a-Standard-C-Compiler" class="headerlink" title="Using a Standard C++ Compiler"></a>Using a Standard C++ Compiler</h3><p>可以使用标准C/C++编译器（gcc或ICC）编译 hip_runtime_api.h。HIP头文件路径和定义（<code>__HIP_PLATFORM_AMD__</code> 或者 <code>__HIP_PLATFORM_NVIDIA__</code>）必须传给标准编译器，hipconfig会返回必要的选项：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; hipconfig --cxx_config</span><br><span class="line">-D__HIP_PLATFORM_AMD__ -I/home/user1/hip/include</span><br></pre></td></tr></table></figure>
<p>您可以捕获hipconfig输出并将其传递给标准编译器；下面是makefile语法示例：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CPPFLAGS += $(shell $(HIP_PATH)/bin/hipconfig --cpp_config)</span><br></pre></td></tr></table></figure>
<p>默认情况下，nvcc包含一些头文件。然而，HIP不包含默认头文件，而是必须明确包含所有必需的文件。具体来说，调用HIP运行时API或定义HIP内核的文件必须明确包含适当的HIP头。如果编译过程报告找不到必要的api（例如，“错误：标识符’hipSetDevice’未定义”），请确保文件包含hip_runtime.h（或hip_runtme_api.h，如果合适）。hipify-perl脚本会自动将“cudaruntime.h”转换为“hip_runtime.h”，并将“cuda_runtime_api.h”转换成“hip_rountime_api.h”，但可能会丢失嵌套的头或宏。</p>
<h4 id="cuda-h"><a href="#cuda-h" class="headerlink" title="cuda.h"></a>cuda.h</h4><p>HIP Clang路径提供了一个空的cuda.h文件。一些现有的CUDA程序包含此文件，但不需要任何功能。</p>
<h3 id="Choosing-HIP-File-Extensions"><a href="#Choosing-HIP-File-Extensions" class="headerlink" title="Choosing HIP File Extensions"></a>Choosing HIP File Extensions</h3><p>许多现有CUDA项目使用“.cu”和“.cuh”文件扩展名来指示应该通过nvcc编译器运行的代码。对于快速HIP端口，保持这些文件扩展名不变通常更容易，因为这样可以减少更改目录中的文件名和文件中的#include语句所需的工作量。</p>
<p>对于可以重新分解的新项目或端口，我们建议对源文件使用扩展名“.hip.cpp”，对头文件使用“.hip.h”或“.hip.hpp”。这表明代码是标准的C++代码，但也为make工具在适当时运行hipcc提供了唯一的指示。</p>
<h2 id="Workarounds"><a href="#Workarounds" class="headerlink" title="Workarounds"></a>Workarounds</h2><h3 id="memcpyToSymbol"><a href="#memcpyToSymbol" class="headerlink" title="memcpyToSymbol"></a>memcpyToSymbol</h3><p><code>hipMemcpyToSymbol</code>的HIP支持已完成。该特性允许内核定义可以在主机端访问的设备端数据符号。符号可以在<code>__constant</code>或设备空间中。</p>
<p>请注意，符号名称需要封装在<code>HIP_symbol</code>宏中，如下面的代码示例所示。这也适用于<code>hipMemcpyFromSymbol</code>、<code>hipGetSymbolAddress</code>和<code>hipGetSymbolSize</code>。</p>
<p>例如，设备代码：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;hip/hip_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;hip/hip_runtime_api.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> HIP_ASSERT(status) \</span></span><br><span class="line"><span class="meta">assert(status == hipSuccess)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> LEN 512</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SIZE 2048</span></span><br><span class="line">__constant__ <span class="type">int</span> Value[LEN];</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">Get</span><span class="params">(hipLaunchParm lp, <span class="type">int</span> *Ad)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> tid =threadIdx.x + blockIdx.x *blockDim.x;</span><br><span class="line">    Ad[tid] = Value[tid];</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> *A, *B, *Ad;</span><br><span class="line">    A = <span class="keyword">new</span> <span class="type">int</span>[LEN];</span><br><span class="line">    B = <span class="keyword">new</span> <span class="type">int</span>[LEN];</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">unsigned</span> i=<span class="number">0</span>;i&lt;LEN;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        A[i] = <span class="number">-1</span>*i;</span><br><span class="line">        B[i] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">HIP_ASSERT</span>(<span class="built_in">hipMalloc</span>((<span class="type">void</span>**)&amp;Ad, SIZE));</span><br><span class="line">    <span class="built_in">HIP_ASSERT</span>(<span class="built_in">hipMemcpyToSymbol</span>(<span class="built_in">HIP_SYMBOL</span>(Value), A, SIZE, <span class="number">0</span>, hipMemcpyHostToDevice));</span><br><span class="line">    <span class="built_in">hipLaunchKernel</span>(Get, <span class="built_in">dim3</span>(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>), <span class="built_in">dim3</span>(LEN,<span class="number">1</span>,<span class="number">1</span>), <span class="number">0</span>, <span class="number">0</span>, Ad);</span><br><span class="line">    <span class="built_in">HIP_ASSERT</span>(<span class="built_in">hipMemcpy</span>(B, Ad, SIZE, hipMemcpyDeviceToHost));</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">unsigned</span> i=<span class="number">0</span>;i&lt;LEN;i++)</span><br><span class="line">    &#123;</span><br><span class="line">	    <span class="built_in">assert</span>(A[i] == B[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    std::cout&lt;&lt;<span class="string">&quot;Passed&quot;</span>&lt;&lt;std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="CU-POINTER-ATTRIBUTE-MEMORY-TYPE"><a href="#CU-POINTER-ATTRIBUTE-MEMORY-TYPE" class="headerlink" title="CU_POINTER_ATTRIBUTE_MEMORY_TYPE"></a>CU_POINTER_ATTRIBUTE_MEMORY_TYPE</h3><p>要在HIP/HIP Clang中获取指针的内存类型，应该使用hipPointerGetAttributes API。API的第一个参数是<code>hipPointerAttribute_t</code>，其成员变量为<code>memoryType</code>，<code>memoryType</code>表示输入指针分配在设备或主机上。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">double</span> * ptr;</span><br><span class="line"><span class="built_in">hipMalloc</span>(<span class="built_in">reinterpret_cast</span>&lt;<span class="type">void</span>**&gt;(&amp;ptr), <span class="built_in">sizeof</span>(<span class="type">double</span>));</span><br><span class="line">hipPointerAttribute_t attr;</span><br><span class="line"><span class="built_in">hipPointerGetAttributes</span>(&amp;attr, ptr); <span class="comment">/*attr.memoryType will have value as hipMemoryTypeDevice*/</span></span><br><span class="line"><span class="type">double</span>* ptrHost;</span><br><span class="line"><span class="built_in">hipHostMalloc</span>(&amp;ptrHost, <span class="built_in">sizeof</span>(<span class="type">double</span>));</span><br><span class="line">hipPointerAttribute_t attr;</span><br><span class="line"><span class="built_in">hipPointerGetAttributes</span>(&amp;attr, ptrHost); <span class="comment">/*attr.memoryType will have value as hipMemoryTypeHost*/</span></span><br></pre></td></tr></table></figure>
<h3 id="threadfence-system"><a href="#threadfence-system" class="headerlink" title="threadfence_system"></a>threadfence_system</h3><p><code>threadence_system</code>使所有设备内存写入、对映射主机内存的所有写入以及对其他GPU设备内存的写入对其他CPU和GPU可见。一些实现可以通过刷新GPU L2缓存来提供这种行为。HIP/HIP-Clang不提供此功能。作为解决方法，用户可以将环境变量<code>HSA_DISABLE_CACHE=1</code>设置为禁用GPU二级缓存。这将影响所有访问和所有内核，因此可能会影响性能。</p>
<h3 id="Textures-and-Cache-Control"><a href="#Textures-and-Cache-Control" class="headerlink" title="Textures and Cache Control"></a>Textures and Cache Control</h3><p>计算程序有时使用纹理来访问专用纹理缓存或使用纹理采样硬件进行插值和夹持。前一种方法使用具有线性插值的简单点采样器，本质上只读取单个点。后一种方法使用采样器硬件对多个样本进行插值和组合。AMD硬件以及最近的竞争硬件都有统一的纹理/L1缓存，因此不再有专用的纹理缓存。但nvcc路径通常将全局加载缓存在二级缓存中，一些程序可能会从一级缓存内容的显式控制中受益。为此，我们建议使用<code>__ldg</code>指令。</p>
<p>AMD编译器目前将所有数据加载到L1和L2缓存中，因此<code>__ldg</code>被视为noop。对于功能可移植性，我们建议如下：</p>
<ul>
<li>对于仅使用纹理以从改进的缓存中获益的程序，请使用<code>__ldg</code>指令 </li>
<li>使用纹理对象和引用API的程序在HIP上运行良好</li>
</ul>
<h2 id="HIP-Porting-Driver-API"><a href="#HIP-Porting-Driver-API" class="headerlink" title="HIP Porting Driver API"></a>HIP Porting Driver API</h2><h3 id="Porting-CUDA-Driver-API"><a href="#Porting-CUDA-Driver-API" class="headerlink" title="Porting CUDA Driver API"></a>Porting CUDA Driver API</h3><p>CUDA提供了单独的CUDA驱动程序和运行时API。这两个API在功能上有很大的重叠：</p>
<ul>
<li>这两个API都支持事件、流、内存管理、内存复制和错误处理。</li>
<li>两种API提供了相似的性能。</li>
<li>驱动程序API调用以前缀cu开头，而运行时API以前缀cuda开头。例如，驱动程序API包含cuEventCreate，而运行时API包含cudaEventCreate，具有类似的功能。</li>
<li>驱动程序API定义的错误代码空间与运行时API使用的编码约定不同，但在很大程度上重叠。例如，驱动程序API定义<code>CUDA_ERROR_INVALID_VALUE</code>，而运行时API定义cudaErrorInvalidValue</li>
</ul>
<p>注意：驱动程序API提供了运行时API没有提供的两个附加功能：cuModule和cuCtx API。</p>
<h3 id="cuModule-API"><a href="#cuModule-API" class="headerlink" title="cuModule API"></a>cuModule API</h3><p>驱动程序API的模块部分提供了如何以及何时加载加速器代码对象的额外控制。例如，驱动程序API允许从文件或内存指针加载代码对象。可以从加载的代码对象中提取内核或全局数据的符号。相反，运行时API在运行时自动加载并（如果需要）从可执行二进制文件编译所有内核。在此模式下，必须使用NVCC编译内核代码，以便自动加载能够正常运行。</p>
<p>驱动程序和运行时API都定义了一个用于启动内核的函数（称为cuLaunchKernel或cudaLaunchKernel）。内核参数和执行配置（网格维度、组维度、动态共享内存和流）作为参数传递给启动函数。Runtime还提供了用于启动内核的&lt;&lt;&lt;&gt;&gt;&gt;语法，它类似于一个特殊的函数调用，比显式启动API更易于使用（特别是内核参数的处理）。然而，此语法不是标准的C++，只有在使用NVCC编译主机代码时才可用。</p>
<p>模块特性在直接生成代码对象的环境中非常有用，例如新的加速器语言前端。此处不使用NVCC。相反，环境可能具有不同的内核语言或不同的编译流。其他环境有许多内核，不希望它们全部自动加载。Module函数可用于加载生成的代码对象并启动内核。正如我们将在下面看到的，HIP定义了一个模块API，它对代码对象管理提供了类似的显式控制。</p>
<h3 id="cuCtx-API"><a href="#cuCtx-API" class="headerlink" title="cuCtx API"></a>cuCtx API</h3><p>驱动程序API将“上下文”和“设备”定义为单独的实体。上下文包含一个设备，理论上一个设备可以有多个上下文。每个上下文都包含一组特定于上下文的流和事件。历史上，上下文也为GPU定义了唯一的地址空间，但在统一内存平台中可能不再是这种情况（因为CPU和同一进程中的所有设备共享一个统一的地址空间）。上下文API还提供了一种在设备之间切换的机制，允许单个CPU线程向不同的GPU发送命令。HIP以及CUDA运行时的最新版本提供了其他机制来实现这一壮举，例如使用流或cudaSetDevice。</p>
<p>CUDA运行时API将上下文API与设备API统一起来。这简化了API，几乎没有功能损失，因为每个上下文都可以包含一个设备，多个上下文的好处已经被其他接口所取代。HIP提供了一个上下文API，以方便从现有驱动程序代码进行移植。在HIP中，Ctx函数在很大程度上提供了用于更改活动设备的替代语法。大多数新应用程序都倾向于使用hipSetDevice或流API，因此HIP已将hipCtx API标记为已弃用。在未来的版本中可能无法提供对这些API的支持。有关弃用API的详细信息，请参阅HIP弃用API：<a href="https://github.com/ROCm-DeveloperTools/HIP/blob/main/docs/markdown/hip_deprecated_api_list.md">https://github.com/ROCm-DeveloperTools/HIP/blob/main/docs/markdown/hip_deprecated_api_list.md</a>  </p>
<h3 id="HIP-Module-and-Ctx-APIs"><a href="#HIP-Module-and-Ctx-APIs" class="headerlink" title="HIP Module and Ctx APIs"></a>HIP Module and Ctx APIs</h3><p>HIP没有提供两个单独的API，而是用模块和Ctx控件的新API扩展了HIP API。</p>
<h4 id="hipModule-API"><a href="#hipModule-API" class="headerlink" title="hipModule API"></a>hipModule API</h4><p>与CUDA驱动程序API一样，模块API提供了对代码加载方式的额外控制，包括从文件或内存指针加载代码的选项。NVCC和HIP Clang针对不同的体系结构，并使用不同的代码对象格式：NVCC是“cubin”或“ptx”文件，而HIP Clangpath是“hsaco”格式。生成这些代码对象的外部编译器负责为每个平台生成和加载正确的代码对象。值得注意的是，没有可以同时包含NVCC和HIP Clang平台代码的胖二进制格式。下表总结了每个平台上使用的格式：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>Format</th>
<th>APIs</th>
<th>NVCC</th>
<th>HIP-CLANG</th>
</tr>
</thead>
<tbody>
<tr>
<td>Code Object</td>
<td>hipModuleLoad, hipModuleLoadData</td>
<td>.cubin or PTX text</td>
<td>.hsaco</td>
</tr>
<tr>
<td>Fat Binary</td>
<td>hipModuleLoadFatBin</td>
<td>.fatbin</td>
<td>.hip_fatbin</td>
</tr>
</tbody>
</table>
</div>
<p><code>hipcc</code>使用HIP-Clang或NVCC来编译主机代码。两者都可以将代码对象嵌入到最终的可执行文件中，并且这些代码对象将在应用程序启动时自动加载。hipModule API可用于加载其他代码对象，并以此方式为自动加载的代码对象提供扩展功能。如果需要，HIP-Clang允许两种功能一起使用。可以创建一个没有内核的程序，因此没有自动加载。</p>
<h3 id="hipCtx-API"><a href="#hipCtx-API" class="headerlink" title="hipCtx API"></a>hipCtx API</h3><p>HIP在现有设备功能上提供了一个Ctx API作为薄层。此Ctx API可用于设置当前上下文或查询与上下文关联的设备的属性。当前上下文由其他API（如hipStreamCreate）隐式使用。</p>
<h3 id="hipify-translation-of-CUDA-Driver-API"><a href="#hipify-translation-of-CUDA-Driver-API" class="headerlink" title="hipify translation of CUDA Driver API"></a>hipify translation of CUDA Driver API</h3><p>HIPIFY工具将用于流、事件、模块、设备、内存管理、上下文、分析器的CUDA驱动程序API转换为等效的HIP驱动程序调用。例如，cuEventCreate将被转换为hipEventCreate。HIPIFY工具还将错误代码从Driver命名空间和编码约定转换为等效的HIP错误代码。因此，HIP统一了这些公共函数的API。内存复制API需要额外的解释。CUDA驱动程序在API的名称中包含内存方向（即cuMemcpyH2D），而CUDA驱动API提供了一个具有指定方向的参数的单一内存复制API，并且还支持运行时自动确定方向的“默认”方向。HIP提供了两种样式的API：例如，hipMemcpyH2D和hipMemcpy。在某些情况下，第一种风格可能更快，因为它们避免了检测不同内存方向的主机开销。</p>
<p>HIP定义单个错误空间，并对所有错误使用驼峰大小写（即hipErrorInvalidValue）</p>
<h2 id="HIP-Clang-Implementation-Notes"><a href="#HIP-Clang-Implementation-Notes" class="headerlink" title="HIP-Clang Implementation Notes"></a>HIP-Clang Implementation Notes</h2><h3 id="hip-fatbin"><a href="#hip-fatbin" class="headerlink" title=".hip_fatbin"></a>.hip_fatbin</h3><p>hip clang将来自不同翻译单元的设备代码链接在一起。对于每个设备目标，都会生成一个代码对象。不同设备目标的代码对象由clang卸载绑定器绑定为一个fatbinary，该fatbinary作为全局符号<code>__hip_fatbin</code>嵌入到可执行或共享对象的ELF文件的.hip_fatbin部分中。</p>
<h3 id="Initialization-and-Termination-Functions"><a href="#Initialization-and-Termination-Functions" class="headerlink" title="Initialization and Termination Functions"></a>Initialization and Termination Functions</h3><p> HIP-Clang为主机代码编译的每个翻译单元生成初始化和终止函数。初始化函数调用<code>__hipRegisterFatBinary</code>来注册ELF文件中嵌入的fatbinary。它们还调用<code>__hipRegisterFunction</code>和<code>__hipRegisterVar</code>来注册内核函数和设备端全局变量。终止函数调用<code>__hipUnregisterFatBinary</code>。HIP Clang发出一个全局变量<code>__HIP_gpubin_handle</code>，类型为<code>void**</code>，带有linkonce链接，每个主机翻译单元的初始值为0。每个初始化函数检查<code>__hip_gpubin_handle</code>，并仅在<code>__hip_gpubin_handle</code>为0时注册fatbinary，并将<code>__hip_gpubin_handle</code>的返回值保存到<code>__hip_gpubin_handle</code>。这是为了保证fatbinary只注册一次。在终端功能中也进行了类似的检查。</p>
<h3 id="Kernel-Launching"><a href="#Kernel-Launching" class="headerlink" title="Kernel Launching"></a>Kernel Launching</h3><p>HIP Clang支持CUDA&lt;&lt;&lt;&gt;&gt;&gt;语法、<code>hipLaunchKernel</code>和<code>hipLaunchKernelGGL</code>启动内核。后两个是扩展到CUDA&lt;&lt;&lt;&gt;&gt;&gt;语法的宏。当动态链接器加载可执行或共享库时，将调用初始化函数。在初始化函数中，当调用<code>__hipRegisterFatBinary</code>时，将加载包含所有内核的代码对象；当调用<code>__hipRegisterFunction</code>时，存根函数与代码对象中的相应内核相关联。HIP Clang实现了两组启动API的内核。</p>
<p>默认情况下，在主机代码中，对于&lt;&lt;&lt;&gt;&gt;&gt;语句，hip-clang首先发出<code>hipConfigureCall</code>调用以设置线程和网格，然后发出带有给定参数的存根函数调用。在存根函数中，为每个内核参数调用<code>hipSetupArgument</code>，然后使用指向存根函数的函数指针调用<code>hipLaunchByPtr</code>。在<code>hipLaunchByPtr</code>中，与存根函数关联的真正内核被启动。</p>
<p>如果HIP程序是用<code>-fhip-new-launch-api</code>编译的，在主机代码中，对于&lt;&lt;&lt;&gt;&gt;&gt;语句，HIP-clang首先发出<code>__hipPushCallConfiguration</code>的调用，以将网格维度、块维度、共享内存使用情况和流保存到堆栈中，然后发出带有给定参数的存根函数调用。在存根函数中，调用<code>__hipPopCallConfiguration</code>以获取保存的网格维度、块维度、共享内存使用情况和流，然后<code>hipLaunchKernel</code>被调用，加上指向存根函数的函数指针。在<code>hipLaunchKernel</code>中，与存根函数关联的真实内核被启动。</p>
<h3 id="Address-Spaces"><a href="#Address-Spaces" class="headerlink" title="Address Spaces"></a>Address Spaces</h3><p>HIP Clang定义了一个进程范围的地址空间，其中CPU和所有设备从单个统一池分配地址。因此，地址可以在上下文之间共享，并且与原始CUDA定义不同，新的上下文不会为设备创建新的地址空间。</p>
<h3 id="Using-hipModuleLaunchKernel"><a href="#Using-hipModuleLaunchKernel" class="headerlink" title="Using hipModuleLaunchKernel"></a>Using hipModuleLaunchKernel</h3><p><code>hipModuleLaunchKernel</code>是HIP世界中的<code>cuLaunchKernel</code>。它采用与<code>cuLaunchKernel</code>相同的参数。</p>
<h3 id="Additional-Information"><a href="#Additional-Information" class="headerlink" title="Additional Information"></a>Additional Information</h3><p>HIP Clang在调用HIP API时创建主上下文。在纯驱动程序API代码中，HIPClang将创建一个主上下文，而HIP/NVCC将有一个空的上下文堆栈。HIP Clang将在主上下文为空时将其推送到上下文堆栈。这可能会在混合运行时和驱动程序API的应用程序中产生细微的差异。</p>
<h2 id="NVCC-Implementation-Notes"><a href="#NVCC-Implementation-Notes" class="headerlink" title="NVCC Implementation Notes"></a>NVCC Implementation Notes</h2><h3 id="Interoperation-between-HIP-and-CUDA-Driver"><a href="#Interoperation-between-HIP-and-CUDA-Driver" class="headerlink" title="Interoperation between HIP and CUDA Driver"></a>Interoperation between HIP and CUDA Driver</h3><p>CUDA应用程序可能希望将CUDA驱动程序代码与HIP代码混合。此表显示了启用此交互的类型等效性。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>HIP Type</th>
<th>CU Driver Type</th>
<th>CUDA Runtime Type</th>
</tr>
</thead>
<tbody>
<tr>
<td>hipModule_t</td>
<td>CUmodule</td>
<td></td>
</tr>
<tr>
<td>hipFunction_t</td>
<td>CUfunction</td>
<td></td>
</tr>
<tr>
<td>hipCtx_t</td>
<td>CUcontext</td>
<td></td>
</tr>
<tr>
<td>hipDevice_t</td>
<td>CUdevice</td>
<td></td>
</tr>
<tr>
<td>hipStream_t</td>
<td>CUstream</td>
<td>cudaStream_t</td>
</tr>
<tr>
<td>hipEvent_t</td>
<td>CUevent</td>
<td>cudaEvent_t</td>
</tr>
<tr>
<td>hipArray</td>
<td>CUarray</td>
<td>cudaArray</td>
</tr>
</tbody>
</table>
</div>
<h3 id="Compilation-Options"><a href="#Compilation-Options" class="headerlink" title="Compilation Options"></a>Compilation Options</h3><p><code>hipModule_t</code>接口不支持用于控制PTX编译选项的<code>cuModuleLoadDataEx</code>函数。HIP Clang不使用PTX，也不支持这些编译选项。HIP Clang代码对象始终包含完全编译的ISA，并且不需要作为加载步骤的一部分进行额外编译。相应的HIP函数<code>hipModuleLoadDataEx</code>在HIP Clang上表现为<code>hipModuleDoadData</code>（不使用编译选项），在NVCC路径上表现<code>cuModuleLoadData</code>。</p>
<p>例如</p>
<p>CUDA</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">CUmodule <span class="keyword">module</span>;</span><br><span class="line"><span class="type">void</span> *imagePtr = ...; <span class="comment">// Somehow populate data pointer with code object</span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> numOptions = <span class="number">1</span>;</span><br><span class="line">CUJit_option options[numOptions];</span><br><span class="line"><span class="type">void</span> * optionValues[numOptions];</span><br><span class="line">options[<span class="number">0</span>] = CU_JIT_MAX_REGISTERS;</span><br><span class="line"><span class="type">unsigned</span> maxRegs = <span class="number">15</span>;</span><br><span class="line">optionValues[<span class="number">0</span>] = (<span class="type">void</span>*)(&amp;maxRegs);</span><br><span class="line"><span class="built_in">cuModuleLoadDataEx</span>(<span class="keyword">module</span>, imagePtr, numOptions, options, optionValues);</span><br><span class="line">CUfunction k;</span><br><span class="line"><span class="built_in">cuModuleGetFunction</span>(&amp;k, <span class="keyword">module</span>, <span class="string">&quot;myKernel&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>HIP</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">hipModule_t <span class="keyword">module</span>;</span><br><span class="line"><span class="type">void</span> *imagePtr = ...; <span class="comment">// Somehow populate data pointer with code object</span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> numOptions = <span class="number">1</span>;</span><br><span class="line">hipJitOption options[numOptions];</span><br><span class="line"><span class="type">void</span> * optionValues[numOptions];</span><br><span class="line">options[<span class="number">0</span>] = hipJitOptionMaxRegisters;</span><br><span class="line"><span class="type">unsigned</span> maxRegs = <span class="number">15</span>;</span><br><span class="line">optionValues[<span class="number">0</span>] = (<span class="type">void</span>*)(&amp;maxRegs);</span><br><span class="line"><span class="comment">// hipModuleLoadData(module, imagePtr) will be called on HIP-Clang path, JIT options will not be used, and</span></span><br><span class="line"><span class="comment">// cupModuleLoadDataEx(module, imagePtr, numOptions, options, optionValues) will be called on NVCC path</span></span><br><span class="line"><span class="built_in">hipModuleLoadDataEx</span>(<span class="keyword">module</span>, imagePtr, numOptions, options, optionValues);</span><br><span class="line">hipFunction_t k;</span><br><span class="line"><span class="built_in">hipModuleGetFunction</span>(&amp;k, <span class="keyword">module</span>, <span class="string">&quot;myKernel&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>下边的例子展示了如何使用<code>hipModuleGetFunction</code>:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;hip_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;hip_runtime_api.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;fstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span><span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> LEN 64</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SIZE LEN&lt;&lt;2</span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __HIP_PLATFORM_HCC__</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> fileName <span class="string">&quot;vcpy_isa.co&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __HIP_PLATFORM_NVCC__</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> fileName <span class="string">&quot;vcpy_isa.ptx&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> kernel_name <span class="string">&quot;hello_world&quot;</span></span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="type">float</span> *A, *B;</span><br><span class="line">    hipDeviceptr_t Ad, Bd;</span><br><span class="line">    A = <span class="keyword">new</span> <span class="type">float</span>[LEN];</span><br><span class="line">    B = <span class="keyword">new</span> <span class="type">float</span>[LEN];</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">uint32_t</span> i=<span class="number">0</span>;i&lt;LEN;i++)&#123;</span><br><span class="line">        A[i] = i*<span class="number">1.0f</span>;</span><br><span class="line">        B[i] = <span class="number">0.0f</span>;  </span><br><span class="line">        std::cout&lt;&lt;A[i] &lt;&lt; <span class="string">&quot; &quot;</span>&lt;&lt;B[i]&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __HIP_PLATFORM_NVCC__</span></span><br><span class="line">    <span class="built_in">hipInit</span>(<span class="number">0</span>);</span><br><span class="line">    hipDevice_t device;</span><br><span class="line">    hipCtx_t context;</span><br><span class="line">    <span class="built_in">hipDeviceGet</span>(&amp;device, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">hipCtxCreate</span>(&amp;context, <span class="number">0</span>, device);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    <span class="built_in">hipMalloc</span>((<span class="type">void</span>**)&amp;Ad, SIZE);</span><br><span class="line">    <span class="built_in">hipMalloc</span>((<span class="type">void</span>**)&amp;Bd, SIZE);</span><br><span class="line">    <span class="built_in">hipMemcpyHtoD</span>(Ad, A, SIZE);</span><br><span class="line">    <span class="built_in">hipMemcpyHtoD</span>(Bd, B, SIZE);</span><br><span class="line">    hipModule_t Module;</span><br><span class="line">    hipFunction_t Function;</span><br><span class="line">    <span class="built_in">hipModuleLoad</span>(&amp;Module, fileName);</span><br><span class="line">    <span class="built_in">hipModuleGetFunction</span>(&amp;Function, Module, kernel_name);</span><br><span class="line">    std::vector&lt;<span class="type">void</span>*&gt;<span class="built_in">argBuffer</span>(<span class="number">2</span>);</span><br><span class="line">    <span class="built_in">memcpy</span>(&amp;argBuffer[<span class="number">0</span>], &amp;Ad, <span class="built_in">sizeof</span>(<span class="type">void</span>*));</span><br><span class="line">    <span class="built_in">memcpy</span>(&amp;argBuffer[<span class="number">1</span>], &amp;Bd, <span class="built_in">sizeof</span>(<span class="type">void</span>*));</span><br><span class="line">    <span class="type">size_t</span> size = argBuffer.<span class="built_in">size</span>()*<span class="built_in">sizeof</span>(<span class="type">void</span>*);</span><br><span class="line">    <span class="type">void</span> *config[] = &#123;</span><br><span class="line">        HIP_LAUNCH_PARAM_BUFFER_POINTER, &amp;argBuffer[<span class="number">0</span>],</span><br><span class="line">        HIP_LAUNCH_PARAM_BUFFER_SIZE, &amp;size,</span><br><span class="line">        HIP_LAUNCH_PARAM_END</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">hipModuleLaunchKernel</span>(Function, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, LEN, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="literal">NULL</span>, (<span class="type">void</span>**)&amp;config);</span><br><span class="line">    <span class="built_in">hipMemcpyDtoH</span>(B, Bd, SIZE);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">uint32_t</span> i=<span class="number">0</span>;i&lt;LEN;i++)&#123;</span><br><span class="line">	    std::cout&lt;&lt;A[i]&lt;&lt;<span class="string">&quot; - &quot;</span>&lt;&lt;B[i]&lt;&lt;std::endl;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> __HIP_PLATFORM_NVCC__</span></span><br><span class="line">	<span class="built_in">hipCtxDetach</span>(context);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="HIP-Module-and-Texture-Driver-API"><a href="#HIP-Module-and-Texture-Driver-API" class="headerlink" title="HIP Module and Texture Driver API"></a>HIP Module and Texture Driver API</h3><p>HIP支持纹理驱动程序API，但纹理引用应在主机范围内声明。以下代码说明了<code>HIP_PLATFORM_HCC</code>平台使用纹理参考</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Code to generate code object</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;hip/hip_runtime.h&quot;</span></span></span><br><span class="line"><span class="keyword">extern</span> texture&lt;<span class="type">float</span>, <span class="number">2</span>, hipReadModeElementType&gt; tex;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">tex2dKernel</span><span class="params">(hipLaunchParm lp, <span class="type">float</span>* outputData,</span></span></span><br><span class="line"><span class="params"><span class="function"><span class="type">int</span> width, <span class="type">int</span> height)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> x = blockIdx.x*blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">int</span> y = blockIdx.y*blockDim.y + threadIdx.y;</span><br><span class="line">    outputData[y*width + x] = <span class="built_in">tex2D</span>(tex, x, y);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Host code:</span></span><br><span class="line">texture&lt;<span class="type">float</span>, <span class="number">2</span>, hipReadModeElementType&gt; tex;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">myFunc</span> <span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    textureReference* texref;</span><br><span class="line">    <span class="built_in">hipModuleGetTexRef</span>(&amp;texref, Module1, <span class="string">&quot;tex&quot;</span>);</span><br><span class="line">    <span class="built_in">hipTexRefSetAddressMode</span>(texref, <span class="number">0</span>, hipAddressModeWrap);</span><br><span class="line">    <span class="built_in">hipTexRefSetAddressMode</span>(texref, <span class="number">1</span>, hipAddressModeWrap);</span><br><span class="line">    <span class="built_in">hipTexRefSetFilterMode</span>(texref, hipFilterModePoint);</span><br><span class="line">    <span class="built_in">hipTexRefSetFlags</span>(texref, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">hipTexRefSetFormat</span>(texref, HIP_AD_FORMAT_FLOAT, <span class="number">1</span>);</span><br><span class="line">    <span class="built_in">hipTexRefSetArray</span>(texref, array, HIP_TRSA_OVERRIDE_FORMAT);</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="使用hip实现矩阵乘"><a href="#使用hip实现矩阵乘" class="headerlink" title="使用hip实现矩阵乘"></a>使用hip实现矩阵乘</h1><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;hip/hip_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;hip/hip_runtime_api.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> M 4</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> K 4</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> N 4</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">initial</span><span class="params">(<span class="type">double</span>* list,<span class="type">int</span> row,<span class="type">int</span> col)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">double</span> *num = list;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i=<span class="number">0</span>; i&lt;row*col; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        num[i] = <span class="built_in">rand</span>()%<span class="number">10</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">CpuMatrix</span><span class="params">(<span class="type">double</span> *A,<span class="type">double</span> *B,<span class="type">double</span> *C)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i,j,k;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>( i=<span class="number">0</span>; i&lt;M; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(j=<span class="number">0</span>; j&lt;N; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">double</span> sum = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="type">int</span> k=<span class="number">0</span>; k&lt;K; k++)</span><br><span class="line">            &#123;</span><br><span class="line">                sum += A[i*K + k] * B[k * N + j];</span><br><span class="line">            &#125;</span><br><span class="line">            C[i * N + j] = sum;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">  </span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">GpuMatrix</span><span class="params">(<span class="type">double</span> *dev_A,<span class="type">double</span> *dev_B,<span class="type">double</span> *dev_C)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> ix = hipBlockIdx_x * hipBlockDim_x + hipThreadIdx_x;</span><br><span class="line">    <span class="type">int</span> iy = hipBlockIdx_y * hipBlockDim_y + hipThreadIdx_y;</span><br><span class="line">    <span class="keyword">if</span>(ix&lt;K &amp;&amp; iy&lt;M)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">double</span> sum = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>( <span class="type">int</span> k = <span class="number">0</span>; k &lt; K;k++)</span><br><span class="line">        &#123;</span><br><span class="line">            sum += dev_A[iy*K + k] * dev_B[k*N + ix];</span><br><span class="line">        &#125;</span><br><span class="line">        dev_C[iy * N + ix] = sum;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">printMatrix</span><span class="params">(<span class="type">double</span> *list,<span class="type">int</span> row,<span class="type">int</span> col)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">double</span> *p = list;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;row; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>; j&lt;col; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;%10lf&quot;</span>,p[j]);</span><br><span class="line">        &#125;</span><br><span class="line">        p = p + col;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">int</span> argc,<span class="type">char</span> **argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> Axy = M*K;</span><br><span class="line">    <span class="type">int</span> Abytes = Axy * <span class="built_in">sizeof</span>(<span class="type">double</span>);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> Bxy = K*N;</span><br><span class="line">    <span class="type">int</span> Bbytes = Bxy * <span class="built_in">sizeof</span>(<span class="type">double</span>);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> nxy = M*N;</span><br><span class="line">    <span class="type">int</span> nbytes = nxy * <span class="built_in">sizeof</span>(<span class="type">double</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="type">float</span> time_cpu,time_gpu;</span><br><span class="line">    </span><br><span class="line">    <span class="type">clock_t</span> start_cpu,stop_cpu;</span><br><span class="line">    </span><br><span class="line">    hipEvent_t start_GPU,stop_GPU;</span><br><span class="line"></span><br><span class="line">    <span class="type">double</span> *host_A, *host_B, *host_C, *c_CPU;</span><br><span class="line">    host_A = (<span class="type">double</span>*)<span class="built_in">malloc</span>(Abytes);</span><br><span class="line">    host_B = (<span class="type">double</span>*)<span class="built_in">malloc</span>(Bbytes);</span><br><span class="line">    host_C = (<span class="type">double</span>*)<span class="built_in">malloc</span>(nbytes);</span><br><span class="line">    c_CPU = (<span class="type">double</span>*)<span class="built_in">malloc</span>(nbytes);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="built_in">initial</span>(host_A,M,K);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;A:(%d,%d):\n&quot;</span>,M,K);</span><br><span class="line">    <span class="built_in">printMatrix</span>(host_A,M,K);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">initial</span>(host_B,K,N);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;B:(%d,%d):\n&quot;</span>,K,N);</span><br><span class="line">    <span class="built_in">printMatrix</span>(host_B,K,N);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// start_cpu = clock();</span></span><br><span class="line">    <span class="built_in">CpuMatrix</span>(host_A,host_B,host_C);</span><br><span class="line">    <span class="comment">// stop_cpu = clock();</span></span><br><span class="line"> </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Host_C:(%d,%d):\n&quot;</span>,M,N);</span><br><span class="line">    <span class="comment">// printf(&quot;\nCPU time is %f(ms)\n&quot;,(float)(stop_cpu-start_cpu)/CLOCKS_PER_SEC);</span></span><br><span class="line">    <span class="built_in">printMatrix</span>(host_C,M,N);</span><br><span class="line">    <span class="type">double</span> *dev_A,*dev_B,*dev_C;</span><br><span class="line">    <span class="built_in">hipMalloc</span>(&amp;dev_A,Axy*<span class="built_in">sizeof</span>(<span class="type">double</span>));</span><br><span class="line">    <span class="built_in">hipMalloc</span>(&amp;dev_B,Bxy*<span class="built_in">sizeof</span>(<span class="type">double</span>));</span><br><span class="line">    <span class="built_in">hipMalloc</span>(&amp;dev_C,nxy*<span class="built_in">sizeof</span>(<span class="type">double</span>));</span><br><span class="line"></span><br><span class="line">    <span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">1024</span>,<span class="number">1</span>)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">grid</span><span class="params">(<span class="number">64</span>,<span class="number">64</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">hipMemcpy</span>(dev_A,host_A,Abytes,hipMemcpyDeviceToHost);</span><br><span class="line">    <span class="built_in">hipMemcpy</span>(dev_B,host_B,Bbytes,hipMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">hipEventCreate</span>(&amp;start_GPU);</span><br><span class="line">    <span class="built_in">hipEventCreate</span>(&amp;stop_GPU);</span><br><span class="line">    <span class="built_in">hipEventRecord</span>(start_GPU,<span class="number">0</span>);</span><br><span class="line">    <span class="built_in">hipLaunchKernelGGL</span>(GpuMatrix,grid,block,<span class="number">0</span>,<span class="number">0</span>,dev_A,dev_B,dev_C);</span><br><span class="line">    <span class="built_in">hipEventRecord</span>(stop_GPU,<span class="number">0</span>);</span><br><span class="line">    <span class="built_in">hipEventSynchronize</span>(start_GPU);</span><br><span class="line">    <span class="built_in">hipEventSynchronize</span>(stop_GPU);</span><br><span class="line">    <span class="built_in">hipEventElapsedTime</span>(&amp;time_gpu, start_GPU,stop_GPU);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\nThe time from GPU:\t%f(ms)\n&quot;</span>, time_GPU/<span class="number">1000</span>);</span><br><span class="line">    <span class="built_in">hipDeviceSynchronize</span>();</span><br><span class="line">    <span class="built_in">hipEventDestroy</span>(start_GPU);</span><br><span class="line">    <span class="built_in">hipEventDestroy</span>(stop_GPU);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">hipMemcpy</span>(c_CPU,dev_C,nbytes,hipMemcpyDeviceToHost);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;device_C:(%d,%d):\n&quot;</span>,M,N);</span><br><span class="line">    <span class="built_in">printMatrix</span>(c_CPU,M,N);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">hipFree</span>(dev_A);</span><br><span class="line">    <span class="built_in">hipFree</span>(dev_B);</span><br><span class="line">    <span class="built_in">hipFree</span>(dev_C);</span><br><span class="line">    <span class="built_in">free</span>(host_A);</span><br><span class="line">    <span class="built_in">free</span>(host_B);</span><br><span class="line">    <span class="built_in">free</span>(host_C);</span><br><span class="line">    <span class="built_in">free</span>(c_CPU);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>结果如下：</p>
<p><img src="/img/1794499-20200417143326110-1808551587.png" alt="img"></p>
<p><img src="/img/1794499-20200417143351557-2115965778.png" alt="img"></p>
<h1 id="使用结构体实现HIP的矩阵乘"><a href="#使用结构体实现HIP的矩阵乘" class="headerlink" title="使用结构体实现HIP的矩阵乘"></a>使用结构体实现HIP的矩阵乘</h1><p>共享内存使用<code>__shared__</code>内存空间说明符来分配。</p>
<p>共享内存应该比全局内存快得多，这在线程结构中有提及并在共享内存中有详细描述。因此，任何可以用</p>
<p>共享内存访问替换全局内存访问的机会都应该被利用，如下面的矩阵乘法示例所示。</p>
<p>下面的示例代码是不利用共享内存的矩阵乘法的简单实现。每个线程读取 A 的一行和 B 的一列，并计算 C 的相应元素，如图 9 所示。因此，A 将从全局内存中被读取 B.width 次，而 B 将被读取 A.height 次。</p>
<p><img src="/img/1794499-20200424150554626-204754530.png" alt="img"></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;time.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;hip/hip_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;hip/hip_runtime_api.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span>&#123;</span><br><span class="line">        <span class="type">int</span> width;</span><br><span class="line">        <span class="type">int</span> height;</span><br><span class="line">        <span class="type">float</span>* elements;</span><br><span class="line">&#125;Matrix;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> BLOCK_SIZE 4</span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">MatMulKernel</span><span class="params">(<span class="type">const</span> Matrix,<span class="type">const</span> Matrix,Matrix)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">initial</span><span class="params">(<span class="type">float</span>* A,<span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>;i&lt;N;i++)</span><br><span class="line">    &#123;</span><br><span class="line">       A[i] = <span class="built_in">rand</span>()%<span class="number">10</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">shuchu</span><span class="params">(Matrix A,<span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> j=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i &lt; N; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>( j == A.width)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">            j = <span class="number">0</span>;</span><br><span class="line">            i--;</span><br><span class="line">        &#125;<span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;%15lf&quot;</span>,A.elements[i]);</span><br><span class="line">            j++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">MatMulKernel</span><span class="params">(Matrix A,Matrix B,Matrix C)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">float</span> Cvalue = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> row = hipBlockIdx_y * hipBlockDim_y + hipThreadIdx_y;</span><br><span class="line">    <span class="type">int</span> col = hipBlockIdx_x * hipBlockDim_x + hipThreadIdx_x;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> e = <span class="number">0</span>; e &lt; A.width; ++e)</span><br><span class="line">    &#123;</span><br><span class="line">        Cvalue += A.elements[row * A.width + e] * B.elements[e*B.width + col];</span><br><span class="line">    &#125;</span><br><span class="line">    C.elements[row * C.width + col] = Cvalue;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//在CPU上计算矩阵乘 </span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">CpuMatrix</span><span class="params">(Matrix A,Matrix B,Matrix C)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> M,N,K;</span><br><span class="line">    M = A.height;</span><br><span class="line">    N = B.width;</span><br><span class="line">    K = A.width;</span><br><span class="line">    <span class="type">int</span> i,j,k;</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>;i &lt; M;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(j = <span class="number">0</span>;j&lt;N;j++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">float</span> sum = <span class="number">0.0</span>;</span><br><span class="line">            <span class="keyword">for</span>(k = <span class="number">0</span>;k&lt;K;k++)</span><br><span class="line">            &#123;</span><br><span class="line">                sum += A.elements[i * K + k] * B.elements[k * N + j];</span><br><span class="line">            &#125;</span><br><span class="line">            C.elements[i * N + j] = sum;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">MatMul</span><span class="params">(Matrix A,Matrix B,Matrix C)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Matrix d_A;</span><br><span class="line">    Matrix d_B;</span><br><span class="line">    Matrix d_C;</span><br><span class="line">    d_A.width = A.width;</span><br><span class="line">    d_A.height = A.height;</span><br><span class="line">    d_B.width = B.width;</span><br><span class="line">    d_B.height = B.height;</span><br><span class="line">    d_C.width = C.width;</span><br><span class="line">    d_C.height = C.height;</span><br><span class="line">    <span class="type">size_t</span> size_A = A.width * A.height * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="type">size_t</span>  size_B = B.width * B.height * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="type">size_t</span>  size_C = C.width * C.height * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">hipMalloc</span>(&amp;d_A.elements,size_A);</span><br><span class="line">    <span class="built_in">hipMalloc</span>(&amp;d_B.elements,size_B);</span><br><span class="line">    <span class="built_in">hipMalloc</span>(&amp;d_C.elements,size_C);</span><br><span class="line">    <span class="function">dim3 <span class="title">dimBlock</span><span class="params">(BLOCK_SIZE,BLOCK_SIZE)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">dimGrid</span><span class="params">(B.width / dimBlock.x,A.height / dimBlock.y)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">hipMemcpy</span>(d_A.elements,A.elements,size_A,hipMemcpyHostToDevice);</span><br><span class="line">    <span class="built_in">hipMemcpy</span>(d_B.elements,B.elements,size_B,hipMemcpyHostToDevice);</span><br><span class="line">    <span class="comment">//测试时间</span></span><br><span class="line">    <span class="type">float</span> gpu_time;</span><br><span class="line">    hipEvent_t start_GPU,stop_GPU;</span><br><span class="line">    <span class="built_in">hipEventCreate</span>(&amp;start_GPU);</span><br><span class="line">    <span class="built_in">hipEventCreate</span>(&amp;stop_GPU);</span><br><span class="line">    <span class="built_in">hipEventRecord</span>(start_GPU,<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">hipLaunchKernelGGL</span>(MatMulKernel,dimGrid,dimBlock,<span class="number">0</span>,<span class="number">0</span>,d_A,d_B,d_C);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">hipEventRecord</span>(stop_GPU,<span class="number">0</span>);</span><br><span class="line">    <span class="built_in">hipEventSynchronize</span>(start_GPU);</span><br><span class="line">    <span class="built_in">hipEventSynchronize</span>(stop_GPU);</span><br><span class="line">    <span class="built_in">hipEventElapsedTime</span>(&amp;gpu_time,start_GPU,stop_GPU);</span><br><span class="line">    <span class="built_in">hipDeviceSynchronize</span>();</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\nGPU spend time is: %lf(ms)\n&quot;</span>,gpu_time/<span class="number">1000</span>);</span><br><span class="line">    <span class="built_in">hipEventDestroy</span>(start_GPU);</span><br><span class="line">    <span class="built_in">hipEventDestroy</span>(stop_GPU);</span><br><span class="line">    <span class="built_in">hipMemcpy</span>(C.elements,d_C.elements,size_C,hipMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\nGPU result is :\n&quot;</span>);</span><br><span class="line">    <span class="built_in">shuchu</span>(C,C.width*C.height);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    <span class="built_in">hipFree</span>(d_A.elements);</span><br><span class="line">    <span class="built_in">hipFree</span>(d_B.elements);</span><br><span class="line">    <span class="built_in">hipFree</span>(d_C.elements);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Matrix A;</span><br><span class="line">    Matrix B;</span><br><span class="line">    Matrix C;</span><br><span class="line">    A.width = BLOCK_SIZE;</span><br><span class="line">    A.height = BLOCK_SIZE;</span><br><span class="line">    B.width = BLOCK_SIZE;</span><br><span class="line">    B.height = BLOCK_SIZE;</span><br><span class="line">    C.width = BLOCK_SIZE;</span><br><span class="line">    C.height = BLOCK_SIZE;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> size = BLOCK_SIZE * BLOCK_SIZE;</span><br><span class="line">    <span class="type">int</span> size_A = A.width * A.height * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="type">int</span> size_B = B.width * B.height * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="type">int</span> size_C = C.width * C.height * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line"></span><br><span class="line">    A.elements = (<span class="type">float</span> *)<span class="built_in">malloc</span>(size_A);</span><br><span class="line">    B.elements = (<span class="type">float</span> *)<span class="built_in">malloc</span>(size_B);</span><br><span class="line">    C.elements = (<span class="type">float</span> *)<span class="built_in">malloc</span>(size_C);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">initial</span>(A.elements,A.height*A.width);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;A:\n&quot;</span>);</span><br><span class="line">    <span class="built_in">shuchu</span>(A,A.width*A.height);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\nB:\n&quot;</span>);</span><br><span class="line">    <span class="built_in">initial</span>(B.elements,B.height*B.width);</span><br><span class="line">    <span class="built_in">shuchu</span>(B,B.width*B.height);</span><br><span class="line"></span><br><span class="line">    <span class="comment">//调用CPU计算</span></span><br><span class="line">    <span class="comment">//测试CPU的计算时间</span></span><br><span class="line">    <span class="type">clock_t</span> start_CPU,stop_CPU;</span><br><span class="line">    <span class="type">double</span> cpu_time;</span><br><span class="line">    start_CPU = <span class="built_in">clock</span>();</span><br><span class="line"></span><br><span class="line">    <span class="built_in">CpuMatrix</span>(A,B,C);</span><br><span class="line">    stop_CPU = <span class="built_in">clock</span>();</span><br><span class="line">    <span class="comment">//cpu_time = (double)(stop_CPU-start_CPU)/CLOCKS_PER_SEC; </span></span><br><span class="line">    <span class="comment">//printf(&quot;\nCPU time is %lf(ms)\n&quot;,cpu_time);</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\nCPU result :\n&quot;</span>);</span><br><span class="line">    <span class="built_in">shuchu</span>(C,C.width*C.height);</span><br><span class="line">    / <span class="built_in">shuchu</span>(C,C.width*C.height);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    <span class="built_in">MatMul</span>(A,B,C);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<p><img src="/img/1794499-20200424110629946-2145566218.png" alt="img"></p>
<h1 id="利用结构体实现HIP的数组相加"><a href="#利用结构体实现HIP的数组相加" class="headerlink" title="利用结构体实现HIP的数组相加"></a>利用结构体实现HIP的数组相加</h1><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;time.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;hip/hip_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;hip/hip_runtime_api.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span>&#123;</span><br><span class="line">    <span class="type">int</span> width;</span><br><span class="line">    <span class="type">float</span>* elements;</span><br><span class="line">&#125;Matrix;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> BLOCK_SIZE 4</span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">MatMulKernel</span><span class="params">(<span class="type">const</span> Matrix,<span class="type">const</span> Matrix,Matrix)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">initial</span><span class="params">(<span class="type">float</span>* A,<span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>;i&lt;N;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        A[i] = <span class="built_in">rand</span>()%<span class="number">10</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">shuchu</span><span class="params">(Matrix A,<span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i &lt; N; i++)</span><br><span class="line">    &#123;</span><br><span class="line">       <span class="built_in">printf</span>(<span class="string">&quot;%10lf&quot;</span>,A.elements[i]);  </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">MatMulKernel</span><span class="params">(Matrix A,Matrix B,Matrix C)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> col = hipBlockIdx_x * hipBlockDim_x + hipThreadIdx_x;</span><br><span class="line">    C.elements[col] = A.elements[col]+B.elements[col];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">CpuMatrix</span><span class="params">(Matrix A,Matrix B,Matrix C)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> N;</span><br><span class="line">    N = B.width;</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;N;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        C.elements[i] = A.elements[i] + B.elements[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">MatMul</span><span class="params">(Matrix A,Matrix B,Matrix C)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Matrix d_A;</span><br><span class="line">    Matrix d_B;</span><br><span class="line">    Matrix d_C;</span><br><span class="line">    d_A.width = A.width;</span><br><span class="line">    d_B.width = B.width;</span><br><span class="line">    d_C.width = C.width;</span><br><span class="line">    </span><br><span class="line">    <span class="type">size_t</span> size_A = A.width * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="type">size_t</span> size_B = B.width * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="type">size_t</span> size_C = C.width * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">hipMalloc</span>(&amp;d_A.elements,size_A);</span><br><span class="line">    <span class="built_in">hipMalloc</span>(&amp;d_B.elements,size_B);</span><br><span class="line">    <span class="built_in">hipMalloc</span>(&amp;d_C.elements,size_C);</span><br><span class="line">    <span class="function">dim3 <span class="title">dimBlock</span><span class="params">(BLOCK_SIZE,BLOCK_SIZE)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">dimGrid</span><span class="params">(<span class="number">1</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">hipMemcpy</span>(d_A.elements,A.elements,size_A,hipMemcpyHostToDevice);</span><br><span class="line">    <span class="built_in">hipMemcpy</span>(d_B.elements,B.elements,size_B,hipMemcpyHostToDevice);</span><br><span class="line"> </span><br><span class="line">    <span class="type">float</span> gpu_time;</span><br><span class="line">    hipEvent_t start_GPU,stop_GPU;</span><br><span class="line">    <span class="built_in">hipEventCreate</span>(&amp;start_GPU);</span><br><span class="line">    <span class="built_in">hipEventCreate</span>(&amp;stop_GPU);</span><br><span class="line">    <span class="built_in">hipEventRecord</span>(start_GPU,<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">hipLaunchKernelGGL</span>(MatMulKernel,dimGrid,dimBlock,<span class="number">0</span>,<span class="number">0</span>,d_A,d_B,d_C);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">hipEventRecord</span>(stop_GPU,<span class="number">0</span>);</span><br><span class="line">    <span class="built_in">hipEventSynchronize</span>(start_GPU);</span><br><span class="line">    <span class="built_in">hipEventSynchronize</span>(stop_GPU);</span><br><span class="line">    <span class="built_in">hipEventElapsedTime</span>(&amp;gpu_time,start_GPU,stop_GPU);</span><br><span class="line">    <span class="built_in">hipDeviceSynchronize</span>();</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\nGPU spend time is: %lf(ms)\n&quot;</span>,gpu_time/<span class="number">1000</span>);</span><br><span class="line">    <span class="built_in">hipEventDestroy</span>(start_GPU);</span><br><span class="line">    <span class="built_in">hipEventDestroy</span>(stop_GPU);</span><br><span class="line">    <span class="built_in">hipMemcpy</span>(C.elements,d_C.elements,size_C,hipMemcpyDeviceToHost);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\nGPU result is :\n&quot;</span>);</span><br><span class="line">    <span class="built_in">shuchu</span>(C,C.width);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    <span class="built_in">hipFree</span>(d_A.elements);</span><br><span class="line">    <span class="built_in">hipFree</span>(d_B.elements);</span><br><span class="line">    <span class="built_in">hipFree</span>(d_C.elements);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Matrix A;</span><br><span class="line">    Matrix B;</span><br><span class="line">    Matrix C;</span><br><span class="line">    A.width = BLOCK_SIZE;</span><br><span class="line">    </span><br><span class="line">    B.width = BLOCK_SIZE;</span><br><span class="line">    </span><br><span class="line">    C.width = BLOCK_SIZE;</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> size_A = A.width * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="type">int</span> size_B = B.width * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="type">int</span> size_C = C.width * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line"></span><br><span class="line">    A.elements = (<span class="type">float</span> *)<span class="built_in">malloc</span>(size_A);</span><br><span class="line">    B.elements = (<span class="type">float</span> *)<span class="built_in">malloc</span>(size_B);</span><br><span class="line">    C.elements = (<span class="type">float</span> *)<span class="built_in">malloc</span>(size_C);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">initial</span>(A.elements,A.width);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;A:\n&quot;</span>);</span><br><span class="line">    <span class="built_in">shuchu</span>(A,A.width);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\nB:\n&quot;</span>);</span><br><span class="line">    <span class="built_in">initial</span>(B.elements,B.width);</span><br><span class="line">    <span class="built_in">shuchu</span>(B,B.width);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">CpuMatrix</span>(A,B,C);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\nCPU result :\n&quot;</span>);</span><br><span class="line">    <span class="built_in">shuchu</span>(C,C.width);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    <span class="built_in">MatMul</span>(A,B,C);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><a href="javascript:void(0"><img src="/img/copycode.gif" alt="复制代码"></a>;)</p>
<p>运行结果如下：</p>
<p><img src="/img/1794499-20200424140453323-1505101520.png" alt="img"></p>
<h1 id="使用共享内存实现矩阵乘法（利用了结构体）"><a href="#使用共享内存实现矩阵乘法（利用了结构体）" class="headerlink" title="使用共享内存实现矩阵乘法（利用了结构体）"></a>使用共享内存实现矩阵乘法（利用了结构体）</h1><p>下面的示例代码是利用共享内存的矩阵乘法的实现.在这个实现中,每个线程块负责计算 C 的一个方形子 矩阵 Csub ,块内的每个线程负责计算 Csub 的一个元素.如图 10 所示,Csub 等于两个矩阵的乘积：维度为 (A.width, block_size)的子矩阵 A 与 Csub 有相同的行索引,维度为(block_size, A.width )的子矩阵 B 与 Csub 有相同的列索引.为了适应设备资源的需求,将这两个矩阵根据需要分为维度为 block_size 的多个 正方形矩阵.计算这些方形矩阵的乘积之和即可得到 Csub .这些乘积中的每一个的计算都是首先将两个 对应的正方形矩阵从全局内存加载到共享内存,一个线程加载一个元素,然后再让每个线程计算一个元 素.每个线程将这些乘积的结果累积到一个寄存器中,完成后再将结果写入全局内存.</p>
<p>通过这种方式分块计算，我们充分利用了快速的共享内存，并节省了大量的全局内存带宽，因为 A 只从全局内存中读取了(B.width / block_size)次，B 只从全局内存中读取了(A.height / block_size)次。</p>
<p>前一段示例代码中的矩阵类型使用了 stride 字段进行扩充，因此可以使用相同类型有效地表示子矩阵。<strong>device</strong>函数用于获取和设置元素并从矩阵中构建任何子矩阵。</p>
<p><img src="/img/1794499-20200424145857004-435911930.png" alt="img"></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;hip/hip_runtime.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;hip/hip_runtime_api.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">struct</span>&#123;</span><br><span class="line">    <span class="type">int</span> width;</span><br><span class="line">    <span class="type">int</span> height;        </span><br><span class="line">    <span class="type">int</span> stride;</span><br><span class="line">    <span class="type">float</span>* elements;</span><br><span class="line">&#125;Matrix;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> BLOCK_SIZE 4</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//初始化 </span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">initial</span><span class="params">(<span class="type">float</span>* A,<span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i;</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>;i&lt;N;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        A[i] = <span class="built_in">rand</span>()%<span class="number">10</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">float</span> <span class="title">GetElement</span><span class="params">(<span class="type">const</span> Matrix A,<span class="type">int</span> row,<span class="type">int</span> col)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> A.elements[row*A.stride+col];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__device__ <span class="type">void</span> <span class="title">SetElement</span><span class="params">(Matrix A,<span class="type">int</span> row,<span class="type">int</span> col,<span class="type">float</span> value)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    A.elements[row*A.stride+col]=value;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">__device__ Matrix <span class="title">GetSubMatrix</span><span class="params">(Matrix A,<span class="type">int</span> row,<span class="type">int</span> col)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Matrix Asub;</span><br><span class="line">    Asub.width = BLOCK_SIZE;</span><br><span class="line">    Asub.height = BLOCK_SIZE;</span><br><span class="line">    Asub.stride = A.stride;</span><br><span class="line">    Asub.elements = &amp;A.elements[A.stride*BLOCK_SIZE*row+BLOCK_SIZE*col];</span><br><span class="line">    <span class="keyword">return</span> Asub;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">shuchu</span><span class="params">(Matrix A,<span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> j=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i &lt; N; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>( j == A.width)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">            j = <span class="number">0</span>;</span><br><span class="line">            i--;</span><br><span class="line">        &#125;<span class="keyword">else</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">&quot;%15lf&quot;</span>,A.elements[i]);</span><br><span class="line">            j++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">MatMulKernel</span><span class="params">(Matrix A,Matrix B,Matrix C)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> blockRow = hipBlockIdx_y;</span><br><span class="line">    <span class="type">int</span> blockCol = hipBlockIdx_x;</span><br><span class="line">    Matrix Csub = <span class="built_in">GetSubMatrix</span>(C,blockRow,blockCol);</span><br><span class="line">    <span class="type">float</span> Cvalue = <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> row = hipThreadIdx_y;</span><br><span class="line">    <span class="type">int</span> col = hipThreadIdx_x;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> m=<span class="number">0</span>; m&lt;(A.width/BLOCK_SIZE);++m)</span><br><span class="line">    &#123;</span><br><span class="line">        Matrix Asub = <span class="built_in">GetSubMatrix</span>(A,blockRow,m);</span><br><span class="line">        Matrix Bsub = <span class="built_in">GetSubMatrix</span>(B,m,blockCol);</span><br><span class="line">        __shared__ <span class="type">float</span> As[BLOCK_SIZE][BLOCK_SIZE];</span><br><span class="line">        __shared__ <span class="type">float</span> Bs[BLOCK_SIZE][BLOCK_SIZE];</span><br><span class="line"></span><br><span class="line">        As[row][col]=<span class="built_in">GetElement</span>(Asub,row,col);</span><br><span class="line">        Bs[row][col]=<span class="built_in">GetElement</span>(Bsub,row,col);</span><br><span class="line"></span><br><span class="line">        __syncthreads();</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> e = <span class="number">0</span>;e&lt;BLOCK_SIZE;++e)</span><br><span class="line">        &#123;</span><br><span class="line">            Cvalue += As[row][e]*Bs[e][col];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">        <span class="built_in">SetElement</span>(Csub,row,col,Cvalue);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">MatMul</span><span class="params">(<span class="type">const</span> Matrix A,<span class="type">const</span> Matrix B,Matrix C)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Matrix d_A;</span><br><span class="line">    d_A.width = d_A.stride = A.width;</span><br><span class="line">    d_A.height = A.height;</span><br><span class="line">    <span class="type">size_t</span> size = A.width * A.height * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="built_in">hipMalloc</span>(&amp;d_A.elements,size);</span><br><span class="line">    <span class="built_in">hipMemcpy</span>(d_A.elements,A.elements,size,hipMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    Matrix d_B;</span><br><span class="line">    d_B.width = d_B.stride=B.width;</span><br><span class="line">    d_B.height = B.height;</span><br><span class="line">    size = B.width * B.height * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="built_in">hipMalloc</span>(&amp;d_B.elements,size);</span><br><span class="line">    <span class="built_in">hipMemcpy</span>(d_B.elements,B.elements,size,hipMemcpyHostToDevice);</span><br><span class="line"></span><br><span class="line">    Matrix d_C;</span><br><span class="line">    d_C.width = d_C.stride =  C.width;</span><br><span class="line">    d_C.height = C.height;</span><br><span class="line">    size = C.width * C.height * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="built_in">hipMalloc</span>(&amp;d_C.elements,size);</span><br><span class="line">    <span class="function">dim3 <span class="title">dimBlock</span><span class="params">(BLOCK_SIZE,BLOCK_SIZE)</span></span>;</span><br><span class="line">    <span class="function">dim3 <span class="title">dimGrid</span><span class="params">(B.width / dimBlock.x,A.height / dimBlock.y)</span></span>;</span><br><span class="line">    </span><br><span class="line">    <span class="type">float</span> gpu_time;</span><br><span class="line">    hipEvent_t start_GPU,stop_GPU;</span><br><span class="line">    <span class="built_in">hipEventCreate</span>(&amp;start_GPU);</span><br><span class="line">    <span class="built_in">hipEventCreate</span>(&amp;stop_GPU);</span><br><span class="line">    <span class="built_in">hipEventRecord</span>(start_GPU,<span class="number">0</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">hipLaunchKernelGGL</span>(MatMulKernel,dimGrid,dimBlock,<span class="number">0</span>,<span class="number">0</span>,d_A,d_B,d_C);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">hipEventRecord</span>(stop_GPU,<span class="number">0</span>);</span><br><span class="line">    <span class="built_in">hipEventSynchronize</span>(start_GPU);</span><br><span class="line">    <span class="built_in">hipEventSynchronize</span>(stop_GPU);</span><br><span class="line">    <span class="built_in">hipEventElapsedTime</span>(&amp;gpu_time,start_GPU,stop_GPU);</span><br><span class="line">    <span class="built_in">hipDeviceSynchronize</span>();</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\nGPU spend time is: %lf(ms)\n&quot;</span>,gpu_time/<span class="number">1000</span>);</span><br><span class="line">    <span class="built_in">hipEventDestroy</span>(start_GPU);</span><br><span class="line">    <span class="built_in">hipEventDestroy</span>(stop_GPU);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">hipMemcpy</span>(C.elements,d_C.elements,size,hipMemcpyDeviceToHost);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\nGPU result is:\n&quot;</span>);</span><br><span class="line">    <span class="built_in">shuchu</span>(C,C.width*C.height);</span><br><span class="line">    <span class="built_in">hipFree</span>(d_A.elements);</span><br><span class="line">    <span class="built_in">hipFree</span>(d_B.elements);</span><br><span class="line">    <span class="built_in">hipFree</span>(d_C.elements);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//使用CPU进行计算 </span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">CpuMatrix</span><span class="params">(Matrix A,Matrix B,Matrix C)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> M,N,K;</span><br><span class="line">    M = A.height;</span><br><span class="line">    N = B.width;</span><br><span class="line">    K = A.width;</span><br><span class="line">    <span class="type">int</span> i,j,k;</span><br><span class="line">    <span class="keyword">for</span>(i = <span class="number">0</span>;i &lt; M;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(j = <span class="number">0</span>;j&lt;N;j++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">float</span> sum = <span class="number">0.0</span>;</span><br><span class="line">            <span class="keyword">for</span>(k = <span class="number">0</span>;k&lt;K;k++)</span><br><span class="line">            &#123;</span><br><span class="line">                sum += A.elements[i * K + k] * B.elements[k * N + j];</span><br><span class="line">            &#125;</span><br><span class="line">            C.elements[i * N + j] = sum;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Matrix A;</span><br><span class="line">    Matrix B;</span><br><span class="line">    Matrix C;</span><br><span class="line"></span><br><span class="line">    A.width = BLOCK_SIZE;</span><br><span class="line">    A.height = BLOCK_SIZE;</span><br><span class="line">    B.width = BLOCK_SIZE;</span><br><span class="line">    B.height = BLOCK_SIZE;</span><br><span class="line">    C.width = BLOCK_SIZE;</span><br><span class="line">    C.height = BLOCK_SIZE;</span><br><span class="line">    </span><br><span class="line">    <span class="type">int</span> size_A = A.width * A.height * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="type">int</span> size_B = B.width * B.height * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line">    <span class="type">int</span> size_C = C.width * C.height * <span class="built_in">sizeof</span>(<span class="type">float</span>);</span><br><span class="line"></span><br><span class="line">    A.elements = (<span class="type">float</span> *)<span class="built_in">malloc</span>(size_A);</span><br><span class="line">    B.elements = (<span class="type">float</span> *)<span class="built_in">malloc</span>(size_B);</span><br><span class="line">    C.elements = (<span class="type">float</span> *)<span class="built_in">malloc</span>(size_C);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">initial</span>(A.elements,A.height*A.width);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;A:\n&quot;</span>);</span><br><span class="line">    <span class="built_in">shuchu</span>(A,A.width*A.height);</span><br><span class="line">       </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\nB:\n&quot;</span>);</span><br><span class="line">    <span class="built_in">initial</span>(B.elements,B.height*B.width);</span><br><span class="line">    <span class="built_in">shuchu</span>(B,B.width*B.height);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">CpuMatrix</span>(A,B,C);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;\nCPU result :\n&quot;</span>);</span><br><span class="line">    <span class="built_in">shuchu</span>(C,C.width*C.height);</span><br><span class="line">    <span class="built_in">MatMul</span>(A,B,C);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>运行结果如下：</p>
<p><img src="/img/1794499-20200424150302330-1828113155.png" alt="img"></p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E7%A7%AF%E7%B4%AF/" rel="tag"># 积累</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/12/26/GDB_GIT_qsub_tmux%E7%AD%89%E5%B7%A5%E5%85%B7%E7%9B%B8%E5%85%B3/" rel="prev" title="gdb、git、qsub、tmux、memcached开发工具相关">
      <i class="fa fa-chevron-left"></i> gdb、git、qsub、tmux、memcached开发工具相关
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/01/12/parallel_cuda/" rel="next" title="parallel CUDA 介绍">
      parallel CUDA 介绍 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFrocm%EF%BC%9F"><span class="nav-number">1.</span> <span class="nav-text">什么是rocm？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CUDA%E5%88%B0HIP%E8%BD%AC%E7%A0%81"><span class="nav-number">2.</span> <span class="nav-text">CUDA到HIP转码</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#CUDA%E4%B8%8EHIP"><span class="nav-number">2.1.</span> <span class="nav-text">CUDA与HIP</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HIP%E8%BD%AC%E7%A0%81%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="nav-number">2.2.</span> <span class="nav-text">HIP转码的实现</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hipify-clang%E4%BB%A3%E7%A0%81%E7%AE%80%E4%BB%8B"><span class="nav-number">2.3.</span> <span class="nav-text">hipify-clang代码简介</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hipify-perl%E7%A8%8B%E5%BA%8F%E7%AE%80%E4%BB%8B"><span class="nav-number">2.4.</span> <span class="nav-text">hipify-perl程序简介</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E"><span class="nav-number">2.5.</span> <span class="nav-text">使用说明</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hipify-clang"><span class="nav-number">2.6.</span> <span class="nav-text">hipify-clang</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hipify-perl"><span class="nav-number">2.7.</span> <span class="nav-text">hipify-perl</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cuda2hip-sh"><span class="nav-number">2.8.</span> <span class="nav-text">cuda2hip.sh</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cuda2hip-sed"><span class="nav-number">2.9.</span> <span class="nav-text">cuda2hip.sed</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cuda2hipsed-sh"><span class="nav-number">2.10.</span> <span class="nav-text">cuda2hipsed.sh</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Getting-Started-with-HIP-API"><span class="nav-number">2.11.</span> <span class="nav-text">Getting Started with HIP API</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#HIP-API-Overview"><span class="nav-number">2.11.1.</span> <span class="nav-text">HIP API Overview</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HIP-API-Examples"><span class="nav-number">2.11.2.</span> <span class="nav-text">HIP API Examples</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Example-1"><span class="nav-number">2.11.2.1.</span> <span class="nav-text">Example 1</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Example-2"><span class="nav-number">2.11.2.2.</span> <span class="nav-text">Example 2</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction-to-Memory-Allocation"><span class="nav-number">2.12.</span> <span class="nav-text">Introduction to Memory Allocation</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Host-Memory"><span class="nav-number">2.12.1.</span> <span class="nav-text">Host Memory</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Memory-allocation-flags"><span class="nav-number">2.12.2.</span> <span class="nav-text">Memory allocation flags</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NUMA-aware-host-memory-allocation"><span class="nav-number">2.12.3.</span> <span class="nav-text">NUMA-aware host memory allocation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Managed-memory-allocation"><span class="nav-number">2.12.4.</span> <span class="nav-text">Managed memory allocation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HIP-Stream-Memory-Operations"><span class="nav-number">2.12.5.</span> <span class="nav-text">HIP Stream Memory Operations</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Coherency-Controls"><span class="nav-number">2.12.6.</span> <span class="nav-text">Coherency Controls</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Visibility-of-Zero-Copy-Host-Memory"><span class="nav-number">2.12.7.</span> <span class="nav-text">Visibility of Zero-Copy Host Memory</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#hipEventSynchronize"><span class="nav-number">2.12.7.1.</span> <span class="nav-text">hipEventSynchronize</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Direct-Dispatch"><span class="nav-number">2.12.7.2.</span> <span class="nav-text">Direct Dispatch</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HIP-Runtime-Compilation"><span class="nav-number">2.12.7.3.</span> <span class="nav-text">HIP Runtime Compilation</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Use-of-Long-Double-Type"><span class="nav-number">2.12.7.4.</span> <span class="nav-text">Use of Long Double Type</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#FMA-and-Contractions"><span class="nav-number">2.12.7.5.</span> <span class="nav-text">FMA and Contractions</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Use-of-Float16-Type"><span class="nav-number">2.12.7.6.</span> <span class="nav-text">Use of _Float16 Type</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Math-Functions-with-Special-Rounding-Modes"><span class="nav-number">2.12.7.7.</span> <span class="nav-text">Math Functions with Special Rounding Modes</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Creating-Static-Libraries"><span class="nav-number">2.12.7.8.</span> <span class="nav-text">Creating Static Libraries</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HIP-Kernel-Language"><span class="nav-number">2.13.</span> <span class="nav-text">HIP Kernel Language</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Function-Type-Qualifiers"><span class="nav-number">2.13.1.</span> <span class="nav-text">Function-Type Qualifiers</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Calling-global-Functions"><span class="nav-number">2.13.1.1.</span> <span class="nav-text">Calling global Functions</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Variable-Type-Qualifiers"><span class="nav-number">2.13.2.</span> <span class="nav-text">Variable-Type Qualifiers</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#constant"><span class="nav-number">2.13.2.1.</span> <span class="nav-text">constant</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#shared"><span class="nav-number">2.13.2.2.</span> <span class="nav-text">shared</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#managed"><span class="nav-number">2.13.2.3.</span> <span class="nav-text">managed</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#restrict"><span class="nav-number">2.13.2.4.</span> <span class="nav-text">restrict</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Built-In-Variables"><span class="nav-number">2.13.3.</span> <span class="nav-text">Built-In Variables</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Coordinate-Built-Ins"><span class="nav-number">2.13.3.1.</span> <span class="nav-text">Coordinate Built-Ins</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#warpSize"><span class="nav-number">2.13.3.2.</span> <span class="nav-text">warpSize</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Vector-Types"><span class="nav-number">2.13.4.</span> <span class="nav-text">Vector Types</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Short-Vector-Types"><span class="nav-number">2.13.4.1.</span> <span class="nav-text">Short Vector Types</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#dim3"><span class="nav-number">2.13.4.2.</span> <span class="nav-text">dim3</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Memory-Fence-Instructions"><span class="nav-number">2.13.5.</span> <span class="nav-text">Memory-Fence Instructions</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Synchronization-Functions"><span class="nav-number">2.13.6.</span> <span class="nav-text">Synchronization Functions</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Math-Functions"><span class="nav-number">2.13.7.</span> <span class="nav-text">Math Functions</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Single-Precision-Mathematical-Functions"><span class="nav-number">2.13.7.1.</span> <span class="nav-text">Single Precision Mathematical Functions</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Double-Precision-Mathematical-Functions"><span class="nav-number">2.13.7.2.</span> <span class="nav-text">Double Precision Mathematical Functions</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Integer-Intrinsics"><span class="nav-number">2.13.7.3.</span> <span class="nav-text">Integer Intrinsics</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Floating-point-Intrinsics"><span class="nav-number">2.13.7.4.</span> <span class="nav-text">Floating-point Intrinsics</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Texture-Functions"><span class="nav-number">2.13.7.5.</span> <span class="nav-text">Texture Functions</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Timer-Functions"><span class="nav-number">2.13.7.6.</span> <span class="nav-text">Timer Functions</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Atomic-Functions"><span class="nav-number">2.13.7.7.</span> <span class="nav-text">Atomic Functions</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Warp-Cross-Lane-Functions"><span class="nav-number">2.13.7.8.</span> <span class="nav-text">Warp Cross-Lane Functions</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Warp-Vote-and-Ballot-Functions"><span class="nav-number">2.13.7.9.</span> <span class="nav-text">Warp Vote and Ballot Functions</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Cooperative-Groups-Functions"><span class="nav-number">2.13.7.10.</span> <span class="nav-text">Cooperative Groups Functions</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Warp-Matrix-Functions"><span class="nav-number">2.13.7.11.</span> <span class="nav-text">Warp Matrix Functions</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Independent-Thread-Scheduling"><span class="nav-number">2.13.7.12.</span> <span class="nav-text">Independent Thread Scheduling</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Assert"><span class="nav-number">2.13.7.13.</span> <span class="nav-text">Assert</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Printf"><span class="nav-number">2.13.7.14.</span> <span class="nav-text">Printf</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Device-Side-Dynamic-Global-Memory-Allocation"><span class="nav-number">2.13.8.</span> <span class="nav-text">Device-Side Dynamic Global Memory Allocation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#launch-bounds"><span class="nav-number">2.13.9.</span> <span class="nav-text">__launch_bounds__</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Compiler-Impact"><span class="nav-number">2.13.9.1.</span> <span class="nav-text">Compiler Impact</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#CU-and-EU-Definitions"><span class="nav-number">2.13.9.2.</span> <span class="nav-text">CU and EU Definitions</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Porting-from-CUDA-launch-bounds"><span class="nav-number">2.13.9.3.</span> <span class="nav-text">Porting from CUDA __launch_bounds</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Maxregcount"><span class="nav-number">2.13.9.4.</span> <span class="nav-text">Maxregcount</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Register-Keyword"><span class="nav-number">2.13.10.</span> <span class="nav-text">Register Keyword</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pragma-Unroll"><span class="nav-number">2.13.11.</span> <span class="nav-text">Pragma Unroll</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#In-Line-Assembly"><span class="nav-number">2.13.12.</span> <span class="nav-text">In-Line Assembly</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#C-Support"><span class="nav-number">2.13.13.</span> <span class="nav-text">C++ Support</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kernel-Compilation"><span class="nav-number">2.13.14.</span> <span class="nav-text">Kernel Compilation</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ROCm-Code-Object-Tooling"><span class="nav-number">2.14.</span> <span class="nav-text">ROCm Code Object Tooling</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#roc-obj"><span class="nav-number">2.14.1.</span> <span class="nav-text">roc-obj</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Examples"><span class="nav-number">2.14.1.1.</span> <span class="nav-text">Examples</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HIP-Logging"><span class="nav-number">2.15.</span> <span class="nav-text">HIP Logging</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#HIP-Logging-Level"><span class="nav-number">2.15.1.</span> <span class="nav-text">HIP Logging Level</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HIP-Logging-Mask"><span class="nav-number">2.15.2.</span> <span class="nav-text">HIP Logging Mask</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HIP-Logging-Command"><span class="nav-number">2.15.3.</span> <span class="nav-text">HIP Logging Command</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HIP-Logging-Example"><span class="nav-number">2.15.4.</span> <span class="nav-text">HIP Logging Example</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Debugging-HIP"><span class="nav-number">2.16.</span> <span class="nav-text">Debugging HIP</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Debugging-tools"><span class="nav-number">2.16.1.</span> <span class="nav-text">Debugging tools</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Using-ltrace"><span class="nav-number">2.16.1.1.</span> <span class="nav-text">Using ltrace</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Using-ROCgdb"><span class="nav-number">2.16.1.2.</span> <span class="nav-text">Using ROCgdb</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Debugging-HIP-Applications"><span class="nav-number">2.16.2.</span> <span class="nav-text">Debugging HIP Applications</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Useful-Environment-Variables"><span class="nav-number">2.16.3.</span> <span class="nav-text">Useful Environment Variables</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Kernel-Enqueue-Serialization-%E5%86%85%E6%A0%B8%E6%8E%92%E9%98%9F%E5%BA%8F%E5%88%97%E5%8C%96"><span class="nav-number">2.16.3.1.</span> <span class="nav-text">Kernel Enqueue Serialization  内核排队序列化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Making-Device-Visible"><span class="nav-number">2.16.3.2.</span> <span class="nav-text">Making Device Visible</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Dump-code-object"><span class="nav-number">2.16.3.3.</span> <span class="nav-text">Dump code object</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#HSA-related-environment-variables"><span class="nav-number">2.16.3.4.</span> <span class="nav-text">HSA related environment variables</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Summary-of-Environment-Variables-in-HIP"><span class="nav-number">2.16.3.5.</span> <span class="nav-text">Summary of Environment Variables in HIP</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#General-Debugging-Tips"><span class="nav-number">2.16.4.</span> <span class="nav-text">General Debugging Tips</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HIP-Version"><span class="nav-number">2.17.</span> <span class="nav-text">HIP Version</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Transiting-from-CUDA-to-HIP"><span class="nav-number">3.</span> <span class="nav-text">Transiting from CUDA to HIP</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Transition-Tool-HIPIFY"><span class="nav-number">3.1.</span> <span class="nav-text">Transition Tool: HIPIFY</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Sample-and-Practice"><span class="nav-number">3.1.1.</span> <span class="nav-text">Sample and Practice</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HIP-Porting-Process"><span class="nav-number">3.2.</span> <span class="nav-text">HIP Porting Process</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Porting-a-New-CUDA-Project"><span class="nav-number">3.2.1.</span> <span class="nav-text">Porting a New CUDA Project</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#General-Tips"><span class="nav-number">3.2.1.1.</span> <span class="nav-text">General Tips</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Scanning-existing-CUDA-code-to-scope-the-porting-effort-%E6%89%AB%E6%8F%8F%E7%8E%B0%E6%9C%89CUDA%E4%BB%A3%E7%A0%81%E4%BB%A5%E7%A1%AE%E5%AE%9A%E7%A7%BB%E6%A4%8D%E5%B7%A5%E4%BD%9C%E7%9A%84%E8%8C%83%E5%9B%B4"><span class="nav-number">3.2.1.2.</span> <span class="nav-text">Scanning existing CUDA code to scope the porting effort  扫描现有CUDA代码以确定移植工作的范围</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Converting-a-project-in-place"><span class="nav-number">3.2.1.3.</span> <span class="nav-text">Converting a project in-place</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Library-Equivalents"><span class="nav-number">3.2.1.4.</span> <span class="nav-text">Library Equivalents</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Distinguishing-Compiler-Modes"><span class="nav-number">3.2.2.</span> <span class="nav-text">Distinguishing Compiler Modes</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Identifying-HIP-Target-Platform"><span class="nav-number">3.2.2.1.</span> <span class="nav-text">Identifying HIP Target Platform</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Identifying-the-Compiler-HIP-Clang-or-NVIDIA"><span class="nav-number">3.2.2.2.</span> <span class="nav-text">Identifying the Compiler: HIP-Clang or NVIDIA</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Identifying-Current-Compilation-Pass-Host-or-Device-%E8%AF%86%E5%88%AB%E5%BD%93%E5%89%8D%E7%BC%96%E8%AF%91%E8%BF%87%E7%A8%8B%EF%BC%9A%E4%B8%BB%E6%9C%BA%E6%88%96%E8%AE%BE%E5%A4%87"><span class="nav-number">3.2.2.3.</span> <span class="nav-text">Identifying Current Compilation Pass: Host or Device  识别当前编译过程：主机或设备</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Compiler-Defines-Summary"><span class="nav-number">3.2.3.</span> <span class="nav-text">Compiler Defines: Summary</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Identifying-Architecture-Features"><span class="nav-number">3.3.</span> <span class="nav-text">Identifying Architecture Features</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#HIP-ARCH-Defines"><span class="nav-number">3.3.1.</span> <span class="nav-text">HIP_ARCH Defines</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Device-Architecture-Properties"><span class="nav-number">3.3.2.</span> <span class="nav-text">Device-Architecture Properties</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Table-of-Architecture-Properties"><span class="nav-number">3.3.3.</span> <span class="nav-text">Table of Architecture Properties</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Finding-HIP"><span class="nav-number">3.3.4.</span> <span class="nav-text">Finding HIP</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Identifying-HIP-Runtime"><span class="nav-number">3.3.5.</span> <span class="nav-text">Identifying HIP Runtime</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hipLaunchKernel"><span class="nav-number">3.3.6.</span> <span class="nav-text">hipLaunchKernel</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Compiler-Options"><span class="nav-number">3.3.7.</span> <span class="nav-text">Compiler Options</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Compiler-Options-Supported-on-AMD-Platforms"><span class="nav-number">3.3.7.1.</span> <span class="nav-text">Compiler Options Supported on AMD Platforms</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Option-for-specifying-GPU-processor"><span class="nav-number">3.3.7.2.</span> <span class="nav-text">Option for specifying GPU processor</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Linking-Issues"><span class="nav-number">3.3.8.</span> <span class="nav-text">Linking Issues</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Linking-with-hipcc"><span class="nav-number">3.3.8.1.</span> <span class="nav-text">Linking with hipcc</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Linking-Code-with-Other-Compilers"><span class="nav-number">3.4.</span> <span class="nav-text">Linking Code with Other Compilers</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#libc-and-libstdc"><span class="nav-number">3.4.1.</span> <span class="nav-text">libc++ and libstdc++</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HIP-Headers-hip-runtime-h-hip-runtime-api-h"><span class="nav-number">3.4.2.</span> <span class="nav-text">HIP Headers (hip_runtime.h, hip_runtime_api.h)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Using-a-Standard-C-Compiler"><span class="nav-number">3.4.3.</span> <span class="nav-text">Using a Standard C++ Compiler</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#cuda-h"><span class="nav-number">3.4.3.1.</span> <span class="nav-text">cuda.h</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Choosing-HIP-File-Extensions"><span class="nav-number">3.4.4.</span> <span class="nav-text">Choosing HIP File Extensions</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Workarounds"><span class="nav-number">3.5.</span> <span class="nav-text">Workarounds</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#memcpyToSymbol"><span class="nav-number">3.5.1.</span> <span class="nav-text">memcpyToSymbol</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CU-POINTER-ATTRIBUTE-MEMORY-TYPE"><span class="nav-number">3.5.2.</span> <span class="nav-text">CU_POINTER_ATTRIBUTE_MEMORY_TYPE</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#threadfence-system"><span class="nav-number">3.5.3.</span> <span class="nav-text">threadfence_system</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Textures-and-Cache-Control"><span class="nav-number">3.5.4.</span> <span class="nav-text">Textures and Cache Control</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HIP-Porting-Driver-API"><span class="nav-number">3.6.</span> <span class="nav-text">HIP Porting Driver API</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Porting-CUDA-Driver-API"><span class="nav-number">3.6.1.</span> <span class="nav-text">Porting CUDA Driver API</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cuModule-API"><span class="nav-number">3.6.2.</span> <span class="nav-text">cuModule API</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#cuCtx-API"><span class="nav-number">3.6.3.</span> <span class="nav-text">cuCtx API</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HIP-Module-and-Ctx-APIs"><span class="nav-number">3.6.4.</span> <span class="nav-text">HIP Module and Ctx APIs</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#hipModule-API"><span class="nav-number">3.6.4.1.</span> <span class="nav-text">hipModule API</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hipCtx-API"><span class="nav-number">3.6.5.</span> <span class="nav-text">hipCtx API</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#hipify-translation-of-CUDA-Driver-API"><span class="nav-number">3.6.6.</span> <span class="nav-text">hipify translation of CUDA Driver API</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#HIP-Clang-Implementation-Notes"><span class="nav-number">3.7.</span> <span class="nav-text">HIP-Clang Implementation Notes</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#hip-fatbin"><span class="nav-number">3.7.1.</span> <span class="nav-text">.hip_fatbin</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Initialization-and-Termination-Functions"><span class="nav-number">3.7.2.</span> <span class="nav-text">Initialization and Termination Functions</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kernel-Launching"><span class="nav-number">3.7.3.</span> <span class="nav-text">Kernel Launching</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Address-Spaces"><span class="nav-number">3.7.4.</span> <span class="nav-text">Address Spaces</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Using-hipModuleLaunchKernel"><span class="nav-number">3.7.5.</span> <span class="nav-text">Using hipModuleLaunchKernel</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Additional-Information"><span class="nav-number">3.7.6.</span> <span class="nav-text">Additional Information</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NVCC-Implementation-Notes"><span class="nav-number">3.8.</span> <span class="nav-text">NVCC Implementation Notes</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Interoperation-between-HIP-and-CUDA-Driver"><span class="nav-number">3.8.1.</span> <span class="nav-text">Interoperation between HIP and CUDA Driver</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Compilation-Options"><span class="nav-number">3.8.2.</span> <span class="nav-text">Compilation Options</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HIP-Module-and-Texture-Driver-API"><span class="nav-number">3.8.3.</span> <span class="nav-text">HIP Module and Texture Driver API</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8hip%E5%AE%9E%E7%8E%B0%E7%9F%A9%E9%98%B5%E4%B9%98"><span class="nav-number">4.</span> <span class="nav-text">使用hip实现矩阵乘</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E7%BB%93%E6%9E%84%E4%BD%93%E5%AE%9E%E7%8E%B0HIP%E7%9A%84%E7%9F%A9%E9%98%B5%E4%B9%98"><span class="nav-number">5.</span> <span class="nav-text">使用结构体实现HIP的矩阵乘</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%88%A9%E7%94%A8%E7%BB%93%E6%9E%84%E4%BD%93%E5%AE%9E%E7%8E%B0HIP%E7%9A%84%E6%95%B0%E7%BB%84%E7%9B%B8%E5%8A%A0"><span class="nav-number">6.</span> <span class="nav-text">利用结构体实现HIP的数组相加</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E5%AE%9E%E7%8E%B0%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95%EF%BC%88%E5%88%A9%E7%94%A8%E4%BA%86%E7%BB%93%E6%9E%84%E4%BD%93%EF%BC%89"><span class="nav-number">7.</span> <span class="nav-text">使用共享内存实现矩阵乘法（利用了结构体）</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Hao Yu</p>
  <div class="site-description" itemprop="description">Introduce something interesting and recode learning process, some articles are written by others, the original link has been given as much as possible, thanks to the original author</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">128</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/yuhao0102" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;yuhao0102" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:yuhhpc0203@gmail.com" title="E-Mail → mailto:yuhhpc0203@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hao Yu</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
