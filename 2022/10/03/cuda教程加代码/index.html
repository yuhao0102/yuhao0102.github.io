<!DOCTYPE html>
<html lang="zn-ch">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="GPU 硬件与 CUDA 程序开发工具 GPU 硬件在由 CPU 和 GPU 构成的异构计算平台中，通常将起控制作用的 CPU 称为 主机（host），将起加速作用的 GPU 称为 设备（device）。  主机和设备都有自己的 DRAM，之间一般由 PCIe 总线连接。 GPU 计算能力不等价于计算性能；表征计算性能的一个重要参数是 浮点数运算峰值（FLOPS）。浮点数运算峰值有单精度和双精度之">
<meta property="og:type" content="article">
<meta property="og:title" content="CUDA教程">
<meta property="og:url" content="http://yoursite.com/2022/10/03/cuda%E6%95%99%E7%A8%8B%E5%8A%A0%E4%BB%A3%E7%A0%81/index.html">
<meta property="og:site_name" content="Hao Yu&#39;s blog">
<meta property="og:description" content="GPU 硬件与 CUDA 程序开发工具 GPU 硬件在由 CPU 和 GPU 构成的异构计算平台中，通常将起控制作用的 CPU 称为 主机（host），将起加速作用的 GPU 称为 设备（device）。  主机和设备都有自己的 DRAM，之间一般由 PCIe 总线连接。 GPU 计算能力不等价于计算性能；表征计算性能的一个重要参数是 浮点数运算峰值（FLOPS）。浮点数运算峰值有单精度和双精度之">
<meta property="og:locale" content="zn_CH">
<meta property="article:published_time" content="2022-10-03T12:53:00.000Z">
<meta property="article:modified_time" content="2022-12-26T07:33:10.000Z">
<meta property="article:author" content="Hao Yu">
<meta property="article:tag" content="积累">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/2022/10/03/cuda%E6%95%99%E7%A8%8B%E5%8A%A0%E4%BB%A3%E7%A0%81/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zn-ch'
  };
</script>

  <title>CUDA教程 | Hao Yu's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Hao Yu's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">The program monkey was eaten by the siege lion.</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>Schedule</a>

  </li>
        <li class="menu-item menu-item-sitemap">

    <a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zn-ch">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2022/10/03/cuda%E6%95%99%E7%A8%8B%E5%8A%A0%E4%BB%A3%E7%A0%81/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Hao Yu">
      <meta itemprop="description" content="Introduce something interesting and recode learning process, some articles are written by others, the original link has been given as much as possible, thanks to the original author">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hao Yu's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          CUDA教程
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-10-03 20:53:00" itemprop="dateCreated datePublished" datetime="2022-10-03T20:53:00+08:00">2022-10-03</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2022-12-26 15:33:10" itemprop="dateModified" datetime="2022-12-26T15:33:10+08:00">2022-12-26</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="GPU-硬件与-CUDA-程序开发工具"><a href="#GPU-硬件与-CUDA-程序开发工具" class="headerlink" title="GPU 硬件与 CUDA 程序开发工具"></a>GPU 硬件与 CUDA 程序开发工具</h1><hr>
<h2 id="GPU-硬件"><a href="#GPU-硬件" class="headerlink" title="GPU 硬件"></a>GPU 硬件</h2><p>在由 CPU 和 GPU 构成的异构计算平台中，通常将起控制作用的 CPU 称为 <strong>主机（host）</strong>，<br>将起加速作用的 GPU 称为 <strong>设备（device）</strong>。 </p>
<p>主机和设备都有自己的 DRAM，之间一般由 PCIe 总线连接。</p>
<p>GPU 计算能力不等价于计算性能；表征计算性能的一个重要参数是 <strong>浮点数运算峰值（FLOPS）</strong>。<br>浮点数运算峰值有单精度和双精度之分。对于 Tesla 系列的 GPU，双精度下 FLOPS 一般是单精度下的 1/2;<br>对于 GeForce 系列的 GPU，双精度下 FLOPS 一般是单精度下的 1/32。</p>
<p>影响计算性能的另一个参数是 <strong>GPU 内存带宽（显存）</strong>。</p>
<hr>
<h2 id="CUDA-程序开发工具"><a href="#CUDA-程序开发工具" class="headerlink" title="CUDA 程序开发工具"></a>CUDA 程序开发工具</h2><ol>
<li>CUDA；</li>
<li>OpenCL，更为通用的各种异构平台编写并行程序的框架，AMD 的 GPU 程序开发工具；</li>
<li>OpenACC，由多公司共同开发的异构并行编程标准。</li>
</ol>
<p>CUDA 提供两层 API，即 CUDA 驱动API 和 CUDA 运行时API。<br>CUDA 开发环境中，程序应用程序是以主机（CPU）为出发点的；应用程序可以调用 CUDA 运行时 API、<br>CUDA 驱动 API 和一些已有的 CUDA 库。</p>
<hr>
<h2 id="CUDA-开发环境搭建"><a href="#CUDA-开发环境搭建" class="headerlink" title="CUDA 开发环境搭建"></a>CUDA 开发环境搭建</h2><p>linux 操作系统：<a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html">linux下cuda环境搭建</a></p>
<p>windows10 操作系统：<a href="https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html">windows10下cuda环境搭建</a></p>
<hr>
<h2 id="nvidia-smi-检查与设置设备"><a href="#nvidia-smi-检查与设置设备" class="headerlink" title="nvidia-smi 检查与设置设备"></a>nvidia-smi 检查与设置设备</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br><span class="line">    +-----------------------------------------------------------------------------+</span><br><span class="line">    | NVIDIA-SMI 462.30       Driver Version: 462.30       CUDA Version: 11.2     |</span><br><span class="line">    |-------------------------------+----------------------+----------------------+</span><br><span class="line">    | GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">    | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">    |                               |                      |               MIG M. |</span><br><span class="line">    |===============================+======================+======================|</span><br><span class="line">    |   0  GeForce MX450      WDDM  | 00000000:2B:00.0 Off |                  N/A |</span><br><span class="line">    | N/A   39C    P8    N/A /  N/A |    119MiB /  2048MiB |      0%      Default |</span><br><span class="line">    |                               |                      |                  N/A |</span><br><span class="line">    +-------------------------------+----------------------+----------------------+</span><br><span class="line">    </span><br><span class="line">    +-----------------------------------------------------------------------------+</span><br><span class="line">    | Processes:                                                                  |</span><br><span class="line">    |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span><br><span class="line">    |        ID   ID                                                   Usage      |</span><br><span class="line">    |=============================================================================|</span><br><span class="line">    |  No running processes found                                                 |</span><br><span class="line">    +-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure>
<ol>
<li><strong>CUDA Version</strong>， 11.2；</li>
<li><strong>GPU Name</strong>，GeForce MX450，设备号为 0；如果系统中有多个 GPU 且只要使用其中某个特定的 GPU，<br> 可以通过设置环境变量 <strong>CUDA_VISIBLE_DEVICES</strong> 的值，从而可以在运行 CUDA 程序前选定 GPU;  </li>
<li><strong>TCC/WDDM</strong>，WDDM（windows display driver model），其它包括 TCC（Tesla compute cluster）；<br> 可以通过命令行 <code>nvidia-smi -g GPU_ID -dm 0</code>，设置为 WDDM 模式（1 为 TCC 模式）；</li>
<li><strong>Compute mode</strong>, Default，此时同一个 GPU 中允许存在多个进程；其他模式包括 E.Process，<br> 指的是独占进程模式，但不适用 WDDM 模式下的 GPU；<br> 可以通过命令行 <code>nvidia-smi -i GPU_ID -c 0</code>，设置为 Default 模式（1 为 E.Process 模式）;</li>
<li><strong>Perf</strong>，p8（GPU 性能状态，最大p0~最小p12）；</li>
</ol>
<p>更多关于 nvidia-smi 的资料：<a href="https://developer.nvidia.com/nvidia-system-management-interface">nvidia-smi</a></p>
<hr>
<h1 id="CUDA-中的线程组织"><a href="#CUDA-中的线程组织" class="headerlink" title="CUDA 中的线程组织"></a>CUDA 中的线程组织</h1><p>CUDA 虽然支持 C++ 但支持得并不充分，导致 C++ 代码中有很多 C 代码的风格。</p>
<p>CUDA 采用 nvcc 作为编译器，支持 C++ 代码；nvcc 在编译 CUDA 程序时，<br>会将纯粹的 c++ 代码交给 c++ 编译器，自己负责编译剩下的 cu 代码。</p>
<hr>
<h2 id="C-的-Hello-World-程序"><a href="#C-的-Hello-World-程序" class="headerlink" title="C++ 的 Hello World 程序"></a>C++ 的 Hello World 程序</h2><h2 id=""><a href="#" class="headerlink" title=""></a><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; g++ hello.cpp -o ./bin/hello.exe</span><br><span class="line">&gt;&gt; ./bin/hello</span><br><span class="line">msvc: hello world!</span><br></pre></td></tr></table></figure></h2><h2 id="CUDA-的-Hello-World-程序"><a href="#CUDA-的-Hello-World-程序" class="headerlink" title="CUDA 的 Hello World 程序"></a>CUDA 的 Hello World 程序</h2><h3 id="使用-nvcc-编译纯粹-c-代码"><a href="#使用-nvcc-编译纯粹-c-代码" class="headerlink" title="使用 nvcc 编译纯粹 c++ 代码"></a>使用 nvcc 编译纯粹 c++ 代码</h3><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt; nvcc -o ./bin/hello_cu.exe hello.cu </span><br><span class="line">&gt;&gt; ./bin/hello_cu.exe</span><br><span class="line">nvcc: hello world!</span><br></pre></td></tr></table></figure>
<p>在该程序中其实并未使用 GPU。</p>
<h3 id="使用-核函数-的-CUDA-程序"><a href="#使用-核函数-的-CUDA-程序" class="headerlink" title="使用 核函数 的 CUDA 程序"></a>使用 核函数 的 CUDA 程序</h3><p>一个利用了 GPU 的 CUDA 程序既有主机代码，又有设备代码（在设备中执行的代码）。<br>主机对设备的调用是通过 <strong>核函数（kernel function）</strong> 实现的。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    主机代码</span><br><span class="line">    核函数的调用</span><br><span class="line">    主机代码</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>；</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>核函数与 c++ 函数的区别：</p>
<ol>
<li>必须加 <code>__global__</code> 限定；</li>
<li>返回类型必须是空类型 <code>void</code>。</li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">hell_from__gpu</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 核函数不支持 c++ 的 iostream。</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;gpu: hello world!\n&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>调用核函数的方式：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hello_from_gpu&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1</span>&gt;&gt;&gt;</span><br></pre></td></tr></table></figure><br>主机在调用一个核函数时，必须指明在设备中指派多少线程。核函数中的线程常组织为若干线程块： </p>
<ol>
<li>三括号中第一个数字是线程块的个数（number of thread block）；</li>
<li>三括号中第二个数字是每个线程块中的线程数（number of thread in per block）。</li>
</ol>
<p>一个核函数的全部线程块构成一个网格（grid），线程块的个数称为网格大小（grid size）。  每个线程块中含有相同数目的线程，该数目称为线程块大小（block size）。</p>
<p>所以，核函数的总的线程数即<code>网格大小*线程块大小</code>:<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hello_from_gpu&lt;&lt;&lt;grid size, block size&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p>
<p>调用核函数后，调用 CUDA 运行时 API 函数，同步主机和设备：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cudaDeviceSynchronize</span>();</span><br></pre></td></tr></table></figure><br>核函数中调用输出函数，输出流是先存放在缓冲区的，而缓冲区不会自动刷新。</p>
<hr>
<h2 id="CUDA-的线程组织"><a href="#CUDA-的线程组织" class="headerlink" title="CUDA 的线程组织"></a>CUDA 的线程组织</h2><p>核函数的总线程数必须至少等于计算核心数时才有可能充分利用 GPU 的全部计算资源。  </p>
<pre><code>hello_from_gpu&lt;&lt;&lt;2, 4&gt;&gt;&gt;
</code></pre><p>网格大小是2，线程块大小是4，总线程数即8。核函数中代码的执行方式是 “单指令-多线程”，<br>即每个线程执行同一串代码。</p>
<p>从开普勒架构开始，最大允许的线程块大小是 2^10 (1024)，最大允许的网格大小是 2^31 - 1（一维网格）。</p>
<p>线程总数可以由两个参数确定：</p>
<ol>
<li>gridDim.x, 即网格大小；</li>
<li>blockDim.x, 即线程块大小；</li>
</ol>
<p>每个线程的身份可以由两个参数确定：</p>
<ol>
<li>blockIdx.x, 即一个线程在一个网格中的线程块索引，[0, gridDm.x);</li>
<li>threadIdx.x, 即一个线程在一个线程块中的线程索引，[0, blockDim.x);</li>
</ol>
<p>网格和线程块都可以拓展为三维结构（各轴默认为 1）：</p>
<ol>
<li>三维网格 grid_size(gridDim.x, gridDim.y, gridDim.z);</li>
<li>三维线程块 block_size(blockDim.x, blockDim.y, blockDim.z);</li>
</ol>
<p>相应的，每个线程的身份参数：</p>
<ol>
<li>线程块ID (blockIdx.x, blockIdx.y, blockIdx.z);</li>
<li>线程ID (threadIdx.x, threadIdx.y, threadIdx.z);</li>
</ol>
<p>多维网格线程在线程块上的 ID；</p>
<pre><code>tid = threadIdx.z * (blockDim.x * blockDim.y)  // 当前线程块上前面的所有线程数
    + threadIdx.y * (blockDim.x)               // 当前线程块上当前面上前面行的所有线程数
    + threadIdx.x                              // 当前线程块上当前面上当前行的线程数
</code></pre><p>多维网格线程块在网格上的 ID:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">bid = blockIdx.z * (gridDim.x * gridDim.y)</span><br><span class="line">    + blockIdx.y * (gridDim.x)</span><br><span class="line">    + blockIdx.x</span><br></pre></td></tr></table></figure>
<p>一个线程块中的线程还可以细分为不同的 <strong>线程束（thread warp）</strong>，即同一个线程块中<br>相邻的 warp_size 个线程（一般为 32）。</p>
<p>对于从开普勒架构到图灵架构的 GPU，网格大小在 x, y, z 方向的最大允许值为 （2^31 - 1, 2^16 - 1, 2^16 -1）；<br>线程块大小在 x, y, z 方向的最大允许值为 （1024， 1024， 64），同时要求一个线程块最多有 1024 个线程。</p>
<hr>
<h2 id="CUDA-的头文件"><a href="#CUDA-的头文件" class="headerlink" title="CUDA 的头文件"></a>CUDA 的头文件</h2><p>CUDA 头文件的后缀一般是 “.cuh”；同时，同时可以包含c/cpp 的头文件 “.h”、“.hpp”，采用 nvcc 编译器会自动包含必要的 cuda 头文件，如 <cuda.h>, <cuda_runtime.h>，同时前者也包含了c++头文件 <stdlib.h>。</p>
<hr>
<h2 id="使用-nvcc-编译-CUDA-程序"><a href="#使用-nvcc-编译-CUDA-程序" class="headerlink" title="使用 nvcc 编译 CUDA 程序"></a>使用 nvcc 编译 CUDA 程序</h2><p>nvcc 会先将全部源代码分离为 主机代码 和 设备代码；主机代码完整的支持 c++ 语法，而设备代码只部分支持。</p>
<p>nvcc 会先将设备代码编译为 PTX（parrallel thread execution）伪汇编代码，再将其编译为二进制 cubin目标代码。  在编译为 PTX 代码时，需要选项 <code>-arch=compute_XY</code> 指定一个虚拟架构的计算能力；在编译为 cubin 代码时， 需要选项 <code>-code=sm_ZW</code> 指定一个真实架构的计算能力，以确定可执行文件能够使用的 GPU。</p>
<p>真实架构的计算能力必须大于等于虚拟架构的计算能力，例如： </p>
<pre><code>-arch=compute_35  -code=sm_60  (right)
-arch=compute_60  -code=sm_35  (wrong)
</code></pre><p>如果希望编译出来的文件能在更多的GPU上运行，则可以同时指定多组计算能力，例如：</p>
<pre><code>-gencode arch=compute_35, code=sm_35
-gencode arch=compute_50, code=sm_50
-gencode arch=compute_60, code=sm_60
</code></pre><p>此时，编译出来的可执行文件将包含3个二进制版本，称为 <strong>胖二进制文件（fatbinary）</strong>。</p>
<p>同时，nvcc 有一种称为 <strong>实时编译（just-in-time compilation）</strong>机制，可以在运行可执行文件时从其中保留的PTX<br>代码中临时编译出一个 cubin 目标代码。因此， 需要通过选项 <code>-gencode arch=compute_XY, code=compute_XY</code>，<br>指定所保留 PTX 代码的虚拟架构， 例如：</p>
<pre><code>-gencode arch=compute_35, code=sm_35
-gencode arch=compute_50, code=sm_50
-gencode arch=compute_60, code=sm_60  
-gencode arch=compute_70, code=compute_70
</code></pre><p>于此同时，nvcc 编译有一个简化的编译选项 <code>-arch=sim_XY</code>，其等价于： </p>
<pre><code>-gencode arch=compute_XY, code=sm_XY  
-gencode arch=compute_XY, code=compute_XY
</code></pre><p>关于 nvcc 编译器的更多资料： <a href="https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html">nvcc</a>。</p>
<hr>
<h1 id="简单-CUDA-程序的基本框架"><a href="#简单-CUDA-程序的基本框架" class="headerlink" title="简单 CUDA 程序的基本框架"></a>简单 CUDA 程序的基本框架</h1><h2 id="单源文件-CUDA-程序基本框架"><a href="#单源文件-CUDA-程序基本框架" class="headerlink" title="单源文件 CUDA 程序基本框架"></a>单源文件 CUDA 程序基本框架</h2><p>对于单源文件的 cuda 程序，基本框架为：</p>
<pre><code>包含头文件

定义常量或宏

声明 c++ 自定义函数和 cuda 核函数的原型

int main()
&#123;
    1. 分配主机和设备内存
    2. 初始化主机中数据
    3. 将某些数据从主机复制到设备
    4. 调用核函数在设备中计算
    5. 将某些数据从设备复制到主机
    6. 释放主机和设备内存
&#125;

c++ 自定义函数和 cuda 核函数的定义
</code></pre><p>CUDA 核函数的要求：</p>
<ol>
<li>返回类型必须是 <code>void</code>，但是函数中可以使用 <code>return</code>（但不可以返回任何值）；</li>
<li>必须使用限定符 <code>__glolbal__</code>，也可以加上 c++ 限定符；</li>
<li>核函数支持 c++ 的重载机制；</li>
<li>核函数不支持可变数量的参数列表，即参数个数必须确定；</li>
<li>一般情况下，传给核函数的数组（指针）必须指向设备内存（“统一内存编程机制”除外）；</li>
<li>核函数不可成为一个类的成员（一般以包装函数调用核函数，将包装函数定义为类成员）；</li>
<li>在计算能力3.5之前，核函数之间不能相互调用；之后，通过“动态并行”机制可以调用；</li>
<li>无论从主机调用还是从设备调用，核函数都在设备中执行（“&lt;&lt;&lt;,&gt;&gt;&gt;”指定执行配置）。</li>
</ol>
<hr>
<h2 id="自定义设备函数"><a href="#自定义设备函数" class="headerlink" title="自定义设备函数"></a>自定义设备函数</h2><p>核函数可以调用不带执行配置的自定义函数，即 <strong>设备函数</strong>。</p>
<p>设备函数在设备中执行、在设备中被调用；而核函数在设备中执行、在主机中被调用。</p>
<ol>
<li><code>__global__</code>修饰的函数称为核函数，一般由主机调用、在设备中执行；</li>
<li><code>__device__</code>修饰的函数称为设备函数，只能被核函数或其他设备函数调用、在设备中执行；</li>
<li><code>__host__</code>修饰主机段的普通 c++ 函数，在主机中被调用、在主机中执行，一般可以省略；</li>
<li>可以同时用 <code>__host__</code> 和 <code>__device__</code> 修饰函数，从而减少代码冗余，此时编译器将<br> 分别在主机和设备上编译该函数；</li>
<li>不能同时用 <code>__global__</code> 和 <code>__device__</code> 修饰函数；</li>
<li>不能同时用 <code>__global__</code> 和 <code>__host__</code> 修饰函数；</li>
<li>可以通过 <code>__noinline__</code> 建议编译器不要将一个设备函数当作内联函数；</li>
<li>可以通过 <code>__forceinline__</code> 建议编译器将一个设备函数当作内联函数。</li>
</ol>
<p>设备函数可以有返回值。</p>
<h1 id="CUDA-程序的错误检测"><a href="#CUDA-程序的错误检测" class="headerlink" title="CUDA 程序的错误检测"></a>CUDA 程序的错误检测</h1><hr>
<h2 id="检测-CUDA-运行时错误的宏函数"><a href="#检测-CUDA-运行时错误的宏函数" class="headerlink" title="检测 CUDA 运行时错误的宏函数"></a>检测 CUDA 运行时错误的宏函数</h2><p>定义检查 cuda 运行时 API 返回值 <code>cudaError_t</code> 的宏函数。</p>
<pre><code>#define CHECK(call)                                                     \
do &#123;                                                                    \
    const cudaError_t error_code = call;                                \
    if (error_code != cudaSuccess)                                      \
    &#123;                                                                   \
        printf(&quot;CUDA ERROR: \n&quot;);                                       \
        printf(&quot;    FILE: %s\n&quot;, __FILE__);                             \
        printf(&quot;    LINE: %d\n&quot;, __LINE__);                             \
        printf(&quot;    ERROR CODE: %d\n&quot;, error_code);                     \
        printf(&quot;    ERROR TEXT: %s\n&quot;, cudaGetErrorString(error_code)); \
        exit(1);                                                        \
    &#125;                                                                   \
&#125;while(0); 
</code></pre><p>因为核函数没有返回值，所以无法直接检查核函数错误。间接的方法是，在调用核函数后执行：</p>
<pre><code>CHECK(cudaGetLastError());  // 捕捉同步前的最后一个错误。
CHECK(cudaDeviceSynchronize());  // 同步主机和设备。
</code></pre><p>核函数的调用是 <strong>异步的</strong>，即主机调用核函数后不会等待核函数执行完成、而是立刻执行之后的语句。 同步操作较为耗时，一般尽量避免；同时，只要在核函数调用后还有对其他任何能返回错误值的 API   函数进行同步调用，都会触发主机和设备的同步并捕捉到核函数中可能发生的错误。</p>
<p>此外，主机和设备之间的数据拷贝会隐式地同步主机和设备。一般要获得精确的出错位置，还是需要显式地  同步，例如调用 <code>cudaDeviceSynchronize()</code>。</p>
<p>或者，通过设置环境变量 <code>CUDA_LAUNCH_BLOCKING</code> 为 1，这样所有核函数的调用都将不再是异步的，  而是同步的。就是说，主机调用一个核函数之后必须等待其执行完，才能向下执行。  一般仅用于程序调试。</p>
<hr>
<h2 id="CUDA-MEMCHECK-检查内存错误"><a href="#CUDA-MEMCHECK-检查内存错误" class="headerlink" title="CUDA-MEMCHECK 检查内存错误"></a>CUDA-MEMCHECK 检查内存错误</h2><p>CUDA 提供了 CUDA-MEMCHECK 的工具集，包括 memcheck, racecheck, initcheck, synccheck.</p>
<pre><code>&gt;&gt; cuda-memcheck --tool memcheck [options] app-name [options]
</code></pre><p>对于 memcheck 工具，可以简化为：</p>
<pre><code>&gt;&gt; cuda-memcheck [options] app-name [options]
</code></pre><p>对于本例，可以通过如下方式检测错误：<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">    &gt;&gt; cuda-memcheck ./bin/check.exe</span><br><span class="line">    ========= CUDA-MEMCHECK</span><br><span class="line"></span><br><span class="line">CUDA ERROR: </span><br><span class="line">    FILE: check.cu</span><br><span class="line">    LINE: 56</span><br><span class="line">    ERROR CODE: 9</span><br><span class="line">    ERROR TEXT: invalid configuration argument</span><br><span class="line">    ========= Program hit cudaErrorInvalidConfiguration (error 9) due to <span class="string">&quot;invalid configuration argument&quot;</span> on CUDA API call to     cudaLaunchKernel.</span><br><span class="line">    =========     Saved host backtrace up to driver entry point at error</span><br><span class="line">    =========     Host Frame:C:\Windows\system32\DriverStore\FileRepository\nvhq.inf_amd64_5550755be1247d27\nvcuda64.dll     (cuProfilerStop + 0x97c18) [0x2b8ca8]</span><br><span class="line">    =========     Host Frame:C:\Windows\system32\DriverStore\FileRepository\nvhq.inf_amd64_5550755be1247d27\nvcuda64.dll     (cuProfilerStop + 0x9a2da) [0x2bb36a]</span><br><span class="line">    =========     Host Frame:C:\Windows\system32\DriverStore\FileRepository\nvhq.inf_amd64_5550755be1247d27\nvcuda64.dll     [0x7b52e]</span><br><span class="line">    =========     Host Frame:C:\Windows\system32\DriverStore\FileRepository\nvhq.inf_amd64_5550755be1247d27\nvcuda64.dll     (cuProfilerStop + 0x11ceaa) [0x33df3a]</span><br><span class="line">    =========     Host Frame:C:\Windows\system32\DriverStore\FileRepository\nvhq.inf_amd64_5550755be1247d27\nvcuda64.dll     (cuProfilerStop + 0x137532) [0x3585c2]</span><br><span class="line">    =========     Host Frame:D:\3_codes\CudaSteps\capter4\bin\check.exe [0x1679]</span><br><span class="line">    =========     Host Frame:D:\3_codes\CudaSteps\capter4\bin\check.exe [0xd32b]</span><br><span class="line">    =========     Host Frame:D:\3_codes\CudaSteps\capter4\bin\check.exe [0xd1a8]</span><br><span class="line">    =========     Host Frame:D:\3_codes\CudaSteps\capter4\bin\check.exe [0xc6a1]</span><br><span class="line">    =========     Host Frame:D:\3_codes\CudaSteps\capter4\bin\check.exe [0xcbf8]</span><br><span class="line">    =========     Host Frame:D:\3_codes\CudaSteps\capter4\bin\check.exe [0xd944]</span><br><span class="line">    =========     Host Frame:C:\Windows\System32\KERNEL32.DLL (BaseThreadInitThunk + 0x14) [0x17034]</span><br><span class="line">    =========     Host Frame:C:\Windows\SYSTEM32\ntdll.dll (RtlUserThreadStart + 0x21) [0x52651]</span><br><span class="line">    =========</span><br><span class="line">    ========= Program hit cudaErrorInvalidConfiguration (error 9) due to <span class="string">&quot;invalid configuration argument&quot;</span> on CUDA API call to     cudaGetLastError.</span><br><span class="line">    =========     Saved host backtrace up to driver entry point at error</span><br><span class="line">    =========     Host Frame:C:\Windows\system32\DriverStore\FileRepository\nvhq.inf_amd64_5550755be1247d27\nvcuda64.dll     (cuProfilerStop + 0x97c18) [0x2b8ca8]</span><br><span class="line">    =========     Host Frame:C:\Windows\system32\DriverStore\FileRepository\nvhq.inf_amd64_5550755be1247d27\nvcuda64.dll     (cuProfilerStop + 0x9a2da) [0x2bb36a]</span><br><span class="line">    =========     Host Frame:C:\Windows\system32\DriverStore\FileRepository\nvhq.inf_amd64_5550755be1247d27\nvcuda64.dll     [0x7b52e]</span><br><span class="line">    =========     Host Frame:C:\Windows\system32\DriverStore\FileRepository\nvhq.inf_amd64_5550755be1247d27\nvcuda64.dll     (cuProfilerStop + 0x11ceaa) [0x33df3a]</span><br><span class="line">    =========     Host Frame:C:\Windows\system32\DriverStore\FileRepository\nvhq.inf_amd64_5550755be1247d27\nvcuda64.dll     (cuProfilerStop + 0x137532) [0x3585c2]</span><br><span class="line">    =========     Host Frame:D:\3_codes\CudaSteps\capter4\bin\check.exe [0x1461]</span><br><span class="line">    =========     Host Frame:D:\3_codes\CudaSteps\capter4\bin\check.exe [0xcbfd]</span><br><span class="line">    =========     Host Frame:D:\3_codes\CudaSteps\capter4\bin\check.exe [0xd944]</span><br><span class="line">    =========     Host Frame:C:\Windows\System32\KERNEL32.DLL (BaseThreadInitThunk + 0x14) [0x17034]</span><br><span class="line">    =========     Host Frame:C:\Windows\SYSTEM32\ntdll.dll (RtlUserThreadStart + 0x21) [0x52651]</span><br><span class="line">    =========</span><br><span class="line">    ========= ERROR SUMMARY: 2 errors</span><br></pre></td></tr></table></figure><br>关于 CUDA-MEMCHECK 的更多内容，详见: <a href="https://docs.nvidia.com/cuda/cuda-memcheck/index.html">CUDA-MEMCHECK</a>。</p>
<hr>
<h1 id="获得-GPU-加速的关键"><a href="#获得-GPU-加速的关键" class="headerlink" title="获得 GPU 加速的关键"></a>获得 GPU 加速的关键</h1><hr>
<h2 id="CUDA-事件计时"><a href="#CUDA-事件计时" class="headerlink" title="CUDA 事件计时"></a>CUDA 事件计时</h2><p>C++ 的计时方法：</p>
<ol>
<li>GCC 和 MSVC 都有的 <code>clock()</code>函数；</li>
<li>原生的 <chrono> 时间库；</li>
<li>GCC 的 <code>gettimeofday()</code>计时；</li>
<li>MSVC 的 <code>QueryPerformanceCounter()</code> 和 <code>QueryPerformanceFrequency()</code> 计时。</li>
</ol>
<p>CUDA 基于 CUDA 事件的计时方法：</p>
<pre><code>cudaEvent_t start, stop;
CHECK(cudaEventCreate(&amp;start)); // 创建cuda 事件对象。
CHECK(cudaEventCreate(&amp;stop));
CHECK(cudaEventRecord(start));  // 记录代表开始的事件。
cudaEventQuery(start);  // 强制刷新 cuda 执行流。

// run code.

CHECK(cudaEventRecord(stop));
CHECK(cudaEventSynchronize(stop)); // 强制同步，让主机等待cuda事件执行完毕。
float elapsed_time = 0;
CHECK(cudaEventElapsedTime(&amp;curr_time, start, stop)); // 计算 start 和stop间的时间差（ms）。
printf(&quot;host memory malloc and copy: %f ms.\n&quot;, curr_time - elapsed_time);  
</code></pre><p>由于 cuda 程序需要在主机和设备间传递数据，所以当计算强度较小时数据传输的性能对程序总耗时影响更大。<br>因此 cuda 的两种浮点数类型对程序性能的影响就较为明显。考虑提供编译选项，指定版本：</p>
<pre><code>#ifdef USE_DP
    typedef double real;  // 双精度
    const real EPSILON = 1.0e-15;
#else
    typedef float real;   // 单精度
    const real EPSILON = 1.0e-6f;
#endif
</code></pre><p>在编译时，除了指定 GPU 计算能力 <code>-arch=sm_50</code>，还可以指定 c++ 优化等级 <code>-O3</code>;同时，可以指定其他<br>编译选项，如 <code>-DUSE_DP</code> 启用双精度版本。</p>
<pre><code>&gt;&gt; nvcc -O3 -arch=sm_50 -DUSE_DP -o ./bin/clock.exe add.cu clock.cu main.cpp
...
&gt;&gt; ./bin/clock
using double precision version
host memory malloc and copy: 2.054112 ms.
device memory malloc: 9.063583 ms.
kernel function : 0.803360 ms.
cuda; no error
copy from device to host: 7.489505 ms.  

&gt;&gt; nvcc -O3 -arch=sm_50 -o ./bin/clock.exe add.cu clock.cu main.cpp
...
&gt;&gt; ./bin/clock     
host memory malloc and copy: 0.950240 ms.
device memory malloc: 5.298208 ms.
kernel function : 0.620512 ms.
cuda; no errors
copy from device to host: 3.034208 ms.
</code></pre><p>可见双精度版本基本上比单精度版本耗时多一倍。</p>
<hr>
<h2 id="nvprof-查看程序性能"><a href="#nvprof-查看程序性能" class="headerlink" title="nvprof 查看程序性能"></a>nvprof 查看程序性能</h2><pre><code>&gt;&gt; nvprof ./bin/clock
</code></pre><p>如果没有输出结果，需要将<code>nvprof</code>的目录包含到环境环境变量中（不支持7.5 以上计算能力的显卡）。<br>推荐采用一代性能分析工具： <a href="https://developer.nvidia.com/zh-cn/nsight-systems">Nvidia Nsight Systems</a>.</p>
<hr>
<h2 id="影响-GPU-加速的关键因素"><a href="#影响-GPU-加速的关键因素" class="headerlink" title="影响 GPU 加速的关键因素"></a>影响 GPU 加速的关键因素</h2><ol>
<li>要获得可观的 GPU 加速，就必须尽量缩减主机和设备间数据传输所花时间的占比。</li>
</ol>
<p>有些计算即使在 GPU 中速度不高也要尽量放在 GPU 中实现，以避免过多数据经由 PCIe 传递。</p>
<ol>
<li>提高算术强度可以显著地提高 GPU 相对于 CPU 的加速比。</li>
</ol>
<p><strong>算术强度</strong>，是指一个计算问题中算术操作的工作量与必要的内存操作的工作量之比。  对设备内存的访问速度取决于 GPU 的显存带宽。</p>
<ol>
<li>核函数的并行规模。</li>
</ol>
<p>并行规模可以用 GPU 中的线程数目来衡量。  一个 GPU 由多个流多处理器SM（streaming multiprocessor）构成，每个 SM 中有若干 CUDA 核心。  每个 SM 是相对独立的，一个 SM 中最多驻留的线程数一般为 2048 或 1024（图灵架构）。</p>
<p>若要 GPU 满负荷工作，则核函数中定义的线程总数要不少于某值，一般与 GPU 能够驻留的线程总数相当。</p>
<hr>
<h2 id="CUDA-的数学函数库"><a href="#CUDA-的数学函数库" class="headerlink" title="CUDA 的数学函数库"></a>CUDA 的数学函数库</h2><p>CUDA 提供的数学函数库提供了多种 <strong>数学函数</strong>，同时 CUDA 提供了一些高效率、低准确度的 <strong>内建函数</strong>。</p>
<p>CUDA 数学函数库的更多资料，详见：<a href="https://docs.nvidia.com/cuda/cuda-math-api/index.html">CUDA math</a>.</p>
<hr>
<h1 id="CUDA-的内存组织"><a href="#CUDA-的内存组织" class="headerlink" title="CUDA 的内存组织"></a>CUDA 的内存组织</h1><h2 id="CUDA-中不同类型的内存"><a href="#CUDA-中不同类型的内存" class="headerlink" title="CUDA 中不同类型的内存"></a>CUDA 中不同类型的内存</h2><p>CUDA 中的内存类型有：全局内存、常量内存、纹理内存、寄存器、局部内存、共享内存。<br>CUDA 的内存，即设备内存，主机无法直接访问。</p>
<hr>
<h3 id="全局内存"><a href="#全局内存" class="headerlink" title="全局内存"></a>全局内存</h3><p><strong>全局内存（global memory）</strong>，即核函数中所有线程都可以访问的内存，可读可写，由主机端分配和释放； 如 cudaMalloc() 的设备内存 d_x, d_y, d_z。</p>
<p>全局内存由于没有放到 GPU 芯片上，所以具有较高的延迟和较低的访问速度，但是容量大（显存）。 全局内存主要为核函数提供数据，并在主机和设备、设备和设备之间传递数据。</p>
<p>全局内存的生命周期由主机端维护，期间不同的核函数可以多次访问全局内存。</p>
<p>除以上动态分配的全局内存变量外，还可以使用 <strong>静态全局内存变量</strong>，其所占内存数量在编译器确定；  这样的静态全局内存变量必须在 所有主机和设备函数外部定义，例如：  </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">__device__ real epsilon;  // 单个静态全局内存变量， `__device` 表示是设备中的变量。</span><br><span class="line">__device__ real arr[10];  // 固定长度的静态全局内存数组变量。</span><br></pre></td></tr></table></figure>
<p>对于静态全局内存变量，其访问权限：  </p>
<ol>
<li>核函数中可以直接访问静态全局内存变量，不必以参数形式传给核函数；</li>
<li>主机中不可以直接访问静态全局内存变量，可以通过 <code>cudaMemcpyToSymbol()</code> 和 <code>cudaMemcpyFromSymbol()</code> 调用。  </li>
</ol>
<hr>
<h3 id="常量内存"><a href="#常量内存" class="headerlink" title="常量内存"></a>常量内存</h3><p><strong>常量内存（constant memory）</strong>，仅有 64 kb，可见范围和生命周期与全局内存一样；具有缓存，从而高速；<br>常量内存仅可读、不可写。  </p>
<p>使用常量内存的方法：一是在核函数外定义常量内存变量；二是向核函数传递常量参数，默认存放在常量内存：  </p>
<ol>
<li>核函数中可以直接访问常量全局内存变量，不必以参数形式传给核函数，但不可更改（只读）；</li>
<li>主机中不可以直接访问常量全局内存变量，可以通过 <code>cudaMemcpyToSymbol()</code> 和 <code>cudaMemcpyFromSymbol()</code> 调用。</li>
</ol>
<hr>
<h3 id="纹理内存"><a href="#纹理内存" class="headerlink" title="纹理内存"></a>纹理内存</h3><p><strong>纹理内存(texture memory)</strong>，类似常量内存，也是一种具有缓存的全局内存，具有相同可见范围和生命周期。</p>
<p>可以将某些只读的全局内存数据用 <code>__ldg()</code> 函数通过只读数据缓存（read-only data cache）读取， 既可以达到使用纹理内存的加速效果，又可使代码简洁：  </p>
<pre><code>int __ldg(const int* ptr);  // 函数原型。
</code></pre><p>全局内存的读取在默认情况下就利用了 <code>__ldg()</code> 函数，所以不需要显式地使用。</p>
<hr>
<h3 id="寄存器"><a href="#寄存器" class="headerlink" title="寄存器"></a>寄存器</h3><p>在核函数中定义的、不加任何限定符的变量一般存放在寄存器（register）；核函数中不加任何限定符的数组可能放在<br>寄存器，也可能放在局部内存中。寄存器可读可写。</p>
<p>各种内建变量，如 gridDim、blockDim 等都保存在特殊的寄存器中。</p>
<p>寄存器变量仅被一个线程看见，寄存器的生命周期也和所属线程相同。</p>
<p>寄存器内存在芯片上，是所有内存中访问速度最高的。一个寄存器占 32b（4字节），一个双精度浮点数占 2个寄存器。</p>
<hr>
<h3 id="局部内存"><a href="#局部内存" class="headerlink" title="局部内存"></a>局部内存</h3><p>局部内存(local memory)也是全局内存的一部分，每个线程最多可以使用 512 kb 的局部内存，但过多使用会降低性能。<br>局部内存的用法类似寄存器。</p>
<hr>
<h3 id="共享内存"><a href="#共享内存" class="headerlink" title="共享内存"></a>共享内存</h3><p>共享内存（shared memory）与寄存器类似，都是位于芯片上，读写速度较快。</p>
<p>共享内存对整个线程块可见，一个线程块上的所有线程都可以访问共享内存上的数据；共享内存的生命周期也与所属线程块一致。</p>
<p>共享内存的主要作用是减少对全局内存的访问，或者改善对全局内存的访问模式。</p>
<hr>
<h3 id="L1-和-L2-缓存"><a href="#L1-和-L2-缓存" class="headerlink" title="L1 和 L2 缓存"></a>L1 和 L2 缓存</h3><p>SM 层次的 L1 缓存（一级缓存）和设备层次 L2 缓存（二级缓存）。它们主要用来缓存全局内存和设备内存的访问。</p>
<hr>
<h2 id="SM-及其占有率"><a href="#SM-及其占有率" class="headerlink" title="SM 及其占有率"></a>SM 及其占有率</h2><p>一个 GPU 由多个 SM（流多处理器）构成，一个 SM 包含如下资源：</p>
<ol>
<li>一定数量的寄存器；</li>
<li>一定数量的共享内存；</li>
<li>常量内存的缓存；</li>
<li>纹理内存的缓存；</li>
<li>L1 缓存；</li>
<li>两个或四个线程束调度器，用于在不同线程上下文间迅速切换，及为准备就绪的线程束发出执行指令；</li>
<li>执行核心。</li>
</ol>
<p>一般来说，要尽量让 SM 的占有率不小于某值（如 25%），才有可能获得较高的性能。</p>
<ul>
<li>一个 SM 中最多拥有的线程块个数 Nb=16（开普勒和图灵架构）或 Nb=32（麦克斯韦、帕斯卡和伏特架构）；</li>
<li>一个 SM 中最多拥有的线程格式为 Nt=1028（图灵架构）或 Nt=2048（开普勒到伏特架构）。</li>
</ul>
<p>在线程块中，每 32 个连续线程为一个 <strong>线程束</strong>。<br>SM 中线程的执行是以线程束为单位的，所以最好将线程块大小取为线程束大小（32个线程）的整数倍（如 128）.</p>
<hr>
<h2 id="CUDA-运行时-API-函数查询设备"><a href="#CUDA-运行时-API-函数查询设备" class="headerlink" title="CUDA 运行时 API 函数查询设备"></a>CUDA 运行时 API 函数查询设备</h2><p>使用 CUDA 运行时 API 函数查询所用GPU 规格。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">#include &quot;common/error.cuh&quot;</span><br><span class="line">#include &lt;stdlib.h&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">int main(int argc, char *argv[])</span><br><span class="line">&#123;</span><br><span class="line">    int device_id = 0;</span><br><span class="line">    if (argc &gt; 1) device_id = atoi(argv[1]);</span><br><span class="line"></span><br><span class="line">    CHECK(cudaSetDevice(device_id));</span><br><span class="line"></span><br><span class="line">    cudaDeviceProp prop;</span><br><span class="line">    CHECK(cudaGetDeviceProperties(&amp;prop, device_id));</span><br><span class="line"></span><br><span class="line">    printf(&quot;Device id: %d\n&quot;, device_id);</span><br><span class="line">    printf(&quot;Device name: %s\n&quot;, prop.name);</span><br><span class="line">    printf(&quot;Compute capability: %d.%d\n&quot;, prop.major, prop.minor);</span><br><span class="line">    printf(&quot;Amount of global memory: %g GB\n&quot;, prop.totalGlobalMem/(1024.0*1024*1024));</span><br><span class="line">    printf(&quot;Amount of constant memory: %g KB\n&quot;, prop.totalConstMem/1024.0);</span><br><span class="line">    printf(&quot;Maximum grid size: %d, %d, %d\n&quot;, prop.maxGridSize[0], prop.maxGridSize[1], prop.maxGridSize[2]);</span><br><span class="line">    printf(&quot;Maximum block size: %d, %d, %d\n&quot;, prop.maxThreadsDim[0],prop.maxThreadsDim[1],prop.maxThreadsDim[2]);</span><br><span class="line">    printf(&quot;Number of SMs: %d\n&quot;, prop.multiProcessorCount);</span><br><span class="line">    printf(&quot;Maximum amount of shared memory per block: %g KB\n&quot;, prop.sharedMemPerBlock/1024.0);</span><br><span class="line">    printf(&quot;Maximum amount of shared memory per SM: %g KB\n&quot;, prop.sharedMemPerMultiprocessor/1024.0);</span><br><span class="line">    printf(&quot;Maximum number of registers per block: %d K\n&quot;, prop.regsPerBlock/1024);</span><br><span class="line">    printf(&quot;Maximum number of registers per SM: %d K\n&quot;, prop.regsPerMultiprocessor/1024);</span><br><span class="line">    printf(&quot;Maximum number of threads per block: %d\n&quot;, prop.maxThreadsPerBlock);</span><br><span class="line">    printf(&quot;Maximum number of threads per SM: %d\n&quot;, prop.maxThreadsPerMultiProcessor);</span><br><span class="line"></span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<pre><code>Device id: 0
Device name: GeForce MX450
Compute capability: 7.5
Amount of global memory: 2 GB
Amount of constant memory: 64 KB
Maximum grid size: 2147483647, 65535, 65535
Maximum block size: 1024, 1024, 64
Number of SMs: 14
Maximum amount of shared memory per block: 48 KB
Maximum amount of shared memory per SM: 64 KB
Maximum number of registers per block: 64 K
Maximum number of registers per SM: 64 K
Maximum number of threads per block: 1024
Maximum number of threads per SM: 1024
</code></pre><hr>
<h1 id="全局内存的合理使用"><a href="#全局内存的合理使用" class="headerlink" title="全局内存的合理使用"></a>全局内存的合理使用</h1><p>在各种设备内存中，全局内存具有最低的访问速度，往往是一个 CUDA 程序的性能瓶颈。</p>
<hr>
<h2 id="全局内存的合并与非合并访问"><a href="#全局内存的合并与非合并访问" class="headerlink" title="全局内存的合并与非合并访问"></a>全局内存的合并与非合并访问</h2><p>对全局内存的访问将触发内存事务，即数据传输。  在启用了 L1 缓存的情况下，对全局内存的读取将首先尝试经过 L1 缓存；如果未命中，  则尝试经过 L2 缓存；如果再次未命中，则直接从 DRAM 读取。</p>
<p>一次 <strong>数据传输处理</strong> 的数据量在默认情况下是 32 字节。<br>一次数据传输中，从全局内存转移到 L2 缓存的一片内存的首地址一定是 32 的整数倍。  也就是说，一次数据传输只能从全局内存读取地址为 0-31 字节、32-63 字节等片段的数据。</p>
<p><strong>合并度</strong>，即线程束请求的字节数与由此导致的所有内存事务中所传输的字节数之比。<br>如果所有数据传输处理的数据都是线程束所需要的，则合并度为 100%，即 <strong>合并访问</strong>； 否则，即为 <strong>非合并访问</strong>。</p>
<p>以仅使用 L2 缓存的情况为例，一次数据传输指的就是将 32 字节数据从全局内存（DRAM）  通过 32 字节的 L2 缓存片段（cache sector）传输到 SM。  考虑一个线程束访问单精度浮点数类型的全局内存变量的场景，  一个单精度浮点数占有 4 个字节，故一次访问需要 32*4 个字节的数据。在理想情况下，  即合并度为 100% 时，将仅触发 128/32=4 次调用 L2 缓存的数据传输。  如果线程束请求的全局内存地址刚好为 0-127 字节或 128-255 字节，就能与 4 次数据  传输所处理的数据完全吻合，这种情况下就是合并访问。</p>
<p>64 位系统中基本数据类型的内存长度（字节）：</p>
<pre><code>int size:               4
short size:             2
float size:             4
double size:            8
char size:              1
bool size:              1
long size:              4
int pointer size:       8
float pointer size:     8
double pointer size:    8
char pointer size:      8
</code></pre><hr>
<h2 id="矩阵转置"><a href="#矩阵转置" class="headerlink" title="矩阵转置"></a>矩阵转置</h2><p>在核函数中，如果读取操作是非合并访问，则可以采用 <em>只读数据缓存技术</em>，通过加载函数  <code>__ldg()</code> 读取全局内存，从而对数据的读取进行缓存、缓解非合并访问的影响。</p>
<p>从帕斯卡架构开始，编译器会自动判断并调用 <code>__ldg()</code> 函数提升性能；对于开普勒架构、麦克斯韦架构，默认情况下不会使用 <code>__ldg()</code> 函数，需要手动配置。</p>
<p>对于核函数中全局内存的写入，则没有类似函数可用。所以若不能满足读取和写入都是合并的，  一般应该尽量做到合并写入。</p>
<p>核函数中可以直接使用在函数外部由 <code>#define</code> 或 <code>const</code> 定义的常量，包括整型和浮点型常量。 但是在windows平台下（MSVC编译器）核函数无法使用外部定义的 <code>const</code> 定义的浮点型常量。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;common/error.cuh&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> USE_DP</span></span><br><span class="line">    <span class="keyword">typedef</span> <span class="type">double</span> real;  </span><br><span class="line">    <span class="type">const</span> real EPSILON = <span class="number">1.0e-15</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">    <span class="keyword">typedef</span> <span class="type">float</span> real;   </span><br><span class="line">    <span class="type">const</span> real EPSILON = <span class="number">1.0e-6f</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// using namespace std;  // 不能使用std，会导致 `copy()` 不能使用（命名冲突）。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">__constant__ <span class="type">int</span> TILE_DIM = <span class="number">32</span>;  <span class="comment">// 设备内存中线程块中矩阵维度（线程块大小，最大1024）。</span></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">copy</span><span class="params">(<span class="type">const</span> real *src, real *dst, <span class="type">const</span> <span class="type">int</span> N)</span></span>;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">transpose1</span><span class="params">(<span class="type">const</span> real *src, real *dst, <span class="type">const</span> <span class="type">int</span> N)</span></span>;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">transpose2</span><span class="params">(<span class="type">const</span> real *src, real *dst, <span class="type">const</span> <span class="type">int</span> N)</span></span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> N = <span class="number">10000</span>; </span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> M = N * N * <span class="built_in">sizeof</span>(real);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> SIZE = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpyFromSymbol</span>(&amp;SIZE, TILE_DIM, <span class="built_in">sizeof</span>(<span class="type">int</span>)));   </span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> grid_size_x = (N + SIZE - <span class="number">1</span>)/SIZE; <span class="comment">// 获取网格大小。</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> grid_size_y = grid_size_x;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">const</span> dim3 <span class="title">block_size</span><span class="params">(SIZE, SIZE)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">const</span> dim3 <span class="title">grid_size</span><span class="params">(grid_size_x, grid_size_y)</span></span>;</span><br><span class="line"></span><br><span class="line">    real *h_matrix_org, *h_matrix_res;</span><br><span class="line">    h_matrix_org = <span class="keyword">new</span> real[N*N];</span><br><span class="line">    h_matrix_res = <span class="keyword">new</span> real[N*N];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; N; ++j)</span><br><span class="line">        &#123;</span><br><span class="line">            h_matrix_org[j] = i;</span><br><span class="line">        &#125;   </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> elapsed_time = <span class="number">0</span>;</span><br><span class="line">    <span class="type">float</span> curr_time = <span class="number">0</span>;</span><br><span class="line">    cudaEvent_t start, stop;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventCreate</span>(&amp;start));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventCreate</span>(&amp;stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventRecord</span>(start));</span><br><span class="line">    <span class="built_in">cudaEventQuery</span>(start);</span><br><span class="line"></span><br><span class="line">    real *d_matrix_org, *d_matrix_res;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>(&amp;d_matrix_org, M));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>(&amp;d_matrix_res, M));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(d_matrix_org, h_matrix_org, M, cudaMemcpyDefault));</span><br><span class="line"></span><br><span class="line">    copy&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(d_matrix_org, d_matrix_res, N);     </span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(h_matrix_res, d_matrix_res, M, cudaMemcpyDefault));</span><br><span class="line"></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventRecord</span>(stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventSynchronize</span>(stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventElapsedTime</span>(&amp;curr_time, start, stop));    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;matrix copy time cost: %f ms.\n&quot;</span>, curr_time - elapsed_time);</span><br><span class="line">    elapsed_time = curr_time;</span><br><span class="line"></span><br><span class="line">    transpose1&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(d_matrix_org, d_matrix_res, N);     </span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(h_matrix_res, d_matrix_res, M, cudaMemcpyDefault));</span><br><span class="line"></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventRecord</span>(stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventSynchronize</span>(stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventElapsedTime</span>(&amp;curr_time, start, stop));    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;matrix transpose1 time cost: %f ms.\n&quot;</span>, curr_time - elapsed_time);</span><br><span class="line">    elapsed_time = curr_time;</span><br><span class="line"></span><br><span class="line">    transpose2&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(d_matrix_org, d_matrix_res, N);     </span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(h_matrix_res, d_matrix_res, M, cudaMemcpyDefault));</span><br><span class="line"></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventRecord</span>(stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventSynchronize</span>(stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventElapsedTime</span>(&amp;curr_time, start, stop));    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;matrix transpose2 time cost: %f ms.\n&quot;</span>, curr_time - elapsed_time);</span><br><span class="line">    elapsed_time = curr_time;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">delete</span>[] h_matrix_res;</span><br><span class="line">    <span class="keyword">delete</span>[] h_matrix_org;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(d_matrix_org));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(d_matrix_res));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">copy</span><span class="params">(<span class="type">const</span> real *src, real *dst, <span class="type">const</span> <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// TILE_DIM = blockDim.x = blockDim.y</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> nx = blockIdx.x * TILE_DIM + threadIdx.x; <span class="comment">// 矩阵列索引。</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> ny = blockIdx.y * TILE_DIM + threadIdx.y; <span class="comment">// 矩阵行索引。</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> index = ny * N + nx;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (nx &gt;= N || ny &gt;= N)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    dst[index] = src[index];  <span class="comment">// 全局内存中数组也是线性存放的。</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">transpose1</span><span class="params">(<span class="type">const</span> real *src, real *dst, <span class="type">const</span> <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> nx = threadIdx.x + blockIdx.x * TILE_DIM;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> ny = threadIdx.y + blockIdx.y * TILE_DIM;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (nx &lt; N &amp;&amp; ny &lt; N)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 矩阵转置（合并读取、非合并写入）。</span></span><br><span class="line">        dst[nx*N + ny] = src[ny*N + nx];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">transpose2</span><span class="params">(<span class="type">const</span> real *src, real *dst, <span class="type">const</span> <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> nx = threadIdx.x + blockIdx.x * TILE_DIM;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> ny = threadIdx.y + blockIdx.y * TILE_DIM;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (nx &lt; N &amp;&amp; ny &lt; N)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 矩阵转置（非合并读取、合并写入）。</span></span><br><span class="line">        dst[ny*N + nx] = __ldg(&amp;src[nx*N + ny]);   <span class="comment">// 显示调用 `__ldg()` 函数缓存全局内存。 </span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="共享内存的合理使用"><a href="#共享内存的合理使用" class="headerlink" title="共享内存的合理使用"></a>共享内存的合理使用</h1><p>共享内存是一种可以被程序员直接操作的缓存，主要作用有两个：  </p>
<ol>
<li>减少核函数中对全局内存的访问次数，实现高效的线程块内部的通信；</li>
<li>提高全局内存访问的合并度。</li>
</ol>
<hr>
<h2 id="数组归约"><a href="#数组归约" class="headerlink" title="数组归约"></a>数组归约</h2><p>对于多线程程序，默认情况下不同线程的执行顺序是不固定的（线程间独立）。</p>
<p>采用 <strong>折半规约法</strong>，通过线程块对数据分片归约，最后再一并求和。</p>
<p>核函数中循环的每一轮都会被拆解、分配到线程块内的所有线程上执行，而不是一个线程连续执行一次完整循环。  核函数中代码是 “单指令多线程” ，代码真正的执行顺序与出现顺序可能不同。所以 线程 0、1、… 127之间实际上并行的。</p>
<p>保证一个线程块中所有线程在执行该语句后面的语句之前，都完全执行了前面的语句：通过 <code>__syncthreads()</code>   实现一个线程块中所有线程按照代码出现的顺序执行指令，但是不同线程块之间依然是独立、异步的。</p>
<p><strong>共享内存变量</strong>，可以在核函数中通过限定符 <code>__shared__</code> 定义一个共享内存变量，  这样就相当于在每一个线程块中有一个该变量的副本。虽然每个副本都是独立的，但核函数中对共享变量的操作  都将 <strong>同时</strong> 作用在所有副本上。</p>
<p>核函数中可以直接使用函数外部由 <code>#define</code> 或 <code>const</code> 定义的常量，但在 MSVC 中限制了核函数使用 <code>const</code> 定义的常量。</p>
<p>利用共享内存进行线程块之间的合作（通信）之前，都要进行同步，以确保共享内存变量中数据对于所有线程块内的  所有线程都是准备好的。 </p>
<p>共享内存的生命周期仅在核函数内，所以必须在核函数结束前将共享内存中需要的结果保存到全局内存。  通过共享内存可以避免修改全局内存变量，同时不再要求全局内存数组为 线程块大小的整数倍。  </p>
<p>线程块的共享内存根据申请方式分为：静态共享内存变量和动态共享内存变量。  前者在核函数中定义共享内存大小（通过编译期常量），后者在主机调用核函数时指定大小（可以提高可维护性）。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../common/error.cuh&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../common/floats.hpp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;chrono&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std::chrono;</span><br><span class="line"></span><br><span class="line">__constant__ <span class="type">int</span> BLOCK_DIM = <span class="number">128</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">real <span class="title">reduce_cpu</span><span class="params">(<span class="type">const</span> real *x, <span class="type">const</span> <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    real sum = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N ; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        sum += x[i];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> sum;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduce</span><span class="params">(real *x, real *y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 这里执行迭代折半归约计算时，实际上的线程执行过程：</span></span><br><span class="line">    <span class="comment">// 1. 线程 0-127，offset = N/2, 迭代第一次；</span></span><br><span class="line">    <span class="comment">// 2. 线程 0-127，offset = N/4, 迭代第二次；</span></span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="comment">// 即，核函数中循环的每一轮都会被拆解、分配到线程块内的所有线程上执行，而不是一个  </span></span><br><span class="line">    <span class="comment">// 线程连续执行一次完整循环。</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    real *curr_x = x + blockIdx.x * blockDim.x;  <span class="comment">// 当前线程块中处理的内存首地址。</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = blockDim.x &gt;&gt; <span class="number">1</span>; offset &gt; <span class="number">0</span>; offset &gt;&gt;=<span class="number">1</span>) <span class="comment">// 迭代折半归约。</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 由于条件筛选，实际导致每轮有效的线程数量减半，即 “线程束的分化”。</span></span><br><span class="line">        <span class="comment">// 要求数组大小为线程块大小的整数倍。</span></span><br><span class="line">        <span class="keyword">if</span> (tid &lt; offset) </span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// 核函数中代码是 “单指令多线程” ，代码真正的执行顺序与出现顺序可能不同。</span></span><br><span class="line">            <span class="comment">// 所以 线程 0、1、... 127之间实际上并行的。</span></span><br><span class="line">            curr_x[tid] += curr_x[tid + offset];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 保证一个线程块中所有线程在执行该语句后面的语句之前，都完全执行了前面的语句。</span></span><br><span class="line">        <span class="comment">// 实现一个线程块中所有线程按照代码出现的顺序执行指令，即线程1等待线程0，如此。</span></span><br><span class="line">        <span class="comment">// 但是不同线程块之间依然是独立、异步的。</span></span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 通过线程块内同步，线程块 0 中的归约顺序：</span></span><br><span class="line">        <span class="comment">// 第一轮，curr_x[0] += curr_x[0+64], ... curr_x[63] += curr_x[63+64]；</span></span><br><span class="line">        <span class="comment">// 第二轮，curr_x[0] += curr_x[0+32], ... curr_x[31] += curr_x[31+32]；</span></span><br><span class="line">        <span class="comment">// 第三轮，curr_x[0] += curr_x[0+16], ... curr_x[15] += curr_x[15+16]； </span></span><br><span class="line">        <span class="comment">// 第四轮，curr_x[0] += curr_x[0+ 8], ... curr_x[7 ] += curr_x[7 + 8]；  </span></span><br><span class="line">        <span class="comment">// 第五轮，curr_x[0] += curr_x[0+ 4], ... curr_x[3 ] += curr_x[3 + 4]； </span></span><br><span class="line">        <span class="comment">// 第六轮，curr_x[0] += curr_x[0+ 2], curr_x[1 ] += curr_x[1 + 2]； </span></span><br><span class="line">        <span class="comment">// 第七轮，curr_x[0] += curr_x[0+ 1]；           </span></span><br><span class="line">        y[blockIdx.x] = curr_x[<span class="number">0</span>];  </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduce_shared</span><span class="params">(<span class="type">const</span> real *x, real *y, <span class="type">const</span> <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> bid = blockIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> ind = bid * blockDim.x + tid;</span><br><span class="line"></span><br><span class="line">    __shared__ real s_x[<span class="number">128</span>];  <span class="comment">// 定义线程块静态共享内存变量。 </span></span><br><span class="line">    s_x[tid] = (ind &lt; N) ? x[ind] : <span class="number">0.0</span>;  <span class="comment">// 拷贝全局内存变量到线程块内的共享内存数据副本。</span></span><br><span class="line">    __syncthreads();   <span class="comment">// 同步线程块的数据拷贝操作，保证各线程块中数据对于块内线程都准备好。</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = blockDim.x&gt;&gt;<span class="number">1</span>; offset &gt; <span class="number">0</span>; offset&gt;&gt;=<span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (ind &lt; offset)</span><br><span class="line">        &#123;</span><br><span class="line">            s_x[tid] += s_x[tid + offset];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads(); <span class="comment">// 线程块内线程同步。</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        y[bid] = s_x[<span class="number">0</span>]; <span class="comment">// 保存各个线程块中共享内存的0元素到全局内存。</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduce_shared2</span><span class="params">(<span class="type">const</span> real *x, real *y, <span class="type">const</span> <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> bid = blockIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> ind = bid * blockDim.x + tid;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">extern</span> __shared__ real s_x[];  <span class="comment">// 定义线程块动态共享内存变量，内存大小由主机调用核函数时定义。 </span></span><br><span class="line">    s_x[tid] = (ind &lt; N) ? x[ind] : <span class="number">0.0</span>;  <span class="comment">// 拷贝全局内存变量到线程块内的共享内存数据副本。</span></span><br><span class="line">    __syncthreads();   <span class="comment">// 同步线程块的数据拷贝操作，保证各线程块中数据对于块内线程都准备好。</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = blockDim.x&gt;&gt;<span class="number">1</span>; offset &gt; <span class="number">0</span>; offset&gt;&gt;=<span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (ind &lt; offset)</span><br><span class="line">        &#123;</span><br><span class="line">            s_x[tid] += s_x[tid + offset];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads(); <span class="comment">// 线程块内线程同步。</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        y[bid] = s_x[<span class="number">0</span>]; <span class="comment">// 保存各个线程块中共享内存的0元素到全局内存。</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> N = <span class="number">1e8</span>;  <span class="comment">// 单精度将发生 “大数吃小数” 的现象，导致结果完全错误；双精度没有问题。</span></span><br><span class="line">    <span class="type">int</span> M = N * <span class="built_in">sizeof</span>(real);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> block_size = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpyFromSymbol</span>(&amp;block_size, BLOCK_DIM, <span class="built_in">sizeof</span>(real)));</span><br><span class="line">    <span class="type">int</span> grid_size = (N + block_size - <span class="number">1</span>)/block_size; </span><br><span class="line"></span><br><span class="line">    real *h_x = <span class="keyword">new</span> real[N];</span><br><span class="line">    real *h_y = <span class="keyword">new</span> real[grid_size]; </span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        h_x[i] = <span class="number">1.23</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; FLOAT_PREC &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> t1 = system_clock::<span class="built_in">now</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// cpu归约，单精度下计算错误，大数吃小数。</span></span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;cpu reduce:  &quot;</span> &lt;&lt; <span class="built_in">reduce_cpu</span>(h_x, N) &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> t2 = system_clock::<span class="built_in">now</span>();</span><br><span class="line">    <span class="type">double</span> time = <span class="built_in">duration</span>&lt;<span class="type">double</span>, std::milli&gt;(t2 - t1).<span class="built_in">count</span>();</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;cpu reduce time cost: &quot;</span> &lt;&lt; time &lt;&lt; <span class="string">&quot; ms&quot;</span> &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    real *d_x, *d_y;</span><br><span class="line">    <span class="type">int</span> size = grid_size*<span class="built_in">sizeof</span>(real);</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>(&amp;d_x, M)); </span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>(&amp;d_y, size)); <span class="comment">// 数据分片后个线程块的归约结果数组。</span></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(d_x, h_x, M, cudaMemcpyDefault)); </span><br><span class="line">    </span><br><span class="line">    cudaEvent_t start, stop;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventCreate</span>(&amp;start));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventCreate</span>(&amp;stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventRecord</span>(start));</span><br><span class="line">    <span class="built_in">cudaEventQuery</span>(start);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// gpu归约，单精度下也能控制误差，稳健性更强。</span></span><br><span class="line">    reduce&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(d_x, d_y); </span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(h_y, d_y, size, cudaMemcpyDefault));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaGetLastError</span>());</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> elap_time=<span class="number">0</span>, curr_time=<span class="number">0</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventRecord</span>(stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventSynchronize</span>(stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventElapsedTime</span>(&amp;curr_time, start, stop));</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;gpu reduce: &quot;</span> &lt;&lt; <span class="built_in">reduce_cpu</span>(h_y, grid_size) &lt;&lt; endl;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;gpu reduce time cost: %f ms\n&quot;</span>, curr_time - elap_time);</span><br><span class="line">    elap_time = curr_time;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// gpu归约，采用静态共享内存的加速。</span></span><br><span class="line">    reduce_shared&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(d_x, d_y, N); </span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(h_y, d_y, size, cudaMemcpyDefault));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaGetLastError</span>());</span><br><span class="line"></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventRecord</span>(stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventSynchronize</span>(stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventElapsedTime</span>(&amp;curr_time, start, stop));</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;gpu shared reduce: &quot;</span> &lt;&lt; <span class="built_in">reduce_cpu</span>(h_y, grid_size) &lt;&lt; endl;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;gpu shared reduce time cost: %f ms\n&quot;</span>, curr_time - elap_time);</span><br><span class="line">    elap_time = curr_time;    </span><br><span class="line"></span><br><span class="line">    <span class="comment">// gpu归约，采用动态共享内存的加速。</span></span><br><span class="line">    <span class="comment">// &lt;&lt;&lt;grid_size, block_size, sharedMemSize&gt;&gt;&gt;，第三个参数指定动态共享内存大小。</span></span><br><span class="line">    <span class="type">int</span> sharedMemSize = block_size * <span class="built_in">sizeof</span>(real);  <span class="comment">// 核函数中每个线程块的动态共享内存大小。</span></span><br><span class="line">    reduce_shared2&lt;&lt;&lt;grid_size, block_size, sharedMemSize&gt;&gt;&gt;(d_x, d_y, N); </span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(h_y, d_y, size, cudaMemcpyDefault));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaGetLastError</span>());</span><br><span class="line"></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventRecord</span>(stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventSynchronize</span>(stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventElapsedTime</span>(&amp;curr_time, start, stop));</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;gpu shared2 reduce: &quot;</span> &lt;&lt; <span class="built_in">reduce_cpu</span>(h_y, grid_size) &lt;&lt; endl;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;gpu shared2 reduce time cost: %f ms\n&quot;</span>, curr_time - elap_time);</span><br><span class="line">    elap_time = curr_time; </span><br><span class="line"></span><br><span class="line">    <span class="keyword">delete</span>[] h_x;</span><br><span class="line">    <span class="keyword">delete</span>[] h_y;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(d_x));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(d_y));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="矩阵转置-1"><a href="#矩阵转置-1" class="headerlink" title="矩阵转置"></a>矩阵转置</h2><p>由于共享内存访问速度快于全局内存，所以可以通过线程块内的共享内存将全局内存的非合并访问转为合并访问。</p>
<p><strong>注意转置后的数组索引变换</strong>。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../common/error.cuh&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../common/floats.hpp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iomanip&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;fstream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> TILE_DIM  32</span></span><br><span class="line"></span><br><span class="line">__constant__ <span class="type">int</span> c_TILE_DIM = <span class="number">32</span>;  <span class="comment">// 设备内存中线程块中矩阵维度（线程块大小，最大1024）。</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">show</span><span class="params">(<span class="type">const</span> real *matrix, <span class="type">const</span> <span class="type">int</span> N, std::string outfile, std::string title)</span></span>;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">transpose1</span><span class="params">(<span class="type">const</span> real *src, real *dst, <span class="type">const</span> <span class="type">int</span> N)</span></span>;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">transpose2</span><span class="params">(<span class="type">const</span> real *src, real *dst, <span class="type">const</span> <span class="type">int</span> N)</span></span>;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">transpose3</span><span class="params">(<span class="type">const</span> real *src, real *dst, <span class="type">const</span> <span class="type">int</span> N)</span></span>;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">transpose4</span><span class="params">(<span class="type">const</span> real *src, real *dst, <span class="type">const</span> <span class="type">int</span> N)</span></span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 由于显存 2 GB，float 为 4 字节，double 为 8 字节，所以在 transpose3, transpose4中：</span></span><br><span class="line">    <span class="comment">// float 矩阵维度不能超过 726；</span></span><br><span class="line">    <span class="comment">// double 矩阵维度不能超过 512；</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> N = <span class="number">500</span>;  </span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> M = N * N * <span class="built_in">sizeof</span>(real);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> SIZE = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpyFromSymbol</span>(&amp;SIZE, c_TILE_DIM, <span class="built_in">sizeof</span>(<span class="type">int</span>)));   </span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> grid_size_x = (N + SIZE - <span class="number">1</span>)/SIZE; <span class="comment">// 获取网格大小。</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> grid_size_y = grid_size_x;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">const</span> dim3 <span class="title">block_size</span><span class="params">(SIZE, SIZE)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">const</span> dim3 <span class="title">grid_size</span><span class="params">(grid_size_x, grid_size_y)</span></span>;</span><br><span class="line"></span><br><span class="line">    real *h_matrix_org, *h_matrix_res;</span><br><span class="line">    h_matrix_org = <span class="keyword">new</span> real[N*N];</span><br><span class="line">    h_matrix_res = <span class="keyword">new</span> real[N*N];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; N; ++j)</span><br><span class="line">        &#123;</span><br><span class="line">            h_matrix_org[i * N + j] = i*<span class="number">1.0e-2</span>;</span><br><span class="line">        &#125;   </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// show(h_matrix_org, N, &quot;result.txt&quot;, &quot;origin matrix&quot;);</span></span><br><span class="line">    </span><br><span class="line">    real *d_matrix_org, *d_matrix_res;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>(&amp;d_matrix_org, M));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>(&amp;d_matrix_res, M));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(d_matrix_org, h_matrix_org, M, cudaMemcpyDefault));    </span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> elapsed_time = <span class="number">0</span>;</span><br><span class="line">    <span class="type">float</span> curr_time = <span class="number">0</span>;</span><br><span class="line">    cudaEvent_t start, stop;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventCreate</span>(&amp;start));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventCreate</span>(&amp;stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventRecord</span>(start));</span><br><span class="line">    <span class="built_in">cudaEventQuery</span>(start);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 矩阵转置（全局内存合并读取、非合并写入）。</span></span><br><span class="line">    transpose1&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(d_matrix_org, d_matrix_res, N);     </span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(h_matrix_res, d_matrix_res, M, cudaMemcpyDefault));</span><br><span class="line">    <span class="comment">// show(h_matrix_res, N, &quot;result.txt&quot;, &quot;transpose1&quot;);</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventRecord</span>(stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventSynchronize</span>(stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventElapsedTime</span>(&amp;curr_time, start, stop));    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;matrix transpose1 time cost: %f ms.\n&quot;</span>, curr_time - elapsed_time);</span><br><span class="line">    elapsed_time = curr_time;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 矩阵转置（全局内存非合并读取、合并写入）。</span></span><br><span class="line">    transpose2&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(d_matrix_org, d_matrix_res, N);     </span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(h_matrix_res, d_matrix_res, M, cudaMemcpyDefault));</span><br><span class="line">    <span class="comment">// show(h_matrix_res, N, &quot;matrix.txt&quot;, &quot;transpose2&quot;);</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventRecord</span>(stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventSynchronize</span>(stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventElapsedTime</span>(&amp;curr_time, start, stop));    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;matrix transpose2 time cost: %f ms.\n&quot;</span>, curr_time - elapsed_time);</span><br><span class="line">    elapsed_time = curr_time;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 矩阵转置（通过共享内存全局内存合并读写）。</span></span><br><span class="line">    transpose3&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(d_matrix_org, d_matrix_res, N);     </span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(h_matrix_res, d_matrix_res, M, cudaMemcpyDefault));</span><br><span class="line">    <span class="comment">// show(h_matrix_res, N, &quot;result.txt&quot;, &quot;transpose3&quot;);</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventRecord</span>(stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventSynchronize</span>(stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventElapsedTime</span>(&amp;curr_time, start, stop));    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;matrix transpose3 time cost: %f ms.\n&quot;</span>, curr_time - elapsed_time);</span><br><span class="line">    elapsed_time = curr_time;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 矩阵转置（通过共享内存、bank处理，实现全局内存合并读写）。</span></span><br><span class="line">    transpose4&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(d_matrix_org, d_matrix_res, N);     </span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(h_matrix_res, d_matrix_res, M, cudaMemcpyDefault));</span><br><span class="line">    <span class="comment">// show(h_matrix_res, N, &quot;result.txt&quot;, &quot;transpose3&quot;);</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventRecord</span>(stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventSynchronize</span>(stop));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaEventElapsedTime</span>(&amp;curr_time, start, stop));    </span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;matrix transpose4 time cost: %f ms.\n&quot;</span>, curr_time - elapsed_time);</span><br><span class="line">    elapsed_time = curr_time;    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">delete</span>[] h_matrix_res;</span><br><span class="line">    <span class="keyword">delete</span>[] h_matrix_org;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(d_matrix_org));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(d_matrix_res));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">show</span><span class="params">(<span class="type">const</span> real *x, <span class="type">const</span> <span class="type">int</span> N, std::string outfile, std::string title)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function">std::fstream <span class="title">out</span><span class="params">(outfile, std::ios::app)</span></span>;</span><br><span class="line">    <span class="keyword">if</span> (!out.<span class="built_in">is_open</span>())</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr &lt;&lt; <span class="string">&quot;invalid output file: &quot;</span> &lt;&lt; outfile &lt;&lt; endl;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    out &lt;&lt; <span class="string">&quot;\n\n----------------&quot;</span> &lt;&lt; title &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        out &lt;&lt; endl;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; N; ++j)</span><br><span class="line">        &#123;</span><br><span class="line">            out &lt;&lt; std::<span class="built_in">setw</span>(<span class="number">6</span>) &lt;&lt; x[i * N + j];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">transpose1</span><span class="params">(<span class="type">const</span> real *src, real *dst, <span class="type">const</span> <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> nx = threadIdx.x + blockIdx.x * c_TILE_DIM;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> ny = threadIdx.y + blockIdx.y * c_TILE_DIM;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (nx &lt; N &amp;&amp; ny &lt; N)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 矩阵转置（合并读取、非合并写入）。</span></span><br><span class="line">        dst[nx*N + ny] = src[ny*N + nx];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">transpose2</span><span class="params">(<span class="type">const</span> real *src, real *dst, <span class="type">const</span> <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> nx = threadIdx.x + blockIdx.x * c_TILE_DIM;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> ny = threadIdx.y + blockIdx.y * c_TILE_DIM;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (nx &lt; N &amp;&amp; ny &lt; N)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 矩阵转置（非合并读取、合并写入）。</span></span><br><span class="line">        dst[ny*N + nx] = __ldg(&amp;src[nx*N + ny]);   <span class="comment">// 显示调用 `__ldg()` 函数缓存全局内存。 </span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">transpose3</span><span class="params">(<span class="type">const</span> real *src, real *dst, <span class="type">const</span> <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 正常的做法中，全局内存的读写必有一个是非合并访问。</span></span><br><span class="line">    <span class="comment">// 现在通过将非合并访问转移到共享内存，利用共享内存的高性能（100倍全局内存），提高计算速度：  </span></span><br><span class="line">    <span class="comment">// 1. 首先将全局内存拷贝到线程块的共享内存；</span></span><br><span class="line">    <span class="comment">// 2. 然后从共享内存非合并访问，读取数据，合并写入全局内存。</span></span><br><span class="line"></span><br><span class="line">    __shared__ real s_mat[TILE_DIM][TILE_DIM];  <span class="comment">//二维静态共享内存，存储线程块内的一片矩阵。</span></span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> bx = blockIdx.x * blockDim.x;  <span class="comment">// 当前线程块首线程在网格中列索引。</span></span><br><span class="line">    <span class="type">int</span> by = blockIdx.y * blockDim.y;  <span class="comment">// 当前线程块首线程在网格中行索引。</span></span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> tx = threadIdx.x + bx;  <span class="comment">// 当前线程在网格中列索引。</span></span><br><span class="line">    <span class="type">int</span> ty = threadIdx.y + by;  <span class="comment">// 当前线程在网格中行索引。</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tx &lt; N &amp;&amp; ty &lt; N)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 全局内存合并访问，共享内存合并访问。</span></span><br><span class="line">        s_mat[threadIdx.y][threadIdx.x] = src[ty * N + tx]; <span class="comment">// 全局内存中二维矩阵一维存储。</span></span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 全局内存合并访问。</span></span><br><span class="line">    <span class="keyword">if</span> (tx &lt; N &amp;&amp; ty &lt; N)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 局部矩阵转置和全局内存合并写入。</span></span><br><span class="line">        <span class="type">int</span> x = by + threadIdx.x;</span><br><span class="line">        <span class="type">int</span> y = bx + threadIdx.y;</span><br><span class="line">        dst[y * N + x] = s_mat[threadIdx.x][threadIdx.y]; </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">transpose4</span><span class="params">(<span class="type">const</span> real *src, real *dst, <span class="type">const</span> <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 通过修改数组行大小，错开数组元素在共享内存bank中的分布，</span></span><br><span class="line">    <span class="comment">// 避免线程束的 32路bank冲突。</span></span><br><span class="line">    __shared__ real s_mat[TILE_DIM][TILE_DIM + <span class="number">1</span>];  </span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> bx = blockIdx.x * blockDim.x; </span><br><span class="line">    <span class="type">int</span> by = blockIdx.y * blockDim.y; </span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> tx = threadIdx.x + bx;  </span><br><span class="line">    <span class="type">int</span> ty = threadIdx.y + by;  </span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tx &lt; N &amp;&amp; ty &lt; N)</span><br><span class="line">    &#123;</span><br><span class="line">        s_mat[threadIdx.y][threadIdx.x] = src[ty * N + tx]; </span><br><span class="line">    &#125;</span><br><span class="line">    __syncthreads();</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (tx &lt; N &amp;&amp; ty &lt; N)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> x = by + threadIdx.x;</span><br><span class="line">        <span class="type">int</span> y = bx + threadIdx.y;</span><br><span class="line">        dst[y * N + x] = s_mat[threadIdx.x][threadIdx.y]; </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="共享内存的-bank-冲突"><a href="#共享内存的-bank-冲突" class="headerlink" title="共享内存的 bank 冲突"></a>共享内存的 bank 冲突</h2><p>共享内存在物理上被分为32个同样宽度（开普勒架构为 8 字节，其他为 4 字节）、能被同时访问的列向内存bank。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">++++++++++++++++++++++++++++++++++++++</span><br><span class="line"></span><br><span class="line">bank0     bank1    ...    bank31  </span><br><span class="line"></span><br><span class="line">++++++++++++++++++++++++++++++++++++++</span><br><span class="line"></span><br><span class="line">layer1    layer1   ...    layer1  </span><br><span class="line">layer2    layer2   ...    layer2  </span><br><span class="line">...  </span><br><span class="line">layer32   layer32   ...   layer32  </span><br></pre></td></tr></table></figure></p>
<p>只要同一个线程束内的多个线程不同时访问同一个 bank 中不同层的数据，该线程束对共享内存的访问就只需要 一次内存事务。当同一个线程束内的多个线程试图访问同一个 bank 中不同层的数据时，就会发生冲突。  在同一线程束中的多个线程对同一个 bank 中的 n 层数据访问将导致 n 次内存事务， 称为发生了 <strong>n 路 bank 冲突</strong>。</p>
<p>当线程束内的32个线程同时访问同一个 bank 的32个不同层，这将导致 32 路 bank 冲突。对于非开普勒架构， 每个共享内存的宽带为 4 字节；于是每一层的32个 bank 将对应 32 个 float 数组元素。</p>
<p>使用共享内存来改善全局内存的访问方式不一定会提高核函数的性能；不要过早优化，在优化程序时要对不同的优化方案进行测试和比较。</p>
<h1 id="原子函数的合理使用"><a href="#原子函数的合理使用" class="headerlink" title="原子函数的合理使用"></a>原子函数的合理使用</h1><p>cuda 中，一个线程的原子操作可以在不受其他线程的任何操作的影响下完成对某个（全局内存或共享内存）<br>数据的一套“读-改-写”操作。</p>
<hr>
<h2 id="完全在-GPU-中进行归约"><a href="#完全在-GPU-中进行归约" class="headerlink" title="完全在 GPU 中进行归约"></a>完全在 GPU 中进行归约</h2><p>有两种方法能够在GPU中得到最终结果：  </p>
<ol>
<li>用另一个核函数将较短的数组进一步归约；</li>
<li>在核函数末尾利用原子函数进行归约。</li>
</ol>
<p>在代码实现中：</p>
<ol>
<li>原子函数 <code>atomicAdd(·)</code>执行数组的一次完整的读-写操作；</li>
<li>传给 <code>cudaMemcpy(·)</code> 的主机内存可以是栈内存，也可以是堆内存；</li>
<li>主机函数可以和设备函数同名，但要遵循重载原则（参数列表不一致）。</li>
</ol>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../common/error.cuh&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../common/floats.hpp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../common/clock.cuh&quot;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduce</span><span class="params">(real *x, real *y, <span class="type">const</span> <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="type">int</span> ind = tid + blockIdx.x * blockDim.x;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">extern</span> __shared__ real curr_x[];</span><br><span class="line">    curr_x[tid] = (ind &lt; N) ? x[ind] : <span class="number">0.0</span>;    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = blockDim.x/<span class="number">2</span> ; offset &gt; <span class="number">0</span> ; offset /= <span class="number">2</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (tid &lt; offset)</span><br><span class="line">        &#123;</span><br><span class="line">            curr_x[tid] += curr_x[tid + offset];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        y[blockIdx.x] = curr_x[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduce2</span><span class="params">(real *x, real *y, <span class="type">const</span> <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="type">int</span> ind = tid + blockIdx.x * blockDim.x;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">extern</span> __shared__ real curr_x[];</span><br><span class="line">    curr_x[tid] = (ind &lt; N) ? x[ind] : <span class="number">0.0</span>;    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = blockDim.x/<span class="number">2</span> ; offset &gt; <span class="number">0</span> ; offset /= <span class="number">2</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (tid &lt; offset)</span><br><span class="line">        &#123;</span><br><span class="line">            curr_x[tid] += curr_x[tid + offset];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 原子函数 atomicAdd(*address, val).</span></span><br><span class="line">        <span class="built_in">atomicAdd</span>(y, curr_x[<span class="number">0</span>]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> N = <span class="number">1e8</span>;</span><br><span class="line">    <span class="type">int</span> M = N * <span class="built_in">sizeof</span>(real);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> bSize = <span class="number">32</span>;</span><br><span class="line">    <span class="type">int</span> gSize = (N + bSize - <span class="number">1</span>)/bSize;</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; FLOAT_PREC &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    real *h_x, *h_y;</span><br><span class="line">    h_x = <span class="keyword">new</span> real[N];</span><br><span class="line">    h_y = <span class="keyword">new</span> real[gSize];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        h_x[i] = <span class="number">1.23</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cudaClockStart</span><br><span class="line"></span><br><span class="line">    real *d_x, *d_y;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>(&amp;d_x, M));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>(&amp;d_y, gSize*<span class="built_in">sizeof</span>(real)));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(d_x, h_x, M, cudaMemcpyDefault));</span><br><span class="line"></span><br><span class="line">    cudaClockCurr</span><br><span class="line"></span><br><span class="line">    reduce&lt;&lt;&lt;gSize, bSize, (bSize<span class="number">+1</span>)*<span class="built_in">sizeof</span>(real)&gt;&gt;&gt;(d_x, d_y, N);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(h_y, d_y, gSize*<span class="built_in">sizeof</span>(real), cudaMemcpyDefault));</span><br><span class="line">    real res = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; gSize; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        res += h_y[i];</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;reduce result: &quot;</span> &lt;&lt; res &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    cudaClockCurr</span><br><span class="line"></span><br><span class="line">    reduce&lt;&lt;&lt;gSize, bSize, (bSize)*<span class="built_in">sizeof</span>(real)&gt;&gt;&gt;(d_x, d_y, N);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(h_y, d_y, gSize*<span class="built_in">sizeof</span>(real), cudaMemcpyDefault));</span><br><span class="line">    res = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; gSize; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        res += h_y[i];</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;reduce result: &quot;</span> &lt;&lt; res &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    cudaClockCurr</span><br><span class="line">    </span><br><span class="line">    real *d_y2, *h_y2;</span><br><span class="line">    h_y2 = <span class="keyword">new</span> <span class="built_in">real</span>(<span class="number">0.0</span>);</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>(&amp;d_y2, <span class="built_in">sizeof</span>(real)));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 采用原子函数、共享内存的核函数归约，</span></span><br><span class="line">    <span class="comment">// 由于减少了主机和设备间的数据传输，效率得以提高。</span></span><br><span class="line">    reduce2&lt;&lt;&lt;gSize, bSize, (bSize)*<span class="built_in">sizeof</span>(real)&gt;&gt;&gt;(d_x, d_y2, N);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(h_y2, d_y2, <span class="built_in">sizeof</span>(real), cudaMemcpyDefault));</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;reduce2 result: &quot;</span> &lt;&lt; *h_y2 &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    cudaClockCurr</span><br><span class="line"></span><br><span class="line">    <span class="keyword">delete</span>[] h_x;</span><br><span class="line">    <span class="keyword">delete</span>[] h_y;</span><br><span class="line">    <span class="keyword">delete</span> h_y2;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(d_x));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(d_y));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(d_y2));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="原子函数"><a href="#原子函数" class="headerlink" title="原子函数"></a>原子函数</h2><p>原子函数对其第一个参数指向的数据进行一次“读-写-改”的原子操作，是不可分割的操作。 第一个参数可以指向全局内存，也可以指向共享内存。  </p>
<p>对所有参与的线程来说，原子操作是一个线程一个线程轮流进行的，没有明确的次序。 原子函数没有同步功能。</p>
<p>原子函数的返回值为所指地址的旧值。</p>
<ul>
<li>加法： <code>T atomicAdd(T *address, T val)</code>；</li>
<li>减法： <code>T atomicSub(T *address, T val)</code>；</li>
<li>交换： <code>T atomicExch(T *address, T val)</code>;</li>
<li>最小值： <code>T atomicMin(T *address, T val)</code>；</li>
<li>最大值： <code>T atomicMax(T *address, T val)</code>；</li>
<li>自增： <code>T atomicInc(T *address, T val)</code>；</li>
<li>自减： <code>T atomicDec(T *address, T val)</code>；</li>
<li>比较交换： <code>T atomicCAS(T *address, T compare, T val)</code>；  </li>
</ul>
<hr>
<h2 id="邻居列表"><a href="#邻居列表" class="headerlink" title="邻居列表"></a>邻居列表</h2><p>两个粒子互为邻居的判断：他们的距离不大于一个给定的截断距离 rc。<br>基本算法： 对每一个给定的粒子，通过比较它与所有其他粒子的距离来判断相应粒子对是否互为邻居。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../common/error.cuh&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../common/floats.hpp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../common/clock.cuh&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;fstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;regex&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">read_data</span><span class="params">(<span class="type">const</span> std::string &amp;fstr, std::vector&lt;real&gt; &amp;x, std::vector&lt;real&gt; &amp;y)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">write_data</span><span class="params">(<span class="type">const</span> std::string &amp;fstr, <span class="type">const</span> <span class="type">int</span> *NL, <span class="type">const</span> <span class="type">int</span> N, <span class="type">const</span> <span class="type">int</span> M)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">find_neighbor</span><span class="params">(<span class="type">int</span> *NN, <span class="type">int</span> *NL, <span class="type">const</span> real *x, <span class="type">const</span> real *y, </span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> N, <span class="type">const</span> <span class="type">int</span> M, </span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> real minDis)</span></span>;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">find_neighbor_gpu</span> <span class="params">(<span class="type">int</span> *NN, <span class="type">int</span> *NL, <span class="type">const</span> real *x, <span class="type">const</span> real *y, </span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> N, <span class="type">const</span> <span class="type">int</span> M, </span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> real mindDis)</span></span>;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">find_neighbor_atomic</span><span class="params">(<span class="type">int</span> *NN, <span class="type">int</span> *NL, <span class="type">const</span> real *x, <span class="type">const</span> real *y, </span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> N, <span class="type">const</span> <span class="type">int</span> M, </span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> real minDis)</span></span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    cout &lt;&lt; FLOAT_PREC &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    std::string fstr = <span class="string">&quot;xy.txt&quot;</span>;</span><br><span class="line">    std::string fout = <span class="string">&quot;result.txt&quot;</span>;</span><br><span class="line">    std::vector&lt;real&gt; x, y;</span><br><span class="line">    <span class="built_in">read_data</span>(fstr, x, y);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> N = x.<span class="built_in">size</span>(), M = <span class="number">10</span>;</span><br><span class="line">    real minDis = <span class="number">1.9</span>*<span class="number">1.9</span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> *NN = <span class="keyword">new</span> <span class="type">int</span>[N];</span><br><span class="line">    <span class="type">int</span> *NL = <span class="keyword">new</span> <span class="type">int</span>[N*M];</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        NN[i] = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; M; ++j)</span><br><span class="line">        &#123;</span><br><span class="line">            NL[i*M + j] = <span class="number">-1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> *d_NN, *d_NL;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>(&amp;d_NN, N*<span class="built_in">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>(&amp;d_NL, N*M*<span class="built_in">sizeof</span>(<span class="type">int</span>)));</span><br><span class="line">    real *d_x, *d_y;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>(&amp;d_x, N*<span class="built_in">sizeof</span>(real)));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>(&amp;d_y, N*<span class="built_in">sizeof</span>(real)));</span><br><span class="line"></span><br><span class="line">    <span class="function">cppClockStart</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    <span class="title">find_neighbor</span><span class="params">(NN, NL, x.data(), y.data(), N, M, minDis)</span></span>;</span><br><span class="line">    <span class="comment">// write_data(fout, NL, N, M);</span></span><br><span class="line">    <span class="function">cppClockCurr</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    cudaClockStart</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    <span class="title">CHECK</span><span class="params">(cudaMemcpy(d_x, x.data(), N*<span class="keyword">sizeof</span>(real), cudaMemcpyDefault))</span></span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(d_y, y.<span class="built_in">data</span>(), N*<span class="built_in">sizeof</span>(real), cudaMemcpyDefault));</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> block_size = <span class="number">128</span>;</span><br><span class="line">    <span class="type">int</span> grid_size = (N + block_size - <span class="number">1</span>)/block_size;</span><br><span class="line">    find_neighbor_atomic&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(d_NN, d_NL, d_x, d_y, N, M, minDis);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(NN, d_NN, N*<span class="built_in">sizeof</span>(<span class="type">int</span>), cudaMemcpyDefault));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(NL, d_NL, N*M*<span class="built_in">sizeof</span>(<span class="type">int</span>), cudaMemcpyDefault));</span><br><span class="line">    <span class="comment">// write_data(fout, NL, N, M);</span></span><br><span class="line"></span><br><span class="line">    <span class="function">cudaClockCurr</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    <span class="title">CHECK</span><span class="params">(cudaMemcpy(d_x, x.data(), N*<span class="keyword">sizeof</span>(real), cudaMemcpyDefault))</span></span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(d_y, y.<span class="built_in">data</span>(), N*<span class="built_in">sizeof</span>(real), cudaMemcpyDefault));</span><br><span class="line">    find_neighbor_gpu&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(d_NN, d_NL, d_x, d_y, N, M, minDis);</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(NN, d_NN, N*<span class="built_in">sizeof</span>(<span class="type">int</span>), cudaMemcpyDefault));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(NL, d_NL, N*M*<span class="built_in">sizeof</span>(<span class="type">int</span>), cudaMemcpyDefault));</span><br><span class="line"></span><br><span class="line">    <span class="function">cudaClockCurr    </span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    <span class="title">write_data</span><span class="params">(fout, NL, N, M)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">delete</span>[] NN;</span><br><span class="line">    <span class="keyword">delete</span>[] NL;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(d_NN));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(d_NL));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(d_x));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(d_y));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">find_neighbor</span><span class="params">(<span class="type">int</span> *NN, <span class="type">int</span> *NL, <span class="type">const</span> real *x, <span class="type">const</span> real *y, </span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> N, <span class="type">const</span> <span class="type">int</span> M, </span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> real minDis)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        NN[i] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = i + <span class="number">1</span>; j &lt; N; ++j)</span><br><span class="line">        &#123;</span><br><span class="line">            real dx = x[j] - x[i];</span><br><span class="line">            real dy = y[j] - y[i];</span><br><span class="line">            real dis = dx * dx + dy * dy;</span><br><span class="line">            <span class="keyword">if</span> (dis &lt; minDis) <span class="comment">// 比较平方，减少计算量。</span></span><br><span class="line">            &#123;</span><br><span class="line">                NL[i*M + NN[i]] = j;  <span class="comment">// 一维数组存放二维数据。</span></span><br><span class="line">                NN[i] ++;</span><br><span class="line">                NL[j*M + NN[j]] = i;  <span class="comment">// 省去一般的判断。</span></span><br><span class="line">                NN[j]++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">find_neighbor_gpu</span> <span class="params">(<span class="type">int</span> *NN, <span class="type">int</span> *NL, <span class="type">const</span> real *x, <span class="type">const</span> real *y, </span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> N, <span class="type">const</span> <span class="type">int</span> M, </span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> real minDis)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (i &lt; N)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">int</span> count = <span class="number">0</span>;  <span class="comment">// 寄存器变量，减少对全局变量NN的访问。</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; N; ++j)  <span class="comment">// 访问次数 N*N，性能降低。</span></span><br><span class="line">        &#123;</span><br><span class="line">            real dx = x[j] - x[i];</span><br><span class="line">            real dy = y[j] - y[i];</span><br><span class="line">            real dis = dx * dx + dy * dy;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> (dis &lt; minDis &amp;&amp; i != j) <span class="comment">// 距离判断优先，提高“假”的命中率。</span></span><br><span class="line">            &#123;</span><br><span class="line">                <span class="comment">// 修改了全局内存NL的数据排列方式，实现合并访问（i 与 threadIdx.x的变化步调一致）。</span></span><br><span class="line">                <span class="comment">// ???</span></span><br><span class="line">                NL[(count++) * N + i] = j;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        NN[i] = count;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">find_neighbor_atomic</span><span class="params">(<span class="type">int</span> *NN, <span class="type">int</span> *NL, <span class="type">const</span> real *x, <span class="type">const</span> real *y, </span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> N, <span class="type">const</span> <span class="type">int</span> M, </span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> real minDis)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 将 cpu 版本的第一层循环展开，一个线程对应一个原子操作。</span></span><br><span class="line">    <span class="type">int</span> i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (i &lt; N)</span><br><span class="line">    &#123;</span><br><span class="line">        NN[i] = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = i + <span class="number">1</span>; j &lt; N; ++j)</span><br><span class="line">        &#123;</span><br><span class="line">            real dx = x[j] - x[i];</span><br><span class="line">            real dy = y[j] - y[i];</span><br><span class="line">            real dis = dx * dx + dy*dy;</span><br><span class="line">            <span class="keyword">if</span> (dis &lt; minDis)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="comment">// 原子函数提高的性能，但是在NL中产生了一定的随机性，不便于后期调试。</span></span><br><span class="line">                <span class="type">int</span> old_i_num = <span class="built_in">atomicAdd</span>(&amp;NN[i], <span class="number">1</span>);  <span class="comment">// 返回值为旧值，当前线程对应点的邻居数</span></span><br><span class="line">                NL[i*M + old_i_num] = j;  <span class="comment">// 当前线程对应点的新邻居</span></span><br><span class="line">                <span class="type">int</span> old_j_num = <span class="built_in">atomicAdd</span>(&amp;NN[j], <span class="number">1</span>);  <span class="comment">// 返回值为旧值，当前邻居点的邻居数</span></span><br><span class="line">                NL[j*M + old_j_num] = i;  <span class="comment">// 当前邻居点的新邻居</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">read_data</span><span class="params">(<span class="type">const</span> std::string &amp;fstr, std::vector&lt;real&gt; &amp;x, std::vector&lt;real&gt; &amp;y)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    x.<span class="built_in">clear</span>();</span><br><span class="line">    y.<span class="built_in">clear</span>();</span><br><span class="line"></span><br><span class="line">    <span class="function">std::fstream <span class="title">reader</span><span class="params">(fstr, std::ios::in)</span></span>;</span><br><span class="line">    <span class="keyword">if</span> (!reader.<span class="built_in">is_open</span>())</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr &lt;&lt; <span class="string">&quot;data file open failed.\n&quot;</span>;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    std::regex re&#123;<span class="string">&quot;[\\s,]+&quot;</span>&#125;;</span><br><span class="line">    std::string line;</span><br><span class="line">    <span class="keyword">while</span>(std::<span class="built_in">getline</span>(reader, line))</span><br><span class="line">    &#123;</span><br><span class="line">       std::vector&lt;std::string&gt; arr&#123;std::<span class="built_in">sregex_token_iterator</span>(line.<span class="built_in">begin</span>(), line.<span class="built_in">end</span>(), re, <span class="number">-1</span>), </span><br><span class="line">           std::<span class="built_in">sregex_token_iterator</span>()&#125;;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span> (arr.<span class="built_in">size</span>() &lt; <span class="number">2</span> || arr[<span class="number">0</span>].<span class="built_in">find</span>(<span class="string">&quot;#&quot;</span>) != std::string::npos)</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="keyword">continue</span>;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		x.<span class="built_in">push_back</span>(<span class="built_in">stod</span>(arr[<span class="number">0</span>]));</span><br><span class="line">		y.<span class="built_in">push_back</span>(<span class="built_in">stod</span>(arr[<span class="number">1</span>]));        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">write_data</span><span class="params">(<span class="type">const</span> std::string &amp;fstr, <span class="type">const</span> <span class="type">int</span> *NL, <span class="type">const</span> <span class="type">int</span> N, <span class="type">const</span> <span class="type">int</span> M)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function">std::fstream <span class="title">writer</span><span class="params">(fstr, std::ios::out)</span></span>;</span><br><span class="line">    <span class="keyword">if</span> (!writer.<span class="built_in">is_open</span>())</span><br><span class="line">    &#123;</span><br><span class="line">        std::cerr &lt;&lt; <span class="string">&quot;result file open failed.\n&quot;</span>;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        writer &lt;&lt; i &lt;&lt; <span class="string">&quot;\t&quot;</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; M; ++j)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">int</span> ind = NL[i*M + j];</span><br><span class="line">            <span class="keyword">if</span> (ind &gt;= <span class="number">0</span>) </span><br><span class="line">            &#123;</span><br><span class="line">                writer &lt;&lt; ind &lt;&lt; <span class="string">&quot;\t&quot;</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        writer &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="线程束基本函数与协作组"><a href="#线程束基本函数与协作组" class="headerlink" title="线程束基本函数与协作组"></a>线程束基本函数与协作组</h1><p>线程束（warp），即一个线程块中连续32个线程。</p>
<hr>
<h2 id="单指令-多线程模式"><a href="#单指令-多线程模式" class="headerlink" title="单指令-多线程模式"></a>单指令-多线程模式</h2><p>一个GPU被分为若干个流多处理器（SM）。核函数中定义的线程块（block）在执行时将被分配到还没有完全占满的 SM。  一个block不会被分配到不同的SM，同时一个 SM 中可以有多个 block。不同的block 之间可以并发也可以顺序执行，一般不能同步。当某些block完成计算任务后，对应的 SM 会部分或完全空闲，然后会有新的block被分配到空闲的SM。</p>
<p>一个 SM 以32个线程（warp）为单位产生、管理、调度、执行线程。<br>一个 SM 可以处理多个block，一个block可以分为若干个warp。</p>
<p>在同一时刻，一个warp中的线程只能执行一个共同的指令或者闲置，即<strong>单指令-多线程</strong>执行模型，  （single instruction multiple thread, SIMT）。</p>
<p>当一个线程束中线程顺序的执行判断语句中的不同分支时，称为发生了 <strong>分支发散</strong>（branch divergence）。</p>
<pre><code>if (condition)
&#123;
    A;
&#125;
else
&#123;
    B;
&#125;
</code></pre><p>首先，满足 <code>condition</code> 的线程或执行语句A，其他的线程会闲置；然后，不满足条件的将会执行语句B，其他线程闲置。  当语句A和B的指令数差不多时，整个warp的执行效率就比没有分支的情况 <em>低一半</em>。</p>
<p>一般应当在核函数中尽量避免分支发散，但有时这也是不可避免的。如数组计算中常用的判断语句：</p>
<pre><code>if(n &lt; N)
&#123;
    // do something.
&#125;
</code></pre><p>该分支判断最多影响最后一个block中的某些warp发生分支发散， 一般不会显著地影响性能。</p>
<p>有时能通过 <strong>合并判断语句</strong> 的方式减少分支发散；另外，如果两分支中有一个分支 不包含指令，则即使发生分支发散也不会显著影响性能。</p>
<p><em>注意不同架构中的线程调度机制</em></p>
<hr>
<h2 id="线程束内的线程同步函数"><a href="#线程束内的线程同步函数" class="headerlink" title="线程束内的线程同步函数"></a>线程束内的线程同步函数</h2><p><code>__syncwarp(·)</code>：当所涉及的线程都在一个线程束内时，可以将线程块同步函数 <code>__syncthreads()</code><br>换成一个更加廉价的线程束同步函数<code>__syncwarp(·)</code>，简称 <strong>束内同步函数</strong>。</p>
<p>函数参数是一个代表掩码的无符号整型数，默认值是全部32个二进制位都为1，代表<br>线程束中的所有线程都参与同步。</p>
<p>关于 <em>掩码(mask)</em> 的简介文章：<a href="https://zhuanlan.zhihu.com/p/352025616">思否小姐姐：“奇怪的知识——位掩码”</a></p>
<hr>
<h2 id="更多线程束内的基本函数"><a href="#更多线程束内的基本函数" class="headerlink" title="更多线程束内的基本函数"></a>更多线程束内的基本函数</h2><p><strong>线程束表决函数</strong>；  </p>
<ul>
<li><p><code>unsigned __ballot_sync(unsigned mask, int predicate)</code>，如果线程束内第n个线程参与计算（旧掩码）且predicate值非零，则返回的无符号整型数（新掩码）  的第n个二进制位为1，否则为0。</p>
</li>
<li><p><code>int __all_sync(unsigned mask, int predicate)</code>，   线程束内所有参与线程的predicate值均非零，则返回1，否则返回0.</p>
</li>
<li><p><code>int __any_sync(unsigned mask, int predicate)</code>，  线程束内所有参与线程的predicate值存在非零，则返回1， 否则返回0.</p>
</li>
</ul>
<p><strong>线程束洗牌函数</strong>：  </p>
<ul>
<li><p><code>T __shfl_sync(unsigned mask, T v, int srcLane, int w = warpSize)</code>， 参与线程返回标号为 srcLane 的线程中变量 v 的值。  该函数将一个线程中的数据广播到所有线程。</p>
</li>
<li><p><code>T __shfl_up_sync(unsigned mask, T v, unsigned d, int w=warpSize)</code>，  标号为t的参与线程返回标号为 t-d 的线程中变量v的值，t-d&lt;0的线程返回t线程的变量v。   该函数是一种将数据向上平移的操作，即将低线程号的值平移到高线程号。  例如当w=8、d=2时，2-7号线程将返回 0-5号线程中变量v的值；0-1号线程返回自己的 v。</p>
</li>
<li><p><code>T __shfl_down_sync(unsigned mask, T v, unsigned d, int w=warpSize)</code>，  标号为t的参与线程返回标号为 t+d 的线程中变量v的值，t+d&gt;w的线程返回t线程的变量v。  该函数是一种将数据向下平移的操作，即将高线程号的值平移到低线程号。  例如当w=8、d=2时，0-5号线程将返回2-7号线程中变量v的值，6-7号线程将返回自己的 v。</p>
</li>
<li><p><code>T __shfl__xor_sync(unsigned mask, T v, int laneMask, int w=warpSize)</code>,  标号为t的参与线程返回标号为 t^laneMask 的线程中变量 v 的值。  该函数让线程束内的线程两两交换数据。</p>
</li>
</ul>
<p>每个线程束洗牌函数都有一个可选参数 <code>w</code>，默认是线程束大小（32），且只能取2、4，8、16、32。  当 w 小于 32 时，相当于逻辑上的线程束大小是 w，其他规则不变。  此时，可以定义一个 <strong>束内索引</strong>：(假设使用一维线程块)</p>
<pre><code>int laneId = threadIdx.x % w;  // 线程索引与束内索引的对应关系。
</code></pre><p>假设线程块大小为16，w 为 8：</p>
<pre><code>线程索引： 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 
束内索引： 0 1 2 3 4 5 6 7 0 1 2  3  4  5  6  7
</code></pre><p>参数中的 <code>mask</code> 称为掩码，是一个无符号整型，具有32位，一般用 <em>十六进制</em> 表示：  </p>
<pre><code>const unsigned FULL_MASK = 0xffffffff; // `0x`表示十六进制数；`0b`表示二进制数。
</code></pre><p>或者</p>
<pre><code>#define FULL_MASK 0xffffffff
</code></pre><p>以上所有线程束内函数都有 <code>_sync</code> 后缀，表示这些函数都具有 <strong>隐式的同步功能</strong>。</p>
<hr>
<h2 id="协作组"><a href="#协作组" class="headerlink" title="协作组"></a>协作组</h2><p>协作组（cooperative groups），可以看作是线程块和线程束同步机制的推广，<br>提供包括线程块内部的同步与协作、线程块之间（网格级）的同步与协作、以及<br>设备与设备之间的同步与协作。</p>
<p>使用协作组需要包含如下头文件：  </p>
<pre><code>#include &lt;cooperative_groups.h&gt;
using namespace cooperative_groups;
</code></pre><p><strong>线程块级别的协作组</strong></p>
<p>协作组编程模型中最基本的类型是线程组 <code>thread_group</code>，其包含如下成员： </p>
<ul>
<li><code>void sync()</code>，同步组内所有线程；</li>
<li><code>unsigned size()</code>，返回组内总的线程数目，即组的大小；</li>
<li><code>unsigned thread_rank()</code>，返回当前调用该函数的线程在组内的标号（从0计数）；</li>
<li><code>bool is_valid()</code>，如果定义的组违反了任何cuda限制，返回 false，否则true；</li>
</ul>
<p>线程组类型有一个导出类型，<strong>线程块thread_block</strong>，其中定义了额外的函数：</p>
<ul>
<li><code>dim3 group_index()</code>，返回当前调用该函数的线程的线程块指标，等价于 <code>blockIdx</code>；</li>
<li><code>dim3 thread_index()</code>，返回当前调用该函数的线程的线程指标，等价于 <code>threadIdx</code>；</li>
</ul>
<p>通过 <code>this_thread_block()</code> 初始化一个线程块对象： </p>
<pre><code>thread_block g = this_thread_block();  // 相当于一个线程块类型的常量。
</code></pre><p>此时，  </p>
<pre><code>g.sync() &lt;===&gt; __syncthreads()
g.group_index() &lt;===&gt; blockIdx
g.thread_index() &lt;===&gt; threadIdx
</code></pre><p>通过 <code>tiled_partition()</code> 可以将一个线程块划分为若干片（tile），每一片构成一个新的线程组。目前，仅支持将片的大小设置为 2 的整数次方且不大于 32。  </p>
<pre><code>thread_group g32 = tiled_partition(this_thread_block(), 32); // 将线程块划分为线程束。
</code></pre><p>可以继续将线程组划分为更细的线程组：  </p>
<pre><code>thread_group g4 = tiled_partition(g32, 4);
</code></pre><p>采用模板、在编译期划分 <strong>线程块片（thread block tile）</strong>：  </p>
<pre><code>thread_block_tile&lt;32&gt; g32 = tiled_partition&lt;32&gt;(this_thread_block());
thread_block_tile&lt;32&gt; g4 = tiled_partition&lt;4&gt;(this_thread_block());
</code></pre><p>线程块片具有额外的函数（类似线程束内函数）：  </p>
<ul>
<li><code>unsigned ballot(int predicate)</code>;</li>
<li><code>int all(int predicate)</code>;</li>
<li><code>int any(int predicate)</code>;</li>
<li><code>T shfl(T v, int srcLane)</code>;</li>
<li><code>T shfl_up(T v, unsigned d)</code>;</li>
<li><code>T shfl_down(T v, unsigned d)</code>;</li>
<li><code>T shfl_xor(T v, unsigned d)</code>;</li>
</ul>
<p>与一般的线程束不同，线程组内的所有线程都要参与代码运行计算；同时，线程组内函数不需要指定宽度，因为该宽度就是线程块片的大小。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../common/error.cuh&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">unsigned</span> WIDTH = <span class="number">8</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">unsigned</span> BLOCK_SIZE = <span class="number">16</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">unsigned</span> FULL_MASK = <span class="number">0xffffffff</span>;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">test_warp_primitives</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="type">int</span> laneId = tid % WIDTH;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;threadIdx.x: &quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%2d  &quot;</span>, tid);</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;laneId: &quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%2d  &quot;</span>, laneId);</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 从 FULL_MASK 出发， 计算 mask1（排除 0 号线程）掩码和mask2（仅保留 0 线程）掩码。</span></span><br><span class="line">    <span class="type">unsigned</span> mask1 = __ballot_sync(FULL_MASK, tid&gt;<span class="number">0</span>);</span><br><span class="line">    <span class="type">unsigned</span> mask2 = __ballot_sync(FULL_MASK, tid==<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;FULL_MASK = %x\n&quot;</span>, FULL_MASK);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;mask1     = %x\n&quot;</span>, mask1);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;mask2     = %x\n&quot;</span>, mask2);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 从 FULL_MASK 出发计算线程束状态。</span></span><br><span class="line">    <span class="comment">// 因为不是所有线程的tid 都大于0，所以此处返回 0.</span></span><br><span class="line">    <span class="type">int</span> result = __all_sync(FULL_MASK, tid);</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>) </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;all_sync (FULL_MASK): %d\n&quot;</span>, result);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 从 mask1 出发计算线程束状态。</span></span><br><span class="line">    <span class="comment">// 因为mask1 中关闭了0号线程，所以剩下的所有线程tid &gt; 0，此处返回 1.</span></span><br><span class="line">    result = __all_sync(mask1, tid);</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">1</span>) </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;all_sync (mask1): %d\n&quot;</span>, result);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 从 FULL_MASK 出发计算线程束状态。</span></span><br><span class="line">    <span class="comment">// 因为存在线程的tid 都大于0，所以此处返回 1.</span></span><br><span class="line">    result = __any_sync(FULL_MASK, tid);</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;any_sync (FULL_MASK): %d\n&quot;</span>, result);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 从 mask2 出发计算线程束状态。</span></span><br><span class="line">    <span class="comment">// 因为mask2 中仅激活了 0 号线程，所以此处返回 0.</span></span><br><span class="line">    result = __any_sync(mask2, tid);</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;any_sync (mask2): %d\n&quot;</span>, result);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 从 FULL_MASK 出发，将每个线程束中 2号线程的tid广播到线程束内所有函数并作为返回值。</span></span><br><span class="line">    <span class="comment">// 所以在第一个线程束中，所有8个线程都将返回 laneId=2 线程（2 号线程）的tid值；</span></span><br><span class="line">    <span class="comment">// 在第二个线程束中，所有8个线程都也将返回 landId=2 线程（10 号线程）的tid值。</span></span><br><span class="line">    <span class="type">int</span> value = __shfl_sync(FULL_MASK, tid, <span class="number">2</span>, WIDTH);</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;shfl:    &quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%2d  &quot;</span>, value);</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 从FULL_MASK出发，将每个线程束内 1-7 号线程取 0-6号线程的tid值并作为返回值。</span></span><br><span class="line">    <span class="comment">// 所以在第一个线程束中，0号线程返回自己的tid，1号线程返回0号线程的tid，2号线程返回1号线程tid, ...</span></span><br><span class="line">    value = __shfl_up_sync(FULL_MASK, tid, <span class="number">1</span>, WIDTH);</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;shfl_up:    &quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%2d  &quot;</span>, value);</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 从 FULL_MASK 出发，将每个线程束内 0-6号线程取 1-7 号线程的tid值并作为返回值。</span></span><br><span class="line">    <span class="comment">// 所以在第一个线程束中，0号线程返回1号线程的tid，2号线程返回3号线程的tid，..., 7号线程返回自己的tid。</span></span><br><span class="line">    value = __shfl_down_sync(FULL_MASK, tid, <span class="number">1</span>, WIDTH);</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;shfl_down:    &quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%2d  &quot;</span>, value);</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    &#125;    </span><br><span class="line"></span><br><span class="line">    <span class="comment">// 从 FULL_MASK 出发，将线程束中相邻的线程的tid相互传递并作为返回值。</span></span><br><span class="line">    <span class="comment">// 所以在第一个线程束中，0号线程返回1号线程的tid、1号线程返回0号线程的tid，2号线程返回3号线程的tid、  </span></span><br><span class="line">    <span class="comment">// 3号线程返回2号线程的tid，...</span></span><br><span class="line">    value = __shfl_xor_sync(FULL_MASK, tid, <span class="number">1</span>, WIDTH);</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;shfl_xor:    &quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%2d  &quot;</span>, value);</span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;\n&quot;</span>);</span><br><span class="line">    &#125;    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    test_warp_primitives&lt;&lt;&lt;<span class="number">1</span>, BLOCK_SIZE&gt;&gt;&gt;();</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="数组归约程序的进一步优化"><a href="#数组归约程序的进一步优化" class="headerlink" title="数组归约程序的进一步优化"></a>数组归约程序的进一步优化</h2><p><strong>提高线程利用率</strong></p>
<p>在当前的归约程序中，当 offset=64，只用了 1/2 的线程；当 offset=32，只用了 1/4 的线程；…<br>最终，当 offset=1，只用了 1/128 的线程；  归约过程一共用了 log2(128) = 7 步，平均线程利用率 (1/2 + 1/4 + … + 1/128)/7 =&gt; 1/7。</p>
<p>而在归约前的数据拷贝中线程利用率为 100%，可以尽量把计算放在在归约前：让一个线程处理多个数据。</p>
<p>一个线程处理相邻若干个数据会导致全局内存的非合并访问。要保证全局内存的合并访问，这里需要  保证相邻线程处理相邻数据，一个线程访问的数据需要有某种跨度。  该跨度可以是线程块的大小，也可以是网格的大小；对于一维情况，分别是 blockDim.x 和 blockDim.x * gridDim.x。</p>
<p><strong>避免反复分配与释放设备内存</strong></p>
<p>设备内存的分配与释放是比较耗时的。  通过采用静态全局内存替代动态全局内存，实现编译期的设备内存分配可以更加高效。</p>
<p>此外，应当尽量避免在较内存循环反复的分配和释放设备内存。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../common/error.cuh&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../common/floats.hpp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../common/clock.cuh&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cooperative_groups.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cooperative_groups;</span><br><span class="line"></span><br><span class="line">__constant__ <span class="type">unsigned</span> FULL_MASK = <span class="number">0xffffffff</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">define</span> __gSize  10240</span></span><br><span class="line">__device__ real static_y[__gSize];</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduce_syncthreads</span><span class="params">(real *x, real *y, <span class="type">const</span> <span class="type">int</span> N)</span></span>;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduce_syncwarp</span><span class="params">(real *x, real *y, <span class="type">const</span> <span class="type">int</span> N)</span></span>;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduce_shfl_down</span><span class="params">(real *x, real *y, <span class="type">const</span> <span class="type">int</span> N)</span></span>;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduce_cp</span><span class="params">(real *x, real *y, <span class="type">const</span> <span class="type">int</span> N)</span></span>;</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduce_cp_grid</span><span class="params">(<span class="type">const</span> real *x, real *y, <span class="type">const</span> <span class="type">int</span> N)</span></span>;</span><br><span class="line"><span class="function">real <span class="title">reduce_wrap</span><span class="params">(<span class="type">const</span> real *x, <span class="type">const</span> <span class="type">int</span> N, <span class="type">const</span> <span class="type">int</span> gSize, <span class="type">const</span> <span class="type">int</span> bSize)</span></span>;</span><br><span class="line"><span class="function">real <span class="title">reduce_wrap_static</span><span class="params">(<span class="type">const</span> real *x, <span class="type">const</span> <span class="type">int</span> N, <span class="type">const</span> <span class="type">int</span> gSize, <span class="type">const</span> <span class="type">int</span> bSize)</span></span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> N = <span class="number">1e8</span>;</span><br><span class="line">    <span class="type">int</span> M = N * <span class="built_in">sizeof</span>(real);</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> bSize = <span class="number">32</span>;</span><br><span class="line">    <span class="type">int</span> gSize = (N + bSize - <span class="number">1</span>)/bSize;</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; FLOAT_PREC &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    real *h_x, *h_x2, *h_y, *h_y2, *h_res;</span><br><span class="line">    h_x = <span class="keyword">new</span> real[N];</span><br><span class="line">    h_x2 = <span class="keyword">new</span> real[N];</span><br><span class="line">    h_y = <span class="keyword">new</span> real[gSize];</span><br><span class="line">    h_y2 = <span class="keyword">new</span> real[gSize];</span><br><span class="line">    h_res = <span class="keyword">new</span> <span class="built_in">real</span>(<span class="number">0.0</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        h_x[i] = <span class="number">1.23</span>;</span><br><span class="line">        h_x2[i] = <span class="number">1.23</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    real initRes = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; gSize ; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        h_y2[i] = <span class="number">0.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cudaClockStart</span><br><span class="line"></span><br><span class="line">    real *d_x, *d_y, *d_res;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>(&amp;d_x, M));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>(&amp;d_y, gSize*<span class="built_in">sizeof</span>(real)));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>(&amp;d_res, <span class="built_in">sizeof</span>(real)));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(d_x, h_x, M, cudaMemcpyDefault));</span><br><span class="line"></span><br><span class="line">    cudaClockCurr</span><br><span class="line"></span><br><span class="line">    reduce_syncthreads&lt;&lt;&lt;gSize, bSize, (bSize)*<span class="built_in">sizeof</span>(real)&gt;&gt;&gt;(d_x, d_y, N);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(h_y, d_y, gSize*<span class="built_in">sizeof</span>(real), cudaMemcpyDefault));</span><br><span class="line">    real res = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; gSize; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        res += h_y[i];</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;reduce_syncthreads result: &quot;</span> &lt;&lt; res &lt;&lt; endl;</span><br><span class="line">    <span class="function">cudaClockCurr</span></span><br><span class="line"><span class="function">    </span></span><br><span class="line"><span class="function">    <span class="title">CHECK</span><span class="params">(cudaMemcpy(d_res, &amp;initRes, <span class="keyword">sizeof</span>(real), cudaMemcpyDefault))</span></span>;</span><br><span class="line">    reduce_syncwarp&lt;&lt;&lt;gSize, bSize, <span class="function">bSize*<span class="title">sizeof</span><span class="params">(real)</span>&gt;&gt;&gt;<span class="params">(d_x, d_res, N)</span></span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(h_res, d_res, <span class="built_in">sizeof</span>(real), cudaMemcpyDefault));</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;reduce_syncwrap result: &quot;</span> &lt;&lt; *h_res &lt;&lt; endl;</span><br><span class="line">    <span class="function">cudaClockCurr</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    <span class="title">CHECK</span><span class="params">(cudaMemcpy(d_res, &amp;initRes, <span class="keyword">sizeof</span>(real), cudaMemcpyDefault))</span></span>;</span><br><span class="line">    reduce_shfl_down&lt;&lt;&lt;gSize, bSize, <span class="function">bSize*<span class="title">sizeof</span><span class="params">(real)</span>&gt;&gt;&gt;<span class="params">(d_x, d_res, N)</span></span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(h_res, d_res, <span class="built_in">sizeof</span>(real), cudaMemcpyDefault));</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;reduce_shfl_down result: &quot;</span> &lt;&lt; *h_res &lt;&lt; endl;</span><br><span class="line">    <span class="function">cudaClockCurr</span></span><br><span class="line"><span class="function"></span></span><br><span class="line"><span class="function">    <span class="title">CHECK</span><span class="params">(cudaMemcpy(d_res, &amp;initRes, <span class="keyword">sizeof</span>(real), cudaMemcpyDefault))</span></span>;</span><br><span class="line">    reduce_cp&lt;&lt;&lt;gSize, bSize, <span class="function">bSize*<span class="title">sizeof</span><span class="params">(real)</span>&gt;&gt;&gt;<span class="params">(d_x, d_res, N)</span></span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(h_res, d_res, <span class="built_in">sizeof</span>(real), cudaMemcpyDefault));</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;reduce_cp result: &quot;</span> &lt;&lt; *h_res &lt;&lt; endl;</span><br><span class="line">    cudaClockCurr</span><br><span class="line"></span><br><span class="line">    reduce_cp_grid&lt;&lt;&lt;gSize, bSize, <span class="function">bSize*<span class="title">sizeof</span><span class="params">(real)</span>&gt;&gt;&gt;<span class="params">(d_x, d_y, N)</span></span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(h_y, d_y, gSize*<span class="built_in">sizeof</span>(real), cudaMemcpyDefault));</span><br><span class="line">    res = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; gSize; ++i)</span><br><span class="line">    &#123;</span><br><span class="line">        res += h_y[i];</span><br><span class="line">    &#125;    </span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;reduce_cp_grid result: &quot;</span> &lt;&lt; res &lt;&lt; endl;</span><br><span class="line">    cudaClockCurr  </span><br><span class="line"></span><br><span class="line">    res =  <span class="built_in">reduce_wrap</span>(d_x, N, <span class="number">10240</span>, <span class="number">128</span>);</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;reduce_wrap result: &quot;</span> &lt;&lt; res &lt;&lt; endl;</span><br><span class="line">    cudaClockCurr  </span><br><span class="line"></span><br><span class="line">    res =  <span class="built_in">reduce_wrap_static</span>(d_x, N, <span class="number">10240</span>, <span class="number">128</span>);</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;reduce_wrap_static result: &quot;</span> &lt;&lt; res &lt;&lt; endl;</span><br><span class="line">    cudaClockCurr         </span><br><span class="line"></span><br><span class="line">    <span class="keyword">delete</span>[] h_x;</span><br><span class="line">    <span class="keyword">delete</span>[] h_y;</span><br><span class="line">    <span class="keyword">delete</span> h_res;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(d_x));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(d_y));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(d_res));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduce_syncthreads</span><span class="params">(real *x, real *y, <span class="type">const</span> <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> tid = threadIdx.x;  <span class="comment">// 线程块中线程在x方向的id。</span></span><br><span class="line">    <span class="type">int</span> ind = tid + blockIdx.x * blockDim.x; <span class="comment">// 一维线程块中线程在GPU中的id。</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">extern</span> __shared__ real block_x[]; <span class="comment">// 线程块共享内存。</span></span><br><span class="line">    block_x[tid] = (ind &lt; N)? x[ind] : <span class="number">0</span>;</span><br><span class="line">    __syncthreads();  <span class="comment">// 同步共享内存的拷贝操作，确保共享内存的数据已准备好。</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> offset = blockDim.x/<span class="number">2</span>; offset &gt; <span class="number">0</span>; offset /= <span class="number">2</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (tid &lt; offset)</span><br><span class="line">        &#123;</span><br><span class="line">            block_x[tid] += block_x[tid + offset];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads(); <span class="comment">// 同步线程块内线程。</span></span><br><span class="line"></span><br><span class="line">    &#125;    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        y[blockIdx.x] = block_x[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduce_syncwarp</span><span class="params">(real *x, real *y, <span class="type">const</span> <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> bid = blockIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> ind = bid * blockDim.x + tid;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">extern</span> __shared__ real block_arr[];</span><br><span class="line">    block_arr[tid] = (ind &lt; N) ? x[ind] : <span class="number">0.0</span>;</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 线程束之间的二分求和。</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = blockDim.x/<span class="number">2</span>; offset &gt;= <span class="number">32</span>; offset /=<span class="number">2</span>)  </span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (tid &lt; offset)</span><br><span class="line">        &#123;</span><br><span class="line">            block_arr[tid] += block_arr[tid + offset];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncthreads(); <span class="comment">// 同步线程块内的线程。</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 线程束内的二分求和。</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = <span class="number">16</span>; offset &gt; <span class="number">0</span>; offset /=<span class="number">2</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (tid &lt; offset)</span><br><span class="line">        &#123;</span><br><span class="line">            block_arr[tid] += block_arr[tid + offset];</span><br><span class="line">        &#125;</span><br><span class="line">        __syncwarp();  <span class="comment">// 同步线程束内的线程。</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">atomicAdd</span>(y, block_arr[<span class="number">0</span>]);  <span class="comment">// 原子函数求和。</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduce_shfl_down</span><span class="params">(real *x, real *y, <span class="type">const</span> <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> bid = blockIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> ind = bid * blockDim.x + tid;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">extern</span> __shared__ real block_arr[];</span><br><span class="line">    block_arr[tid] = (ind &lt; N) ? x[ind] : <span class="number">0.0</span>;</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = blockDim.x /<span class="number">2</span> ; offset &gt;= <span class="number">32</span>; offset /= <span class="number">2</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (tid &lt; offset)</span><br><span class="line">        &#123;</span><br><span class="line">            block_arr[tid] += block_arr[tid + offset];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在线程寄存器上定义一个变量y。</span></span><br><span class="line">    real curr_y = block_arr[tid];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = <span class="number">16</span>; offset &gt; <span class="number">0</span>; offset /= <span class="number">2</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 通过线程束洗牌函数，从FULL_MASK出发，</span></span><br><span class="line">        <span class="comment">// 将高线程号（数组索引）中的curr_y值平移到低线程号，通过设置偏移值为 offset，等价实现了线程束内的折半归约。</span></span><br><span class="line">        curr_y += __shfl_down_sync(FULL_MASK, curr_y, offset);</span><br><span class="line">    &#125;  </span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">atomicAdd</span>(y, curr_y);</span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduce_cp</span><span class="params">(real *x, real *y, <span class="type">const</span> <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> bid = blockIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> ind = bid * blockDim.x + tid;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">extern</span> __shared__ real block_arr[];</span><br><span class="line">    block_arr[tid] = (ind &lt; N) ? x[ind] : <span class="number">0.0</span>;</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = blockDim.x /<span class="number">2</span> ; offset &gt;= <span class="number">32</span>; offset /= <span class="number">2</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (tid &lt; offset)</span><br><span class="line">        &#123;</span><br><span class="line">            block_arr[tid] += block_arr[tid + offset];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    real curr_y = block_arr[tid];   </span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建线程块片。</span></span><br><span class="line">    thread_block_tile&lt;<span class="number">32</span>&gt; g32 = <span class="built_in">tiled_partition</span>&lt;<span class="number">32</span>&gt;(<span class="built_in">this_thread_block</span>());</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = <span class="number">16</span>; offset &gt; <span class="number">0</span>; offset /= <span class="number">2</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 线程块片的等价线程束内函数。</span></span><br><span class="line">        curr_y += g<span class="number">32.</span><span class="built_in">shfl_down</span>(curr_y, offset);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">atomicAdd</span>(y, curr_y);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">reduce_cp_grid</span><span class="params">(<span class="type">const</span> real *x, real *y, <span class="type">const</span> <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> bid = blockIdx.x;</span><br><span class="line">    <span class="keyword">extern</span> __shared__ real block_arr[];</span><br><span class="line"></span><br><span class="line">    real curr_y = <span class="number">0.0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在归约前处理计算。</span></span><br><span class="line">    <span class="comment">// ???</span></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> stride = blockDim.x * gridDim.x;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> n = bid * blockDim.x + tid; n &lt; N; n += stride)</span><br><span class="line">    &#123;</span><br><span class="line">        curr_y += x[n];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    block_arr[tid] = curr_y;</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = blockDim.x /<span class="number">2</span> ; offset &gt;= <span class="number">32</span>; offset /= <span class="number">2</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (tid &lt; offset)</span><br><span class="line">        &#123;</span><br><span class="line">            block_arr[tid] += block_arr[tid + offset];</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        __syncthreads();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    curr_y = block_arr[tid];</span><br><span class="line">    thread_block_tile&lt;<span class="number">32</span>&gt; g32 = <span class="built_in">tiled_partition</span>&lt;<span class="number">32</span>&gt;(<span class="built_in">this_thread_block</span>());</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = <span class="number">16</span>; offset &gt; <span class="number">0</span>; offset /= <span class="number">2</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 线程块片的等价线程束内函数。</span></span><br><span class="line">        curr_y += g<span class="number">32.</span><span class="built_in">shfl_down</span>(curr_y, offset);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        y[bid] = curr_y;</span><br><span class="line">    &#125;    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function">real <span class="title">reduce_wrap</span><span class="params">(<span class="type">const</span> real *x, <span class="type">const</span> <span class="type">int</span> N, <span class="type">const</span> <span class="type">int</span> gSize, <span class="type">const</span> <span class="type">int</span> bSize)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> ymem = gSize * <span class="built_in">sizeof</span>(real);</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> smem = bSize * <span class="built_in">sizeof</span>(real);</span><br><span class="line"></span><br><span class="line">    real h_y[<span class="number">1</span>] = &#123;<span class="number">0</span>&#125;;</span><br><span class="line">    real *d_y;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>(&amp;d_y, ymem));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 使用两个核函数时，将数组 d_y 归约到最终结果的计算也是折半归约，  </span></span><br><span class="line">    <span class="comment">// 这比直接累加（使用原子函数或复制到主机再累加）要稳健（单精度下精度更高）。</span></span><br><span class="line">    <span class="comment">// 设备全局内存变量 d_x, d_y 对于每个线程块都是可见的，对于两个核函数是相同的。</span></span><br><span class="line">    reduce_cp_grid&lt;&lt;&lt;gSize, bSize, smem&gt;&gt;&gt;(x, d_y, N);</span><br><span class="line">    reduce_cp_grid&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1024</span>, <span class="number">1024</span>*<span class="built_in">sizeof</span>(real)&gt;&gt;&gt;(d_y, d_y, gSize);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(h_y, d_y, <span class="built_in">sizeof</span>(real), cudaMemcpyDefault));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(d_y));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> h_y[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">real <span class="title">reduce_wrap_static</span><span class="params">(<span class="type">const</span> real *x, <span class="type">const</span> <span class="type">int</span> N, <span class="type">const</span> <span class="type">int</span> gSize, <span class="type">const</span> <span class="type">int</span> bSize)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    real *d_y;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaGetSymbolAddress</span>((<span class="type">void</span>**)&amp;d_y, static_y));   <span class="comment">// 获取设备静态全局内存或常量内存的地址（指针）。</span></span><br><span class="line"></span><br><span class="line">    reduce_cp_grid&lt;&lt;&lt;gSize, bSize, <span class="function">bSize * <span class="title">sizeof</span><span class="params">(real)</span>&gt;&gt;&gt;<span class="params">(x, d_y, N)</span></span>;</span><br><span class="line">    reduce_cp_grid&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1024</span>, <span class="number">1024</span>*<span class="built_in">sizeof</span>(real)&gt;&gt;&gt;(d_y, d_y, gSize);</span><br><span class="line"></span><br><span class="line">    real h_y[<span class="number">1</span>] = &#123;<span class="number">0</span>&#125;;  </span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(h_y, d_y, <span class="built_in">sizeof</span>(real), cudaMemcpyDefault));</span><br><span class="line">    <span class="comment">// CHECK(cudaFree(d_y));  // 全局内存由系统否则释放。</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> h_y[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="CUDA-流"><a href="#CUDA-流" class="headerlink" title="CUDA 流"></a>CUDA 流</h1><p>一个 CUDA 流一般是指由主机发出的、在设备中执行的cuda操作序列（即和cuda有关的操作， 如主机—设备数据传输和核函数执行）。目前不考虑由设备段发出的流。</p>
<p>任何cuda操作都存在于某个cuda流，要么是 <strong>默认流（default stream）</strong>，也称为 <strong>空流</strong>；  要么是明确指定的流。非默认的cuda流（非空流）都是在主机端产生与销毁。<br>一个cuda流由类型为 <code>cudaStream_t</code> 的变量表示，创建与销毁的方式：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cudaSteam_t stream;</span><br><span class="line">CHECK(cudaStreamCreate(&amp;stream));</span><br><span class="line">...</span><br><span class="line">CHECK(cudaStreamDestroy(stream));</span><br></pre></td></tr></table></figure>
<p>主机中可以产生多个相互独立的cuda流，并实现cuda流之间的并行。</p>
<p>为了检查一个cuda流中所有操作是否都已在设备中执行完毕：  </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cudaError_t cudaStreamSynchronize(cudaStream_t stream);</span><br><span class="line">cudaError_t cudaStreamQuery(cudaStream_t stream);</span><br></pre></td></tr></table></figure>
<p><code>cudaStreamSynchronize</code> 会强制阻塞主机，直到其中的stream流执行完毕；  <code>cudaStreamQuery</code> 不会阻塞主机，只是检查cuda流（stream）是否执行完毕，若是，则返回 <code>cudaSuccess</code>;  否则，返回 <code>cudaErrorNotReady</code>。</p>
<hr>
<h2 id="在默认流中重叠主机和设备计算"><a href="#在默认流中重叠主机和设备计算" class="headerlink" title="在默认流中重叠主机和设备计算"></a>在默认流中重叠主机和设备计算</h2><p><strong>同一个cuda流在设备中都是顺序执行的。</strong> 在数组相加的例子中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cudaMemcpy(d_x, h_x, M, cudaMemcpyDefault);</span><br><span class="line">cudaMemcpy(d_y, h_y, M, cudaMemcpyDefault);</span><br><span class="line">add&lt;&lt;&lt;gridSize, blockSize&gt;&gt;&gt;(d_x, d_y, d_z, N);</span><br><span class="line">cudaMemcpy(h_z, d_z, M, cudaMemcpyDefault);</span><br></pre></td></tr></table></figure>
<p>从设备的角度，以上4个cuda语句是按代码顺序执行的。</p>
<p>采用 <code>cudaMemcpy</code> 函数在主机与设备间拷贝数据，是具有隐式同步功能的。<br>所以从主机的角度看，数据传输是同步的或者说阻塞的，即主机在发出命令：  </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cudaMemcpy(d_x, h_x, M, cudaMemcpyDefault);</span><br></pre></td></tr></table></figure>
<p>之后，会等待该命令执行完完毕，再接着往下走；数据传输时，主机是闲置的。<br>与此不同的是，核函数的启动是异步的或者说非阻塞的，即在主机发出命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add&lt;&lt;&lt;gridSize, blockSize&gt;&gt;&gt;(d_x, d_y, d_z, N);</span><br></pre></td></tr></table></figure>
<p>之后，不会等待该命令执行完毕，而是立刻得到程序的控制权。紧接着发出：  </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cudaMemcpy(h_z, d_z, M, cudaMemcpyDefault);</span><br></pre></td></tr></table></figure>
<p>然而，该命令不会被立刻执行，因为其与核函数同处默认流，需要顺序执行。</p>
<p>所以，主机在发出核函数调用后会立刻发出下一个命令；如果下一个命令是 主机中的某个计算任务，那么主机就会在设备执行核函数的同时执行计算。  这样就可以实现主机和设备的重叠计算。</p>
<p>当主机和设备的计算量相当时，将主机函数放在设备核函数后可以达到主机函数  与设备函数并发执行的效果，从而有效地隐藏主机函数的执行时间。</p>
<hr>
<h2 id="非默认-cuda-流重叠多个核函数"><a href="#非默认-cuda-流重叠多个核函数" class="headerlink" title="非默认 cuda 流重叠多个核函数"></a>非默认 cuda 流重叠多个核函数</h2><p>要实现多个核函数之间的并行必须使用多个非默认 cuda 流。</p>
<p>使用多个流相对于使用一个流有加速效果；当流的数目超过某个阈值时，加速比就趋于饱和。  制约加速比的因素：  </p>
<ul>
<li>GPU 计算资源，当核函数的线程总数超过某一值时，再增加流的数目就不会带来更高性能；</li>
<li>GPU 中能够并发执行的核函数的上限。</li>
</ul>
<p>指定核函数的cuda流的方法：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kernal_func&lt;&lt;&lt;grid_size, block_size, 0, stream&gt;&gt;&gt;(params);</span><br></pre></td></tr></table></figure>
<p>在调用核函数时，如果不需要使用共享内存，则该项设为0；同时指定cuda流的id。</p>
<p>计算能力为7，5的GPU能执行的核函数上限值为128。</p>
<hr>
<h2 id="非默认-cuda-流重叠核函数与数据传递"><a href="#非默认-cuda-流重叠核函数与数据传递" class="headerlink" title="非默认 cuda 流重叠核函数与数据传递"></a>非默认 cuda 流重叠核函数与数据传递</h2><p>要实现核函数执行与数据传输的并发（重叠），必须让这两个操作处于不同的非默认流；同时，数据传输需要使用 <code>cudaMemcpy</code> 的异步版本 <code>cudaMemcpyAsync</code>。</p>
<p>异步传输由GPU的DMA（direct memory access）实现，不需要主机的参与。</p>
<p>使用异步的数据传输函数时，需要将主机内存定义为不可分页内存或者固定内存，从而防止在程序执行期间物理地址被修改。如果将可分页内存传递给 <code>cudaMemcpyAsync</code>  则会导致同步传输。</p>
<p>主机不可分页内存的分配与释放：  </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cudaError_t cudaMallocHost(void **ptr, size_t size);</span><br><span class="line">或者</span><br><span class="line">cudaError_t cudaHostAlloc(void **ptr, size_t size);</span><br><span class="line"></span><br><span class="line">cudaError_t cudaFreeHost(void *ptr);</span><br></pre></td></tr></table></figure>
<p>要利用多个流提升性能，一种方法是将数据和相应计算操作分为若干等分，  然后在每个流中发布一个cuda操作序列。</p>
<p>如果核函数执行、主机与设备间的数据传输这3个cuda操作能完全并行执行，理论上最大加速比为 3。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../common/error.cuh&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../common/floats.hpp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;math.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> NUM_REPEATS = <span class="number">10</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N1 = <span class="number">1024</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> MAX_NUM_STREAMS = <span class="number">30</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N2 = N1 * MAX_NUM_STREAMS;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> M2 = <span class="built_in">sizeof</span>(real) * N2;</span><br><span class="line">cudaStream_t streams[MAX_NUM_STREAMS];  <span class="comment">// cuda流数组，全局变量由系统负责销毁。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">100000000</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> M = <span class="built_in">sizeof</span>(real) * N;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> block_size = <span class="number">128</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> grid_size = (N - <span class="number">1</span>) / block_size + <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">timing</span><span class="params">(<span class="type">const</span> real *h_x, <span class="type">const</span> real *h_y, real *h_z,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> real *d_x, <span class="type">const</span> real *d_y, real *d_z,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> ratio, <span class="type">bool</span> overlap)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">timing</span><span class="params">(<span class="type">const</span> real *d_x, <span class="type">const</span> real *d_y, real *d_z, </span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> num)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">timing</span><span class="params">(<span class="type">const</span> real *h_x, <span class="type">const</span> real *h_y, real *h_z,</span></span></span><br><span class="line"><span class="params"><span class="function">    real *d_x, real *d_y, real *d_z,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> num</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    real *h_x = (real*) <span class="built_in">malloc</span>(M);</span><br><span class="line">    real *h_y = (real*) <span class="built_in">malloc</span>(M);</span><br><span class="line">    real *h_z = (real*) <span class="built_in">malloc</span>(M);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> n = <span class="number">0</span>; n &lt; N; ++n)</span><br><span class="line">    &#123;</span><br><span class="line">        h_x[n] = <span class="number">1.23</span>;</span><br><span class="line">        h_y[n] = <span class="number">2.34</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    real *d_x, *d_y, *d_z;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>(&amp;d_x, M));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>(&amp;d_y, M));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>(&amp;d_z, M));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(d_x, h_x, M, cudaMemcpyHostToDevice));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpy</span>(d_y, h_y, M, cudaMemcpyHostToDevice));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// host and kernal overlap.</span></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Without CPU-GPU overlap (ratio = 10)\n&quot;</span>);</span><br><span class="line">    <span class="built_in">timing</span>(h_x, h_y, h_z, d_x, d_y, d_z, <span class="number">10</span>, <span class="literal">false</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;With CPU-GPU overlap (ratio = 10)\n&quot;</span>);</span><br><span class="line">    <span class="built_in">timing</span>(h_x, h_y, h_z, d_x, d_y, d_z, <span class="number">10</span>, <span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Without CPU-GPU overlap (ratio = 1)\n&quot;</span>);</span><br><span class="line">    <span class="built_in">timing</span>(h_x, h_y, h_z, d_x, d_y, d_z, <span class="number">1</span>, <span class="literal">false</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;With CPU-GPU overlap (ratio = 1)\n&quot;</span>);</span><br><span class="line">    <span class="built_in">timing</span>(h_x, h_y, h_z, d_x, d_y, d_z, <span class="number">1</span>, <span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Without CPU-GPU overlap (ratio = 1000)\n&quot;</span>);</span><br><span class="line">    <span class="built_in">timing</span>(h_x, h_y, h_z, d_x, d_y, d_z, <span class="number">1000</span>, <span class="literal">false</span>);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;With CPU-GPU overlap (ratio = 1000)\n&quot;</span>);</span><br><span class="line">    <span class="built_in">timing</span>(h_x, h_y, h_z, d_x, d_y, d_z, <span class="number">1000</span>, <span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// kernal and kernal overlap.</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> n = <span class="number">0</span> ; n &lt; MAX_NUM_STREAMS; ++n)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 创建cuda流。</span></span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaStreamCreate</span>(&amp;(streams[n])));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> num = <span class="number">1</span>; num &lt;= MAX_NUM_STREAMS; ++num)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">timing</span>(d_x, d_y, d_z, num);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> n = <span class="number">0</span> ; n &lt; MAX_NUM_STREAMS; ++n)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">// 销毁cuda流。</span></span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaStreamDestroy</span>(streams[n]));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// kernal and data transfering overlap.</span></span><br><span class="line">    real *h_x2, *h_y2, *h_z2;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMallocHost</span>(&amp;h_x2, M));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMallocHost</span>(&amp;h_y2, M));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMallocHost</span>(&amp;h_z2, M));</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> n = <span class="number">0</span>; n &lt; N; ++n)</span><br><span class="line">    &#123;</span><br><span class="line">        h_x2[n] = <span class="number">1.23</span>;</span><br><span class="line">        h_y2[n] = <span class="number">2.34</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; MAX_NUM_STREAMS; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaStreamCreate</span>(&amp;(streams[i])));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> num = <span class="number">1</span>; num &lt;= MAX_NUM_STREAMS; num *= <span class="number">2</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">timing</span>(h_x2, h_y2, h_z2, d_x, d_y, d_z, num);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span> ; i &lt; MAX_NUM_STREAMS; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaStreamDestroy</span>(streams[i]));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFreeHost</span>(h_x2));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFreeHost</span>(h_y2));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFreeHost</span>(h_z2));</span><br><span class="line"></span><br><span class="line">    <span class="built_in">free</span>(h_x);</span><br><span class="line">    <span class="built_in">free</span>(h_y);</span><br><span class="line">    <span class="built_in">free</span>(h_z);</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(d_x));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(d_y));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(d_z));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">cpu_sum</span><span class="params">(<span class="type">const</span> real *x, <span class="type">const</span> real *y, real *z, <span class="type">const</span> <span class="type">int</span> N_host)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> n = <span class="number">0</span>; n &lt; N_host; ++n)</span><br><span class="line">    &#123;</span><br><span class="line">        z[n] = x[n] + y[n];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> __global__ <span class="title">gpu_sum</span><span class="params">(<span class="type">const</span> real *x, <span class="type">const</span> real *y, real *z)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> n = blockDim.x * blockIdx.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span> (n &lt; N)</span><br><span class="line">    &#123;</span><br><span class="line">        z[n] = x[n] + y[n];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">timing</span></span></span><br><span class="line"><span class="function"><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> real *h_x, <span class="type">const</span> real *h_y, real *h_z,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> real *d_x, <span class="type">const</span> real *d_y, real *d_z,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> ratio, <span class="type">bool</span> overlap</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">float</span> t_sum = <span class="number">0</span>;</span><br><span class="line">    <span class="type">float</span> t2_sum = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> repeat = <span class="number">0</span>; repeat &lt;= NUM_REPEATS; ++repeat)</span><br><span class="line">    &#123;</span><br><span class="line">        cudaEvent_t start, stop;</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventCreate</span>(&amp;start));</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventCreate</span>(&amp;stop));</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventRecord</span>(start));</span><br><span class="line">        <span class="built_in">cudaEventQuery</span>(start);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (!overlap)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">cpu_sum</span>(h_x, h_y, h_z, N / ratio);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        gpu_sum&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(d_x, d_y, d_z);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (overlap)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// 主机函数与设备核函数重叠。</span></span><br><span class="line">            <span class="built_in">cpu_sum</span>(h_x, h_y, h_z, N / ratio);</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventRecord</span>(stop));</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventSynchronize</span>(stop));</span><br><span class="line">        <span class="type">float</span> elapsed_time;</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventElapsedTime</span>(&amp;elapsed_time, start, stop));</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Time = %g ms.\n&quot;</span>, elapsed_time);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (repeat &gt; <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            t_sum += elapsed_time;</span><br><span class="line">            t2_sum += elapsed_time * elapsed_time;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventDestroy</span>(start));</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventDestroy</span>(stop));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">float</span> t_ave = t_sum / NUM_REPEATS;</span><br><span class="line">    <span class="type">const</span> <span class="type">float</span> t_err = <span class="built_in">sqrt</span>(t2_sum / NUM_REPEATS - t_ave * t_ave);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Time = %g +- %g ms.\n&quot;</span>, t_ave, t_err);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> __global__ <span class="title">add</span><span class="params">(<span class="type">const</span> real *d_x, <span class="type">const</span> real *d_y, real *d_z)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> n = blockDim.x * blockIdx.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span> (n &lt; N1)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100000</span>; ++i)</span><br><span class="line">        &#123;</span><br><span class="line">            d_z[n] = d_x[n] + d_y[n];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">timing</span><span class="params">(<span class="type">const</span> real *d_x, <span class="type">const</span> real *d_y, real *d_z, <span class="type">const</span> <span class="type">int</span> num)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">float</span> t_sum = <span class="number">0</span>;</span><br><span class="line">    <span class="type">float</span> t2_sum = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> repeat = <span class="number">0</span>; repeat &lt;= NUM_REPEATS; ++repeat)</span><br><span class="line">    &#123;</span><br><span class="line">        cudaEvent_t start, stop;</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventCreate</span>(&amp;start));</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventCreate</span>(&amp;stop));</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventRecord</span>(start));</span><br><span class="line">        <span class="built_in">cudaEventQuery</span>(start);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> n = <span class="number">0</span>; n &lt; num; ++n)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">int</span> offset = n * N1;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 指定各个核函数的cuda流，实现核函数的并行。</span></span><br><span class="line">            add&lt;&lt;&lt;grid_size, block_size, <span class="number">0</span>, streams[n]&gt;&gt;&gt;(d_x + offset, d_y + offset, d_z + offset);</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventRecord</span>(stop));</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventSynchronize</span>(stop));</span><br><span class="line">        <span class="type">float</span> elapsed_time;</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventElapsedTime</span>(&amp;elapsed_time, start, stop));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (repeat &gt; <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            t_sum += elapsed_time;</span><br><span class="line">            t2_sum += elapsed_time * elapsed_time;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventDestroy</span>(start));</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventDestroy</span>(stop));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">float</span> t_ave = t_sum / NUM_REPEATS;</span><br><span class="line">    <span class="type">const</span> <span class="type">float</span> t_err = <span class="built_in">sqrt</span>(t2_sum / NUM_REPEATS - t_ave * t_ave);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%g\n&quot;</span>, t_ave);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> __global__ <span class="title">add2</span><span class="params">(<span class="type">const</span> real *x, <span class="type">const</span> real *y, real *z, <span class="type">int</span> N)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> n = blockDim.x * blockIdx.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span> (n &lt; N)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">40</span>; ++i)</span><br><span class="line">        &#123;</span><br><span class="line">            z[n] = x[n] + y[n];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">timing</span></span></span><br><span class="line"><span class="function"><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> real *h_x, <span class="type">const</span> real *h_y, real *h_z,</span></span></span><br><span class="line"><span class="params"><span class="function">    real *d_x, real *d_y, real *d_z,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> num</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> N1 = N / num;</span><br><span class="line">    <span class="type">int</span> M1 = M / num;</span><br><span class="line"></span><br><span class="line">    <span class="type">float</span> t_sum = <span class="number">0</span>;</span><br><span class="line">    <span class="type">float</span> t2_sum = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> repeat = <span class="number">0</span>; repeat &lt;= NUM_REPEATS; ++repeat)</span><br><span class="line">    &#123;</span><br><span class="line">        cudaEvent_t start, stop;</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventCreate</span>(&amp;start));</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventCreate</span>(&amp;stop));</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventRecord</span>(start));</span><br><span class="line">        <span class="built_in">cudaEventQuery</span>(start);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; num; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">int</span> offset = i * N1;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 划分主机不可分页内存，实现异步的数据传输。</span></span><br><span class="line">            <span class="comment">// 每个cuda流都有各自的数据传输操作。</span></span><br><span class="line">            <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpyAsync</span>(d_x + offset, h_x + offset, M1, </span><br><span class="line">                cudaMemcpyHostToDevice, streams[i]));</span><br><span class="line">            <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpyAsync</span>(d_y + offset, h_y + offset, M1, </span><br><span class="line">                cudaMemcpyHostToDevice, streams[i]));</span><br><span class="line"></span><br><span class="line">            <span class="type">int</span> block_size = <span class="number">128</span>;</span><br><span class="line">            <span class="type">int</span> grid_size = (N1 - <span class="number">1</span>) / block_size + <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 指定核函数的cuda流。</span></span><br><span class="line">            add2&lt;&lt;&lt;grid_size, block_size, <span class="number">0</span>, streams[i]&gt;&gt;&gt;(d_x + offset, d_y + offset, d_z + offset, N1);</span><br><span class="line"></span><br><span class="line">            <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpyAsync</span>(h_z + offset, d_z + offset, M1, </span><br><span class="line">                cudaMemcpyDeviceToHost, streams[i]));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventRecord</span>(stop));</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventSynchronize</span>(stop));</span><br><span class="line">        <span class="type">float</span> elapsed_time;</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventElapsedTime</span>(&amp;elapsed_time, start, stop));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (repeat &gt; <span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            t_sum += elapsed_time;</span><br><span class="line">            t2_sum += elapsed_time * elapsed_time;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventDestroy</span>(start));</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaEventDestroy</span>(stop));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">float</span> t_ave = t_sum / NUM_REPEATS;</span><br><span class="line">    <span class="type">const</span> <span class="type">float</span> t_err = <span class="built_in">sqrt</span>(t2_sum / NUM_REPEATS - t_ave * t_ave);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;%d %g\n&quot;</span>, num, t_ave);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="分子动力学模型"><a href="#分子动力学模型" class="headerlink" title="分子动力学模型"></a>分子动力学模型</h1><ol>
<li><p>将静态函数放在头文件中，则该函数就有可能被编译为内联函数，从而提高效率。<br> 适用于于需要被多个编译单元反复调用的函数。  开发cuda程序时，也应该尽量优化对应的c++程序。</p>
</li>
<li><p>半步长推进。<br> 粒子在t+dt时刻的坐标仅依赖t时刻的坐标、速度和力；但是t+dt时刻的速度依赖  t时刻的坐标、速度和t+dt时刻的力。  所以首先，以t时刻的状态计算t+dt/2时刻的速度；然后计算t+dt时刻的坐标，同时  更新t时刻的力到t+dt时刻；最后，以t+dt/2时刻的速度和t+dt时刻的力计算t+dt   时刻的速度。</p>
</li>
<li><p>常量内存比全局内存高速。<br> 如果数据量在编译期就确定且不大（明显小于4KB），在核函数中仅被读取，而且  一个线程束中的所有线程在某个时刻访问同一个地址，  则该数据适合用传参的方式使用常量内存。</p>
</li>
<li><p>逐步分析程序的性能瓶颈，逐步优化。<br> 将一个c++程序用cuda加速时，一般首先确定其中最耗时的部分并将其用cuda加速，从而  快速提高程序性能。  要得到最好的加速效果，需要尽可能多的将程序中可并行的计算用cuda加速。当然，  在大数情况下，我们需要在付出和收获间找到一个平衡点。</p>
</li>
</ol>
<hr>
<h1 id="cuda-标准库的使用"><a href="#cuda-标准库的使用" class="headerlink" title="cuda 标准库的使用"></a>cuda 标准库的使用</h1><ul>
<li>Thrust： 类型 c++ 的标准模板库；  </li>
<li>cuBLAS：基本线性代数子程序；</li>
<li>cuFFT：快速傅里叶变换；</li>
<li>cuSPARSE：稀疏矩阵；</li>
<li>cuRAND：随机数生成器；</li>
<li>cuSolver：稠密矩阵和稀疏矩阵计算库；</li>
<li>cuDNN：深度神经网络。</li>
</ul>
<hr>
<h2 id="Thrust"><a href="#Thrust" class="headerlink" title="Thrust"></a>Thrust</h2><p><strong>Thrust</strong>：一个实现了众多基本并行算法的c++模板库，类似c++的标准库stl。  </p>
<p><a href="https://github.com/NVIDIA/thrust">Thrust官方资料</a>  </p>
<ol>
<li>数据结构</li>
</ol>
<p>Thrust 中的数据结构主要是矢量容器，类似 stl 中的 std::vector:  </p>
<ul>
<li>存储于主机的容器 <code>thrust::host_vector&lt;typename&gt;</code>;</li>
<li>存储于设备的容器 <code>thrust::device__vector&lt;typename&gt;</code>;</li>
</ul>
<p>容器的使用也类似于 stl：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 包含头文件</span><br><span class="line">#include&lt;thrust/host_vector.h&gt;</span><br><span class="line">#include&lt;thrust/device_vector.h&gt;</span><br><span class="line"></span><br><span class="line">// 定义并初始化主机内存</span><br><span class="line">thrust::host_vector&lt;double&gt; arr(12, 0.0);</span><br></pre></td></tr></table></figure>
<p>Thrust 函数可以直接调用设备上的矢量容器。</p>
<ol>
<li>算法</li>
</ol>
<p>Thrust 提供5类常用算法：变换，归约，前缀和，排序于搜索，选择性复制、替换、移除、分区等重排操作。</p>
<p>Thrust 函数的参数必须都来自于主机容器，或者都来自于设备容器；thrust::copy 除外。</p>
<p>如果程序中大量使用了 thrust 库，使用设备矢量较为合适；如果只是偶尔使用 Thrust 库，<br>则使用设备内存指针更为合适。</p>
<hr>
<h2 id="cuBLAS"><a href="#cuBLAS" class="headerlink" title="cuBLAS"></a>cuBLAS</h2><p><strong>cuBLAS</strong>，一个基本线性代数子程序，提供三层功能函数：</p>
<ul>
<li>处理矢量之间的计算，如矢量之间的内积；</li>
<li>处理矩阵和矢量之间的运算，如相乘；</li>
<li>处理矩阵之间的运算，如相乘。</li>
</ul>
<p>CUBLAS 中矩阵采用 <strong>列主序</strong>，即矩阵数据按列存储。</p>
<p><a href="https://docs.nvidia.com/cuda/cublas/index.html">cuBLAS官方资料</a></p>
<hr>
<h2 id="cuSolver"><a href="#cuSolver" class="headerlink" title="cuSolver"></a>cuSolver</h2><p><strong>cuSolver</strong>：稠密矩阵和稀疏矩阵计算库。</p>
<p>cuSolver 相比于 cuBLAS，专注于一些比较高级的线性代数计算，并由3个子库组成：</p>
<ul>
<li>cuSolverDN，处理稠密矩阵线性代数计算；</li>
<li>cuSolverSP，处理稀疏矩阵线性代数计算；</li>
<li>cuSolverRF，处理稀疏矩阵分解。</li>
</ul>
<p>cuSolver 库函数倾向于使用异步执行。为例保证一个 cuSolver 函数的工作已完成，<br>可以使用 <code>cudaDeviceSynchronize()</code> 函数进行同步。</p>
<p>cuSolver 中矩阵同样采用 <strong>列主序</strong>。 </p>
<p><a href="https://docs.nvidia.com/cuda/cusolver/index.html">cuSolver官方资料</a></p>
<hr>
<h2 id="cuRAND"><a href="#cuRAND" class="headerlink" title="cuRAND"></a>cuRAND</h2><p><strong>cuRAND</strong>：随机数生成器。</p>
<p>cuRAND 库中提供两种 API： 主机API 和 设备API。以主机API为例，使用方式：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#include &lt;curand.h&gt;</span><br><span class="line"></span><br><span class="line">编译时指定链接选项 `-lcurand`</span><br></pre></td></tr></table></figure>
<p>同时，主机API 分为两种使用方式：</p>
<ul>
<li>使用设备产生伪随机数并存于设备数组；</li>
<li>使用主机产生伪随机数并存于主机数组。</li>
</ul>
<p><a href="https://docs.nvidia.com/cuda/curand/index.html">cuRAND官方资料</a></p>
<hr>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E7%A7%AF%E7%B4%AF/" rel="tag"># 积累</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2022/10/01/cmake%E6%95%99%E7%A8%8B/" rel="prev" title="CMake教程">
      <i class="fa fa-chevron-left"></i> CMake教程
    </a></div>
      <div class="post-nav-item">
    <a href="/2022/12/08/sgemm/" rel="next" title="SGEMM实施的完整演练">
      SGEMM实施的完整演练 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#GPU-%E7%A1%AC%E4%BB%B6%E4%B8%8E-CUDA-%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7"><span class="nav-number">1.</span> <span class="nav-text">GPU 硬件与 CUDA 程序开发工具</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#GPU-%E7%A1%AC%E4%BB%B6"><span class="nav-number">1.1.</span> <span class="nav-text">GPU 硬件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CUDA-%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7"><span class="nav-number">1.2.</span> <span class="nav-text">CUDA 程序开发工具</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CUDA-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA"><span class="nav-number">1.3.</span> <span class="nav-text">CUDA 开发环境搭建</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#nvidia-smi-%E6%A3%80%E6%9F%A5%E4%B8%8E%E8%AE%BE%E7%BD%AE%E8%AE%BE%E5%A4%87"><span class="nav-number">1.4.</span> <span class="nav-text">nvidia-smi 检查与设置设备</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CUDA-%E4%B8%AD%E7%9A%84%E7%BA%BF%E7%A8%8B%E7%BB%84%E7%BB%87"><span class="nav-number">2.</span> <span class="nav-text">CUDA 中的线程组织</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#C-%E7%9A%84-Hello-World-%E7%A8%8B%E5%BA%8F"><span class="nav-number">2.1.</span> <span class="nav-text">C++ 的 Hello World 程序</span></a></li><li class="nav-item nav-level-2"><a class="nav-link"><span class="nav-number">2.2.</span> <span class="nav-text">123&gt;&gt; g++ hello.cpp -o .&#x2F;bin&#x2F;hello.exe&gt;&gt; .&#x2F;bin&#x2F;hellomsvc: hello world!</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CUDA-%E7%9A%84-Hello-World-%E7%A8%8B%E5%BA%8F"><span class="nav-number">2.3.</span> <span class="nav-text">CUDA 的 Hello World 程序</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8-nvcc-%E7%BC%96%E8%AF%91%E7%BA%AF%E7%B2%B9-c-%E4%BB%A3%E7%A0%81"><span class="nav-number">2.3.1.</span> <span class="nav-text">使用 nvcc 编译纯粹 c++ 代码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8-%E6%A0%B8%E5%87%BD%E6%95%B0-%E7%9A%84-CUDA-%E7%A8%8B%E5%BA%8F"><span class="nav-number">2.3.2.</span> <span class="nav-text">使用 核函数 的 CUDA 程序</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CUDA-%E7%9A%84%E7%BA%BF%E7%A8%8B%E7%BB%84%E7%BB%87"><span class="nav-number">2.4.</span> <span class="nav-text">CUDA 的线程组织</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CUDA-%E7%9A%84%E5%A4%B4%E6%96%87%E4%BB%B6"><span class="nav-number">2.5.</span> <span class="nav-text">CUDA 的头文件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8-nvcc-%E7%BC%96%E8%AF%91-CUDA-%E7%A8%8B%E5%BA%8F"><span class="nav-number">2.6.</span> <span class="nav-text">使用 nvcc 编译 CUDA 程序</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%AE%80%E5%8D%95-CUDA-%E7%A8%8B%E5%BA%8F%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A1%86%E6%9E%B6"><span class="nav-number">3.</span> <span class="nav-text">简单 CUDA 程序的基本框架</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%95%E6%BA%90%E6%96%87%E4%BB%B6-CUDA-%E7%A8%8B%E5%BA%8F%E5%9F%BA%E6%9C%AC%E6%A1%86%E6%9E%B6"><span class="nav-number">3.1.</span> <span class="nav-text">单源文件 CUDA 程序基本框架</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E8%AE%BE%E5%A4%87%E5%87%BD%E6%95%B0"><span class="nav-number">3.2.</span> <span class="nav-text">自定义设备函数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CUDA-%E7%A8%8B%E5%BA%8F%E7%9A%84%E9%94%99%E8%AF%AF%E6%A3%80%E6%B5%8B"><span class="nav-number">4.</span> <span class="nav-text">CUDA 程序的错误检测</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%A3%80%E6%B5%8B-CUDA-%E8%BF%90%E8%A1%8C%E6%97%B6%E9%94%99%E8%AF%AF%E7%9A%84%E5%AE%8F%E5%87%BD%E6%95%B0"><span class="nav-number">4.1.</span> <span class="nav-text">检测 CUDA 运行时错误的宏函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CUDA-MEMCHECK-%E6%A3%80%E6%9F%A5%E5%86%85%E5%AD%98%E9%94%99%E8%AF%AF"><span class="nav-number">4.2.</span> <span class="nav-text">CUDA-MEMCHECK 检查内存错误</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%8E%B7%E5%BE%97-GPU-%E5%8A%A0%E9%80%9F%E7%9A%84%E5%85%B3%E9%94%AE"><span class="nav-number">5.</span> <span class="nav-text">获得 GPU 加速的关键</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#CUDA-%E4%BA%8B%E4%BB%B6%E8%AE%A1%E6%97%B6"><span class="nav-number">5.1.</span> <span class="nav-text">CUDA 事件计时</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#nvprof-%E6%9F%A5%E7%9C%8B%E7%A8%8B%E5%BA%8F%E6%80%A7%E8%83%BD"><span class="nav-number">5.2.</span> <span class="nav-text">nvprof 查看程序性能</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BD%B1%E5%93%8D-GPU-%E5%8A%A0%E9%80%9F%E7%9A%84%E5%85%B3%E9%94%AE%E5%9B%A0%E7%B4%A0"><span class="nav-number">5.3.</span> <span class="nav-text">影响 GPU 加速的关键因素</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CUDA-%E7%9A%84%E6%95%B0%E5%AD%A6%E5%87%BD%E6%95%B0%E5%BA%93"><span class="nav-number">5.4.</span> <span class="nav-text">CUDA 的数学函数库</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CUDA-%E7%9A%84%E5%86%85%E5%AD%98%E7%BB%84%E7%BB%87"><span class="nav-number">6.</span> <span class="nav-text">CUDA 的内存组织</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#CUDA-%E4%B8%AD%E4%B8%8D%E5%90%8C%E7%B1%BB%E5%9E%8B%E7%9A%84%E5%86%85%E5%AD%98"><span class="nav-number">6.1.</span> <span class="nav-text">CUDA 中不同类型的内存</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%A8%E5%B1%80%E5%86%85%E5%AD%98"><span class="nav-number">6.1.1.</span> <span class="nav-text">全局内存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B8%B8%E9%87%8F%E5%86%85%E5%AD%98"><span class="nav-number">6.1.2.</span> <span class="nav-text">常量内存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BA%B9%E7%90%86%E5%86%85%E5%AD%98"><span class="nav-number">6.1.3.</span> <span class="nav-text">纹理内存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%84%E5%AD%98%E5%99%A8"><span class="nav-number">6.1.4.</span> <span class="nav-text">寄存器</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B1%80%E9%83%A8%E5%86%85%E5%AD%98"><span class="nav-number">6.1.5.</span> <span class="nav-text">局部内存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98"><span class="nav-number">6.1.6.</span> <span class="nav-text">共享内存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L1-%E5%92%8C-L2-%E7%BC%93%E5%AD%98"><span class="nav-number">6.1.7.</span> <span class="nav-text">L1 和 L2 缓存</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SM-%E5%8F%8A%E5%85%B6%E5%8D%A0%E6%9C%89%E7%8E%87"><span class="nav-number">6.2.</span> <span class="nav-text">SM 及其占有率</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CUDA-%E8%BF%90%E8%A1%8C%E6%97%B6-API-%E5%87%BD%E6%95%B0%E6%9F%A5%E8%AF%A2%E8%AE%BE%E5%A4%87"><span class="nav-number">6.3.</span> <span class="nav-text">CUDA 运行时 API 函数查询设备</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%85%A8%E5%B1%80%E5%86%85%E5%AD%98%E7%9A%84%E5%90%88%E7%90%86%E4%BD%BF%E7%94%A8"><span class="nav-number">7.</span> <span class="nav-text">全局内存的合理使用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%A8%E5%B1%80%E5%86%85%E5%AD%98%E7%9A%84%E5%90%88%E5%B9%B6%E4%B8%8E%E9%9D%9E%E5%90%88%E5%B9%B6%E8%AE%BF%E9%97%AE"><span class="nav-number">7.1.</span> <span class="nav-text">全局内存的合并与非合并访问</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5%E8%BD%AC%E7%BD%AE"><span class="nav-number">7.2.</span> <span class="nav-text">矩阵转置</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E7%9A%84%E5%90%88%E7%90%86%E4%BD%BF%E7%94%A8"><span class="nav-number">8.</span> <span class="nav-text">共享内存的合理使用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E7%BB%84%E5%BD%92%E7%BA%A6"><span class="nav-number">8.1.</span> <span class="nav-text">数组归约</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5%E8%BD%AC%E7%BD%AE-1"><span class="nav-number">8.2.</span> <span class="nav-text">矩阵转置</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E7%9A%84-bank-%E5%86%B2%E7%AA%81"><span class="nav-number">8.3.</span> <span class="nav-text">共享内存的 bank 冲突</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8E%9F%E5%AD%90%E5%87%BD%E6%95%B0%E7%9A%84%E5%90%88%E7%90%86%E4%BD%BF%E7%94%A8"><span class="nav-number">9.</span> <span class="nav-text">原子函数的合理使用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AE%8C%E5%85%A8%E5%9C%A8-GPU-%E4%B8%AD%E8%BF%9B%E8%A1%8C%E5%BD%92%E7%BA%A6"><span class="nav-number">9.1.</span> <span class="nav-text">完全在 GPU 中进行归约</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8E%9F%E5%AD%90%E5%87%BD%E6%95%B0"><span class="nav-number">9.2.</span> <span class="nav-text">原子函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%82%BB%E5%B1%85%E5%88%97%E8%A1%A8"><span class="nav-number">9.3.</span> <span class="nav-text">邻居列表</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%BA%BF%E7%A8%8B%E6%9D%9F%E5%9F%BA%E6%9C%AC%E5%87%BD%E6%95%B0%E4%B8%8E%E5%8D%8F%E4%BD%9C%E7%BB%84"><span class="nav-number">10.</span> <span class="nav-text">线程束基本函数与协作组</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%95%E6%8C%87%E4%BB%A4-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%BC%8F"><span class="nav-number">10.1.</span> <span class="nav-text">单指令-多线程模式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E7%A8%8B%E6%9D%9F%E5%86%85%E7%9A%84%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5%E5%87%BD%E6%95%B0"><span class="nav-number">10.2.</span> <span class="nav-text">线程束内的线程同步函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9B%B4%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%9D%9F%E5%86%85%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%87%BD%E6%95%B0"><span class="nav-number">10.3.</span> <span class="nav-text">更多线程束内的基本函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%8F%E4%BD%9C%E7%BB%84"><span class="nav-number">10.4.</span> <span class="nav-text">协作组</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%95%B0%E7%BB%84%E5%BD%92%E7%BA%A6%E7%A8%8B%E5%BA%8F%E7%9A%84%E8%BF%9B%E4%B8%80%E6%AD%A5%E4%BC%98%E5%8C%96"><span class="nav-number">10.5.</span> <span class="nav-text">数组归约程序的进一步优化</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CUDA-%E6%B5%81"><span class="nav-number">11.</span> <span class="nav-text">CUDA 流</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9C%A8%E9%BB%98%E8%AE%A4%E6%B5%81%E4%B8%AD%E9%87%8D%E5%8F%A0%E4%B8%BB%E6%9C%BA%E5%92%8C%E8%AE%BE%E5%A4%87%E8%AE%A1%E7%AE%97"><span class="nav-number">11.1.</span> <span class="nav-text">在默认流中重叠主机和设备计算</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9D%9E%E9%BB%98%E8%AE%A4-cuda-%E6%B5%81%E9%87%8D%E5%8F%A0%E5%A4%9A%E4%B8%AA%E6%A0%B8%E5%87%BD%E6%95%B0"><span class="nav-number">11.2.</span> <span class="nav-text">非默认 cuda 流重叠多个核函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9D%9E%E9%BB%98%E8%AE%A4-cuda-%E6%B5%81%E9%87%8D%E5%8F%A0%E6%A0%B8%E5%87%BD%E6%95%B0%E4%B8%8E%E6%95%B0%E6%8D%AE%E4%BC%A0%E9%80%92"><span class="nav-number">11.3.</span> <span class="nav-text">非默认 cuda 流重叠核函数与数据传递</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%88%86%E5%AD%90%E5%8A%A8%E5%8A%9B%E5%AD%A6%E6%A8%A1%E5%9E%8B"><span class="nav-number">12.</span> <span class="nav-text">分子动力学模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#cuda-%E6%A0%87%E5%87%86%E5%BA%93%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="nav-number">13.</span> <span class="nav-text">cuda 标准库的使用</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Thrust"><span class="nav-number">13.1.</span> <span class="nav-text">Thrust</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cuBLAS"><span class="nav-number">13.2.</span> <span class="nav-text">cuBLAS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cuSolver"><span class="nav-number">13.3.</span> <span class="nav-text">cuSolver</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#cuRAND"><span class="nav-number">13.4.</span> <span class="nav-text">cuRAND</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Hao Yu</p>
  <div class="site-description" itemprop="description">Introduce something interesting and recode learning process, some articles are written by others, the original link has been given as much as possible, thanks to the original author</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">128</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hao Yu</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
